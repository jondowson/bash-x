#!/usr/bin/env bash
 f_arrays_filter(){ local array_new="${1}"; local filter_string="${2}"; declare -a filter_array; declare -A temp_filter_a; declare -n array_ref=${array_new}; asterix_count=$(f_utils_strings "count_chars" "${filter_string}" "*"); ((asterix_count++)); for ((i=1; i<=asterix_count; i++)) ; do string_id="string_${i}"; string_id="$(echo ${filter_string} | cut -d '*' -f${i})"; filter_array+=( ${string_id} ); done; current_array="A_variables_all"; first_run_flag="true"; for f in "${filter_array[@]}" ; do if [[ "${current_array}" == "A_variables_all" ]];then current_array="temp_filter_a"; for key in "${!A_variables_all[@]}" ; do case "${key}" in *"${f}"*) value="${A_variables_all[${key}]}"; temp_filter_a["${key}"]="${value}";; esac; done; elif [[ "${current_array}" == "temp_filter_a" ]];then for key in "${!temp_filter_a[@]}" ; do case "${key}" in *"${f}"*) ;; *) unset temp_filter_a["${key}"];; esac; done; fi; done; for key in "${!temp_filter_a[@]}" ; do value=${temp_filter_a["${key}"]}; array_ref["${key}"]="${value}"; done; unset -n array_ref; unset -n temp_filter_a; };  f_arrays_paths_clean_framework(){ for key in ${!A_framework_vars[@]} ; do result=""; new_key=""; new_value=""; this_value=""; new_value="${A_framework_vars[${key}]}"; this_value=$(f_utils_strings_bpe "paths_single_slash" "${new_value}"); if [[ "${this_value}" == "~/"* ]];then result=$(f_utils_strings_bpe "del_fromleft_upto_including" "${this_value}" "~/"); f_arrays_set_var "${key}" "${HOME}/${result}"; else f_arrays_set_var "${key}" "${this_value}"; fi; done; };  f_arrays_paths_clean_project(){ for key in ${!A_project_vars[@]} ; do result=""; new_key=""; new_value=""; this_value=""; if [[ "${key}" == *"_type" ]];then type_value="${A_project_vars[${key}]}"; new_key=$(echo $key | ${vf_cmd_sed} 's|\(.*\)_.*|\1|'); new_value="${A_project_vars[${new_key}]}"; case "${type_value}" in "path_"*) this_value=$(f_utils_strings_bpe "paths_single_slash" "${new_value}"); if [[ "${this_value}" == "~/"* ]];then result=$(f_utils_strings_bpe "del_fromleft_upto_including" "${this_value}" "~/"); f_arrays_set_var "${new_key}" "${HOME}/${result}"; else f_arrays_set_var "${new_key}" "${this_value}"; fi;; esac; fi; done; for key in ${!A_project_vars[@]} ; do result=""; new_key=""; new_value=""; this_value=""; if [[ "${key}" == *"_type" ]];then type_value="${A_project_vars[${key}]}"; new_key=$(echo $key | ${vf_cmd_sed} 's|\(.*\)_.*|\1|'); new_value="${A_project_vars[${new_key}]}"; case "${type_value}" in *"_local_relative_framework"*) relative_path=$(f_utils_strings_bpe "del_fromleft_upto_including" "${new_value}" "/bash-x/"); f_arrays_set_var "${new_key}" "${vf_path_framework_home}${relative_path}";; *"_local_relative_project"*) relative_path=$(f_utils_strings_bpe "del_fromleft_upto_including" "${new_value}" "/${vp_project_name}/"); f_arrays_set_var "${new_key}" "${vp_project_rootpath}${relative_path}";; *"custom_"*) fp_project_custom_flagtype "${type_value}" "${new_key}" "${new_value}";; esac; fi; done; };  f_arrays_set_var(){ local key; local value; key="${1}"; value="${2}"; A_variables_all["${key}"]="${value}"; if [[ "${value}" == "" ]];then A_variables_all_empty["${key}"]="${value}"; fi; a_variables_all_ordered+=( "${currentKey}" ); case "${key}" in     "vf_"*) A_framework_vars["${key}"]="${value}";; "vp_"*) A_project_vars["${key}"]="${value}";; "vj_inventory_"*) A_variables_inventory["${key}"]="${value}";; "vj_framework_"*) A_framework_json["${key}"]="${value}";; "vj_project_"*) A_project_json["${key}"]="${value}";; esac; key=$(f_utils_strings "bashvar_swap" "${key}"); printf -v "${key}" "${value}"; };  f_auth(){ AUTH_APPROACH="${vf_framework_flags_ssh_approach}"; f_arrays_set_var "SSH_PATH_TARGET" "${vf_framework_flags_ssh_targetpath}"; f_arrays_set_var "vp_path_remote_logs" "${SSH_PATH_TARGET}bash-x-projects/${vp_project_name}/input_output/logs/*.log"; result=""; isthere=$(command -v ssh); if [[ "${isthere}" == "" ]]; then result="ssh command unavailable"; fi; if [[ "${SSH_PATH_TARGET}" == "" ]]; then result="ssh target path not defined"; fi; case "${AUTH_APPROACH}" in "user_pass") f_arrays_set_var "USERNAME" "${vf_framework_flags_ssh_user}"; f_arrays_set_var "PASSWORD" "$(cat ${vf_framework_flags_ssh_passpath} 2> /dev/null)"; if [[ "${USERNAME}" == "" ]]; then result="no ssh user specified"; fi; if [[ "${PASSWORD}" == "" ]]; then result="${result} + no ssh user password specified"; fi; isthere=$(command -v sshpass); if [[ "${isthere}" == "" ]]; then result="${result} + no sshpass command available"; fi;; "user_key") f_arrays_set_var "SSH_PATH_KEY" "${vf_framework_flags_ssh_keypath}"; f_arrays_set_var "USERNAME" "${vf_framework_flags_ssh_user}"; if [[ "${USERNAME}" == "" ]]; then result="no ssh user specified"; fi; if [[ ! -f "${SSH_PATH_KEY}" ]]; then result="${result} + empty ssh key path"; fi;; "user_pass_key") f_arrays_set_var "SSH_PATH_KEY" "${vf_framework_flags_ssh_keypath}"; f_arrays_set_var "USERNAME" "${vf_framework_flags_ssh_user}"; f_arrays_set_var "PASSWORD" "$(cat ${SSH_PATH_KEY} 2> /dev/null)"; if [[ "${USERNAME}" == "" ]]; then result="no ssh user specified"; fi; if [[ "${PASSWORD}" == "" ]]; then result="${result} + no ssh user password specified"; fi; isthere=$(command -v sshpass); if [[ "${isthere}" == "" ]]; then result="${result} + no sshpass command available"; fi; if [[ ! -f "${SSH_PATH_KEY}" ]]; then result="${result} + empty ssh key path"; fi;; "cicd_user_pass") f_arrays_set_var "USERNAME" "${USERNAME}"; f_arrays_set_var "PASSWORD" "${PASSWORD}"; if [[ "${USERNAME}" == "" ]]; then result="no ssh user specified"; fi; if [[ "${PASSWORD}" == "" ]]; then result="${result} + no ssh user password specified"; fi;; *) result="Non-valid user authentication specified: ${AUTH_APPROACH}";; esac; if [[ "${result}" != "" ]]; then f_arrays_set_var "vf_framework_flags_behaviour_fastfail" "true"; f_arrays_set_var "vf_dynamic_error_msg" "${result}"; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "authentication"; fi; };  f_check_project_checktypes(){ local json_errcode; local loop_stage_exitcode; local check_type; local check_mode; local check_this; local result; local true_count; local comma_count; local cc; local cmd_substring; check_type=${1}; json_errorcode="1"; while :; do loop_stage_exitcode="vj_errors_s${vp_stage_number}_e${json_errorcode}"; if [[ "${A_json_errors[${loop_stage_exitcode}_message]}" == "" ]];then break; fi; check_type="${A_json_errors[${loop_stage_exitcode}_check_type]}"; if [[ "${A_json_errors[${loop_stage_exitcode}_check_type]}" == "" ]];then json_errorcode=$((json_errorcode+1)); continue; fi; if [[ "${vf_framework_flags_behaviour_remotecompute}" == "true" ]]; then check_mode="${A_json_errors[${loop_stage_exitcode}_check_remote]}"; else check_mode="${A_json_errors[${loop_stage_exitcode}_check_local]}"; fi; check_this="${A_json_errors[${loop_stage_exitcode}_check_this]}"; result="true"; true_count="0"; case "${check_type}" in command) comma_count=$(f_utils_strings "count_chars" "${check_this}" ","); cc=0; until [ "${cc}" -gt $((comma_count)) ] ; do cmd_substring=$(echo "${check_this}" | cut -d "," -f"$((cc+1))"); result=$(command -v ${cmd_substring}); if [[ "${result}" != "" ]];then true_count=$((true_count+1)); fi; ((cc++)); done; if [[ "${true_count}" -eq "0" ]] && [[ "${check_mode}" == "true" ]];then result=false; fi;; path_file) pathfile="${check_this}"; if [[ "${check_this}" == "vj_"* ]] || [[ "${check_this}" == "vf_"* ]]|| [[ "${check_this}" == "vp_"* ]];then pathfile=${!check_this}; fi; if [[ ! -f "${pathfile}" ]] && [[ "${check_mode}" == "true" ]];then result="false"; fi;; path_folder) pathfolder="${check_this}"; if [[ "${check_this}" == "vj_"* ]] || [[ "${check_this}" == "vf_"* ]]|| [[ "${check_this}" == "vp_"* ]];then pathfolder=${!check_this}; fi; if [[ ! -d "${pathfolder}" ]] && [[ "${check_mode}" == "true" ]];then result="false"; fi;; var_empty) var_set="${check_this}"; if [[ "${check_this}" == "vj_"* ]] || [[ "${check_this}" == "vf_"* ]]|| [[ "${check_this}" == "vp_"* ]];then var_set=${!check_this}; fi; if [[ "${var_set}" == "" ]];then result="false"; fi;; esac; if [[ "${result}" == "false" ]];then hint=$(echo ${A_json_errors[${loop_stage_exitcode}_hint]}); f_arrays_set_var "vf_framework_flags_behaviour_fastfail" "true"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${json_errorcode}"; fi; json_errorcode=$((json_errorcode+1)); done; };  f_check_project_flags(){ local i; local string; local was_matched; local short_flag; local long_flag; was_matched="false"; for k in "${!A_json_help[@]}"   ; do     if [[ "$k" == *"vj_help_flags_"* ]] && [[ "$k" == *"_shortflag"* ]];then       shortflag=${A_json_help[${k}]}; longflag1=$(echo ${k%"_shortflag"}); longflag2=$(echo ${longflag1#"vj_help_flags_"}); if [[ "-${shortflag}" == "${vf_flag_current}" ]] || [[ "--${longflag2}" == "${vf_flag_current}" ]];then         was_matched="true"; f_arrays_set_var "vp_help_flags_${longflag2}" "${vf_flag_current_value}"; break; fi; fi; done; if [[ "${was_matched}" == "false" ]];then   f_display_colors "true"; f_display_banner; ${spacer}; printf "%b\n" "${yl}--> Project name:${cy}         ${vj_project_name}"; printf "%b\n" "${yl}--> Project repo:${cy}         ${vj_project_repo}"; printf "%b\n" "${yl}--> Project version:${cy}      ${vj_project_version}${rs}"; ${dashLine}; ${spacer}; printf "%b\n" "${yl}--> Project started with these passed flags.${rs}"; ${spacer}; printf "%b\n" "${vf_args_passed}"; ${spacer}; f_arrays_set_var "vf_framework_flags_behaviour_fastfail" "true"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "1"; fi; };  f_check_project_json_exist(){ local err_flag; err_flag=""; if [ ! -f "${vp_project_rootpath}json/project/arrays.json" ];then f_arrays_set_var "vf_dynamic_error_msg" "${vp_project_rootpath}json/project/arrays.json"; err_flag="true"; fi; if [ ! -f "${vp_project_rootpath}json/project/errors.json" ];then f_arrays_set_var "vf_dynamic_error_msg" "${vp_project_rootpath}json/project/errors.json"; err_flag="true"; fi; if [ ! -f "${vp_project_rootpath}json/project/help.json" ];then f_arrays_set_var "vf_dynamic_error_msg" "${vp_project_rootpath}json/project/help.json"; err_flag="true"; fi; if [[ "${err_flag}" == "true" ]];then f_arrays_set_var "vf_framework_flags_behaviour_fastfail" "true"; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "project_json"; fi; };  f_debug_arrays(){ local array_to_display; local k; array_to_display="${1}"; filter="${2}"; declare -n dynamic_array_name="${array_to_display}"; case "${array_to_display}" in   "all") declare -n dynamic_array_name="A_variables_all";; "empty") declare -n dynamic_array_name="A_variables_all_empty";; "framework") declare -n dynamic_array_name="A_framework_vars";; "project") declare -n dynamic_array_name="A_project_vars";; esac; if [[ "${filter}" == "false" ]];then    for k in "${!dynamic_array_name[@]}"   ; do       printf "%b\n" "${cy}Key:     ${blB}${k}${rs}"; printf "%b\n" "${yl}value:   ${blB}${dynamic_array_name[$k]}${rs}"; done; else   for k in "${!dynamic_array_name[@]}"   ; do     if [[ "${k}" == *"${filter}"* ]];then        printf "%b\n" "${cy}Key:     ${blB}${k}${rs}"; printf "%b\n" "${yl}value:   ${blB}${dynamic_array_name[$k]}${rs}"; fi; done; fi; };  f_dependency_actual_cleaner(){ local version; local mode; local regex; local version_number; version="${1}"; mode="${2}"; regex=""; if [[ $mode == "basic" ]];then     regex='[0-9]+(\.[0-9]+)*'; elif [[ $mode == "normal" ]];then     regex="v?([0-9]+(\.[0-9]+)+)"; elif [[ $mode == "with_x" ]];then     regex='[0-9]+((\.|-|_)([0-9]|x)+)*'; fi; [[ $version =~ $regex ]]; version_number="${BASH_REMATCH[0]}"; version_number=$(echo "${version_number}" | ${vf_cmd_sed} 's/[^0-9.]//g'); printf "%s" "${version_number}"; };  f_dependency_array_copy(){ local var=$(declare -p $1); var=${var/declare /declare -g }; eval "${var/$1=/$2=}"; };  f_dependency_metadata_json(){ local length; local lastIndex; local total_count; local category_count; local prevf_category; local category; local clean_name; if [[ $vj_framework_flags_tools_inspect == "json" ]] || [[ $vj_framework_flags_tools_inspect == "" ]];then vf_metadata_string='{ "metadata":{'; length=${#A_metadata[@]}; lastIndex=$(( $length - 1 )); total_count=0; category_count=0; prevf_category=""; for i in "${a_metadata_ordered[@]}" ; do category=$(f_utils_strings_bpe "keep_fromleft_upto_excluding_first" "${i}" "_"); clean_name=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${i}" "_"); if [[ $total_count == 0 ]];then vf_metadata_string+="\"$category\":{"; fi; if [[ $total_count != 0 ]] && [[ $category != $prevf_category ]];then vf_metadata_string+="},\"$category\":{"; category_count=0; fi; if [[ $category_count != 0 ]];then vf_metadata_string+=','; fi; prevf_category=$category; vf_metadata_string+="\"${clean_name}\": \"${A_metadata[$i]}\""; if [[ $total_count == $lastIndex ]];then vf_metadata_string+='}'; fi; category_count=$((category_count + "1")); total_count=$((total_count + "1")); done; vf_metadata_string+='},'; fi; };  f_dependency_metadata_linux(){ local system; local kernel_version; local kernel_release; local os_architecture; local cpu; local cpu_cores; local threads; local cpu_mode; local byte_order; local processes; local hypervisor; local virtualization; local ram; local ram_free; local ram_available; local disk; local disk_used; local disk_available; local disk_used_percent; local current_user; local users; local nb_users; local users_with_home; local nb_users_with_home; local last_users; local last_users2; local last_lastuser; local last_current; local groups; local nb_groups; local nb_crontab; local docker_container_list; local docker_container_nb; local podman_container_list; local podman_container_nb; local private_ip; local subnet_mask; local subnet_mask2; local public_ip; system=$(uname); A_metadata["os_system"]=${system}; a_metadata_ordered+=( "os_system" ); A_metadata["os_name"]=${vf_os_identify}; a_metadata_ordered+=( "os_name" ); kernel_version=$(uname -v); A_metadata["os_kernel_version"]=${kernel_version}; a_metadata_ordered+=( "os_kernel_version" ); kernel_release=$(uname -r); A_metadata["os_kernel_release"]=${kernel_release}; a_metadata_ordered+=( "os_kernel_release" ); os_architecture=$(uname -m); A_metadata["os_architecture"]=${os_architecture}; a_metadata_ordered+=( "os_architecture" ); cpu=$(lscpu | grep 'Model name'); cpu=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "$cpu" ":" | sed -e 's/^[ \t]*//'); A_metadata["cpu_name"]=$cpu; a_metadata_ordered+=( "cpu_name" ); cpu_cores=$(lscpu | grep -w 'CPU(s):' | head -n 1); cpu_cores=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "$cpu_cores" ":" | sed -e 's/^[ \t]*//'); A_metadata["cpu_cores"]=$cpu_cores; a_metadata_ordered+=( "cpu_cores" ); threads=$(lscpu | grep -w 'Thread'); threads=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "$threads" ":" | sed -e 's/^[ \t]*//'); A_metadata["cpu_threads"]=$threads; a_metadata_ordered+=( "cpu_threads" ); cpu_mode=$(lscpu | grep -w 'CPU op-mode(s)'); cpu_mode=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "$cpu_mode" ":" | sed -e 's/^[ \t]*//'); A_metadata["cpu_mode"]=$cpu_mode; a_metadata_ordered+=( "cpu_mode" ); byte_order=$(lscpu | grep -w 'Byte Order'); byte_order=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "$byte_order" ":" | sed -e 's/^[ \t]*//'); A_metadata["cpu_byte_order"]=$byte_order; a_metadata_ordered+=( "cpu_byte_order" ); processes=$(ps -e --no-headers | wc -l); A_metadata["cpu_processes"]=$processes; a_metadata_ordered+=( "cpu_processes" ); hypervisor=$(lscpu | grep -w 'Hypervisor'); hypervisor=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${hypervisor}" ":" | sed -e 's/^[ \t]*//'); A_metadata["vm_hypervisor_vendor"]=${hypervisor}; a_metadata_ordered+=( "vm_hypervisor_vendor" ); virtualization=$(lscpu | grep -w 'Virtualization'); virtualization=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${virtualization}" ":" | sed -e 's/^[ \t]*//'); A_metadata["vm_virtualization_type"]=${virtualization}; a_metadata_ordered+=( "vm_virtualization_type" ); ram=$(echo $(($(getconf _PHYS_PAGES) * $(getconf PAGE_SIZE) / (1024 * 1024)))); A_metadata["ram_total (MB)"]=${ram}; a_metadata_ordered+=( "ram_total (MB)" ); ram_free=$(echo $(($(getconf _AVPHYS_PAGES) * $(getconf PAGE_SIZE) / (1024 * 1024)))); A_metadata["ram_free (MB)"]=${ram_free}; a_metadata_ordered+=( "ram_free (MB)" ); ram_available=$(cat /proc/meminfo | grep -w "MemAvailable"); ram_available=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${ram_available}" ": "); ram_available=$(f_utils_strings_bpe "keep_fromleft_upto_excluding_first" "${ram_available}" "k"); ram_available=$(( ram_available / 1024 )); A_metadata["ram_available (MB)"]=${ram_available}; a_metadata_ordered+=( "ram_available (MB)" ); disk=$(df -m . | head -2 | tail -1 | awk '{print $2}'); A_metadata["disk_total (MB)"]=${disk}; a_metadata_ordered+=( "disk_total (MB)" ); disk_used=$(df -m . | head -2 | tail -1 | awk '{print $3}'); A_metadata["disk_used (MB)"]=${disk_used}; a_metadata_ordered+=( "disk_used (MB)" ); disk_available=$(df -m . | head -2 | tail -1 | awk '{print $4}'); A_metadata["disk_available (MB)"]=${disk_available}; a_metadata_ordered+=( "disk_available (MB)" ); disk_used_percent=$(df -m . | head -2 | tail -1 | awk '{print $5}'); A_metadata["disk_used_percent (MB)"]=${disk_used_percent}; a_metadata_ordered+=( "disk_used_percent (MB)" ); current_user=$(whoami); A_metadata["user_current"]=${current_user}; a_metadata_ordered+=( "user_current" ); users=($(cat /etc/passwd | awk -F: '{print $1}')); A_metadata["user_users"]=${users[@]}; a_metadata_ordered+=( "user_users" ); nb_users=$(cat /etc/passwd | wc -l); A_metadata["user_nb_users"]=${nb_users}; a_metadata_ordered+=( "user_nb_users" ); users_with_home=($(cat /etc/passwd | grep '/home/' | awk -F: '{print $1}')); A_metadata["user_users_with_home"]=${users_with_home[@]}; a_metadata_ordered+=( "user_users_with_home" ); nb_users_with_home=$(cat /etc/passwd | grep '/home/' | wc -l); A_metadata["user_nb_users_with_home"]=${nb_users_with_home}; a_metadata_ordered+=( "user_nb_users_with_home" ); last_users=($(last -5 | head -n -2 | awk '{print $1}')); A_metadata["user_last_users"]=${last_users[@]}; a_metadata_ordered+=( "user_last_users" ); last_users2=($(last -6 | tail -n +2 | head -n -2 | awk '{print $1}')); A_metadata["user_last_users_no_current"]=${last_users2[@]}; a_metadata_ordered+=( "user_last_users_no_current" ); last_lastuser=$(last -a -2 ${last_users[1]} | tail -n +2 | head -n -2 | awk -F '[[:space:]][[:space:]]+' '{print $3}'); last_lastuser=$(f_utils_strings_bpe "keep_fromleft_upto_excluding_first" "${last_lastuser}" "-"); A_metadata["user_last_time_last_user"]=${last_lastuser}; a_metadata_ordered+=( "user_last_time_last_user" ); last_current=$(last -a -2 ${current_user} | tail -n +2 | head -n -2 | awk -F '[[:space:]][[:space:]]+' '{print $3}'); last_current=$(f_utils_strings_bpe "keep_fromleft_upto_excluding_first" "${last_current}" "-"); A_metadata["user_last_time_current_user"]=${last_current}; a_metadata_ordered+=( "user_last_time_current_user" ); groups=($(groups)); A_metadata["user_groups"]=${groups[@]}; a_metadata_ordered+=( "user_groups" ); nb_groups=${#groups[@]}; A_metadata["user_nb_groups"]=${nb_groups}; a_metadata_ordered+=( "user_nb_groups" ); nb_crontab=$(crontab -l 2>/dev/null | grep -ve "#\|^$" | wc -l); A_metadata["crontab_nb_crontab"]=${nb_crontab}; a_metadata_ordered+=( "crontab_nb_crontab" ); which docker > /dev/null 2>&1; if [[ $? == 0 ]];then docker_container_list=($(docker ps --format '{{.Names}}')); A_metadata["container_docker_container_list"]=${docker_container_list[@]}; a_metadata_ordered+=( "container_docker_container_list" ); docker_container_nb=${#docker_container_list[@]}; A_metadata["container_docker_container_nb"]=${docker_container_nb}; a_metadata_ordered+=( "container_docker_container_nb" ); fi; which podman > /dev/null 2>&1; if [[ ${?} == 0 ]];then podman_container_list=($(podman ps -a --format '{{.Names}}')); A_metadata["container_podman_container_list"]=${podman_container_list[@]}; a_metadata_ordered+=( "container_docker_container_list" ); podman_container_nb=${#podman_container_list[@]}; A_metadata["container_podman_container_nb"]=${podman_container_nb}; a_metadata_ordered+=( "container_podman_container_nb" ); fi; private_ip=$(f_utils_network "calc_ip_local"); A_metadata["network_private_ip"]=${private_ip}; a_metadata_ordered+=( "network_private_ip" ); subnet_mask=$(ip -o -f inet addr show | grep ${private_ip} | awk '{print $4}'); A_metadata["network_subnet_mask"]=${subnet_mask}; a_metadata_ordered+=( "network_subnet_mask" ); which ifconfig > /dev/null 2>&1; if [[ $? == 0 ]];then subnet_mask2=$(ifconfig | grep ${private_ip} | awk '{print $4}'); A_metadata["network_subnet_mask2"]=${subnet_mask2}; a_metadata_ordered+=( "network_subnet_mask2" ); fi; which curl > /dev/null 2>&1; if [[ $? == 0 ]];then public_ip=$(f_utils_network "calc_ip_public"); A_metadata["network_public_ip"]=${public_ip}; a_metadata_ordered+=( "network_public_ip" ); fi; };  f_dependency_metadata_macos(){ local system; local kernel_version; local kernel_release; local os_architecture; local disk; local disk_used; local disk_available; local disk_used_percent; local nb_crontab; local docker_container_list; local docker_container_nb; local podman_container_list; local podman_container_nb; system=$(uname); A_metadata["os_system"]=${system}; a_metadata_ordered+=( "os_system" ); A_metadata["os_name"]=${vf_os_identify}; a_metadata_ordered+=( "os_name" ); kernel_version=$(uname -v); A_metadata["os_kernel_version"]=${kernel_version}; a_metadata_ordered+=( "os_kernel_version" ); kernel_release=$(uname -r); A_metadata["os_kernel_release"]=${kernel_release}; a_metadata_ordered+=( "os_kernel_release" ); os_architecture=$(uname -m); A_metadata["os_architecture"]=${os_architecture}; a_metadata_ordered+=( "os_architecture" ); disk=$(df -m . | head -2 | tail -1 | awk '{print $2}'); A_metadata["disk_total (MB)"]=${disk}; a_metadata_ordered+=( "disk_total (MB)" ); disk_used=$(df -m . | head -2 | tail -1 | awk '{print $3}'); A_metadata["disk_used (MB)"]=${disk_used}; a_metadata_ordered+=( "disk_used (MB)" ); disk_available=$(df -m . | head -2 | tail -1 | awk '{print $4}'); A_metadata["disk_available (MB)"]=${disk_available}; a_metadata_ordered+=( "disk_available (MB)" ); disk_used_percent=$(df -m . | head -2 | tail -1 | awk '{print $5}'); A_metadata["disk_used_percent (MB)"]=${disk_used_percent}; a_metadata_ordered+=( "disk_used_percent (MB)" ); nb_crontab=$(crontab -l 2>/dev/null | grep -ve "#\|^$" | wc -l | sed 's/^ *//g' | sed 's/$ *//g' | sed 's/ */ /g'); A_metadata["crontab_nb_crontab"]=${nb_crontab}; a_metadata_ordered+=( "crontab_nb_crontab" ); which docker > /dev/null 2>&1; if [[ $? == 0 ]];then docker_container_list=($(docker ps --format '{{.Names}}')); A_metadata["container_docker_container_list"]=${docker_container_list[@]}; a_metadata_ordered+=( "container_docker_container_list" ); docker_container_nb=${#docker_container_list[@]}; A_metadata["container_docker_container_nb"]=${docker_container_nb}; a_metadata_ordered+=( "container_docker_container_nb" ); fi; which podman > /dev/null 2>&1; if [[ ${?} == 0 ]];then podman_container_list=($(podman ps -a --format '{{.Names}}')); A_metadata["container_podman_container_list"]=${podman_container_list[@]}; a_metadata_ordered+=( "container_docker_container_list" ); podman_container_nb=${#podman_container_list[@]}; A_metadata["container_podman_container_nb"]=${podman_container_nb}; a_metadata_ordered+=( "container_podman_container_nb" ); fi; };  f_dependency_step1(){ local run_mode="${1}"; local debian_list; local length; local lastIndex; local count; f_dependency_step2 "vj_framework_dependencies_os_all"; debian_list=("Ubuntu" "Alpine" "Debian" "MX Linux" "Linux Mint" "Deepin" "AntiX" "PureOS" "Kali Linux" "Parrot OS" "Devuan" "Knoppix" "AV Linux" "Pop!_OS" "Q4OS" "SparkyLinux" "Zorin OS" "Devuan" "KDE Neon"); if [[ "${vf_os_identify}" == "Mac" ]]; then     f_dependency_step2 "vj_framework_dependencies_os_mac"; elif [[ "${debian_list[*]}" =~ "${vf_os_identify}" ]]; then     f_dependency_step2 "vj_framework_dependencies_os_debian"; else     f_dependency_step2 "vj_framework_dependencies_os_rhel"; fi; f_arrays_set_var "vf_metadata_string" ""; if [[ "${vf_os_identify}" != "Mac" ]]; then     f_dependency_metadata_linux; else     f_dependency_metadata_macos; fi; f_dependency_metadata_json; if [[ "${vp_project_name}" != "" ]]; then     f_dependency_step2 "vj_project_dependencies"; fi; f_dependency_version_json "framework"; if [[ "${vp_project_name}" != "" ]];then     vf_metadata_string+=','; f_dependency_version_json "project_make"; fi; if [[ "${vp_project_name}" != "" ]];then     vf_metadata_string+=','; f_dependency_version_json "project_execute"; fi; vf_metadata_string+='}'; if [[ "${run_mode}" == "true" ]];then     clear; clear; printf "%s\n" "${vf_metadata_string}" | ${jq} --indent 4 .; fi; };  f_dependency_step2(){ local array_to_check; local char_count; local dependency; local version; array_to_check="${1}"; source=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${array_to_check}" "_"); source=$(f_utils_strings_bpe "keep_fromleft_upto_excluding_first" "${source}" "_"); for k in "${!A_variables_all[@]}" ; do if [[ "${k}" == *"${array_to_check}_"* ]];then if [[ "${k}" == *"project_dependencies_make_about"* ]] || [[ "${k}" == *"project_dependencies_execute_about"* ]];then continue; fi; if [[ "${k}" == *"project_dependencies_make"* ]];then project_subcategory="project_dependencies_make"; elif [[ "${k}" == *"project_dependencies_execute"* ]];then project_subcategory="project_dependencies_execute"; fi; dependency=$(f_utils_strings_bpe "del_fromleft_upto_including" "${k}" "_"); version=${A_variables_all[${k}]}; which ${dependency} > /dev/null 2>&1; if [[ ${?} != 0 ]];then man ${dependency} > /dev/null 2>&1; if [[ ${?} != 0 ]];then if [[ "${vf_os_identify}" == "Mac" ]]; then which brew > /dev/null 2>&1; if [[ ${?} == 0 ]];then brew list | grep -iw ${dependency} > /dev/null 2>&1; if [[ ${?} != 0 ]];then if [[ "${source}" == "framework" ]];then A_dependency_checked["${dependency}"]="false"; A_dependency_installed["${dependency}"]="none"; continue; elif [[ "${source}" == "project" ]];then A_dependency_checked_project["${dependency}"]="false"; A_dependency_installed_project["${dependency}"]="none"; if [[ "${project_subcategory}" == *"project_dependencies_make"* ]];then A_dependency_checked_project_make["${dependency}"]="false"; A_dependency_installed_project_make["${dependency}"]="none"; elif [[ "${project_subcategory}" == *"project_dependencies_execute"* ]];then A_dependency_checked_project_execute["${dependency}"]="false"; A_dependency_installed_project_execute["${dependency}"]="none"; fi; continue; fi; fi; fi; else which dpkg > /dev/null 2>&1; if [[ ${?} == 0 ]];then dpkg -s ${dependency} 2>/dev/null; if [[ $? != 0 ]];then if [[ "${source}" == "framework" ]];then A_dependency_checked["${dependency}"]="false"; A_dependency_installed["${dependency}"]="none"; elif [[ "${source}" == "project" ]];then A_dependency_checked_project["${dependency}"]="false"; A_dependency_installed_project["${dependency}"]="none"; if [[ "${project_subcategory}" == *"project_dependencies_make"* ]];then A_dependency_checked_project_make["${dependency}"]="false"; A_dependency_installed_project_make["${dependency}"]="none"; elif [[ "${project_subcategory}" == *"project_dependencies_execute"* ]];then A_dependency_checked_project_execute["${dependency}"]="false"; A_dependency_installed_project_execute["${dependency}"]="none"; fi; fi; continue; fi; fi; fi; fi; fi; f_dependency_step3 ${dependency} ${version} ${source} ${project_subcategory}; fi; done; };  f_dependency_step3(){ local dependency; local json_value; local source; local json_value_clean; local VERSION_PARTS; local major_json; local minor_json; local patch_json; local get_version; local VERSION_PARTS_ACTUAL; local major_actual; local minor_actual; local patch_actual; local actual_value; dependency="${1}"; json_value="${2}"; source="${3}"; project_subcategory="${4}"; json_value_clean="$(echo "${json_value}" | ${vf_cmd_sed} 's/^[^0-9]*//')"; OLD_IFS=$IFS; IFS='.' read -ra VERSION_PARTS <<< "${json_value_clean}"; major_json="${VERSION_PARTS[0]}"; minor_json="${VERSION_PARTS[1]}"; patch_json="${VERSION_PARTS[2]}"; IFS=$OLD_IFS; get_version=""; if [[ "${dependency}" == "ping" ]];then ping 127.0.0.1 -t 1 > /dev/null 2>&1; if [[ $? == 0 ]];then get_version="0.0.0"; else get_version=""; fi; elif [[ "${dependency}" == "awk" ]];then awk --version > /dev/null 2>&1; if [[ $? == 0 ]];then get_version="0.0.0"; else get_version=""; fi; else get_version=$(${dependency} --version 2>&1); if [[ $? != 0 ]];then get_version=$(${dependency} -version 2>&1); if [[ $? != 0 ]];then get_version=$(${dependency} -v 2>&1); if [[ $? != 0 ]];then get_version=$("${dependency}" -V 2>&1); if [[ $? != 0 ]];then get_version=$(${dependency} -W version 2>&1); if [ "${?}" != 0 ] && [ "${vf_os_identify}" != "Mac" ];then which dpkg > /dev/null 2>&1; if [[ "${?}" == 0 ]];then get_version=$(dpkg -s ${dependency} 2>&1); if [[ $? != 0 ]];then which apt > /dev/null 2>&1; if [[ "${?}" == 0 ]];then get_version=$(apt-cache policy ${dependency} 2>&1); else get_version=""; fi; fi; fi; else which brew > /dev/null 2>&1; if [[ ${?} == 0 ]];then brew list | grep -iw ${dependency}; if [[ "${?}" == 0 ]];then get_version=$(brew info ${dependency}); else brew info ${dependency} > /dev/null 2>&1; if [[ "${?}" == 0 ]];then get_version=$(brew info ${dependency}); else get_version=""; fi; fi; fi; fi; fi; fi; fi; fi; fi; if [[ "${get_version}" == "" ]];then if [[ "${source}" == "framework" ]];then A_dependency_checked["${dependency}"]="false"; A_dependency_installed["${dependency}"]="none"; elif [[ "${source}" == "project" ]];then A_dependency_checked_project["${dependency}"]="false"; A_dependency_installed_project["${dependency}"]="none"; if [[ "${project_subcategory}" == *"project_dependencies_make"* ]];then A_dependency_checked_project_make["${dependency}"]="false"; A_dependency_installed_project_make["${dependency}"]="none"; elif [[ "${project_subcategory}" == *"project_dependencies_execute"* ]];then A_dependency_checked_project_execute["${dependency}"]="false"; A_dependency_installed_project_execute["${dependency}"]="none"; fi; fi; else actual_value=$(f_dependency_actual_cleaner "${get_version}" "normal"); OLD_IFS=$IFS; IFS='.' read -ra VERSION_PARTS_ACTUAL <<< "${actual_value}"; major_actual="${VERSION_PARTS_ACTUAL[0]}"; minor_actual="${VERSION_PARTS_ACTUAL[1]}"; patch_actual="${VERSION_PARTS_ACTUAL[2]}"; IFS=$OLD_IFS; f_dependency_step4 "${source}" "${dependency}" "${project_subcategory}" "${json_value}" "${actual_value}" "${major_json}" "${minor_json}" "${patch_json}" "${major_actual}" "${minor_actual}" "${patch_actual}"; fi; };  f_dependency_step4(){ local version_part_count; local source; local dependency; local json_value; local major_json; local minor_json; local patch_json; local major_actual; local minor_actual; local patch_actual; local success; source="${1}"; dependency="${2}"; project_subcategory="${3}"; json_value="${4}"; actual_value="${5}"; major_json="${6}"; minor_json="${7}"; patch_json="${8}"; major_actual="${9}"; minor_actual="${10}"; patch_actual="${11}"; if [[ "${patch_json}" == "" ]] && [[ "${minor_json}" == "" ]];then version_part_count="1"; elif [[ "${patch_json}" == "" ]] && [[ "${minor_json}" != "" ]];then version_part_count="2"; else version_part_count="3"; fi; success="false"; case ${json_value:0:1} in "^") if [[ "${major_actual}" -eq "${major_json}" ]];then if [[ "${minor_actual}" -ge "${minor_json}" ]] && [[ "${patch_actual}" -ge "${patch_json}" ]] ;then success="true"; elif [[ "${minor_actual}" -ge "${minor_json}" ]];then if [[ "${patch_actual}" == "" ]] && [[ "${patch_json}" == "" ]] ;then success="true"; fi; fi; fi;; "~") if [[ "${version_part_count}" != "3" ]];then echo "No way"; exit; fi; if [[ "${major_actual}" -ne "${major_json}" ]] || [[ "${minor_actual}" -ne "${minor_json}" ]];then echo "No way"; exit; elif [[ "${patch_actual}" -ge "${patch_json}" ]];then success="true"; fi;; ">") if [[ ${json_value:1:1} == "=" ]];then if [[ "${major_actual}" -gt "${major_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -gt "${minor_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -eq "${minor_json}" ]] && [[ "${patch_actual}" -ge "${patch_json}" ]];then success="true"; fi; else if [[ "${major_actual}" -gt "${major_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -gt "${minor_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -eq "${minor_json}" ]] && [[ "${patch_actual}" -gt "${patch_json}" ]];then success="true"; fi; fi;; "<") if [[ ${json_value:1:1} == "=" ]];then if [[ "${major_actual}" -lt "${major_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -le "${minor_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -eq "${minor_json}" ]] && [[ "${patch_actual}" -le "${patch_json}" ]];then success="true"; fi; else if [[ "${major_actual}" -lt "${major_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -lt "${minor_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -eq "${minor_json}" ]] && [[ "${patch_actual}" -lt "${patch_json}" ]];then success="true"; fi; fi;; "*") success="true";; "l") latest_version=""; which apt > /dev/null 2>&1; if [[ ${?} == 0 ]];then latest_version=$(apt info ${dependency} 2>/dev/null); else latest_version=$(yum info ${dependency} 2>/dev/null); fi; version_latest=$(f_dependency_actual_cleaner "${latest_version}" "basic"); if [[ "${major_actual}" -gt "${major_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -gt "${minor_json}" ]];then success="true"; elif [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -eq "${minor_json}" ]] && [[ "${patch_actual}" -ge "${patch_json}" ]];then success="true"; fi;; ?) if [[ "${major_actual}" -eq "${major_json}" ]] && [[ "${minor_actual}" -eq "${minor_json}" ]] && [[ "${patch_actual}" -eq "${patch_json}" ]];then success="true"; fi;; esac; if [[ ${actual_value} == "0.0.0" ]];then actual_value="unknown"; fi; if [[ ${source} == "framework" ]];then A_dependency_checked["${dependency}"]=${success}; A_dependency_installed["${dependency}"]=${actual_value}; elif [[ ${source} == "project" ]];then A_dependency_checked_project["${dependency}"]=${success}; A_dependency_installed_project["${dependency}"]=${actual_value}; if [[ "${project_subcategory}" == *"project_dependencies_make"* ]];then A_dependency_checked_project_make["${dependency}"]=${success}; A_dependency_installed_project_make["${dependency}"]=${actual_value}; elif [[ "${project_subcategory}" == *"project_dependencies_execute"* ]];then A_dependency_checked_project_execute["${dependency}"]=${success}; A_dependency_installed_project_execute["${dependency}"]=${actual_value}; fi; fi; };  f_dependency_version_json(){ local source; local length; local lastIndex; local count; source="${1}"; if [[ ${source} == "framework" ]];then vf_metadata_string+='"framework_dependencies":{'; f_dependency_array_copy A_dependency_checked checked; f_dependency_array_copy A_dependency_installed installed; elif [[ ${source} == "project_make" ]];then vf_metadata_string+='"project_dependencies":{"make":{'; f_dependency_array_copy A_dependency_checked_project_make pmchecked; f_dependency_array_copy A_dependency_installed_project_make pminstalled; elif [[ ${source} == "project_execute" ]];then vf_metadata_string+='"execute":{'; f_dependency_array_copy A_dependency_checked_project_execute pechecked; f_dependency_array_copy A_dependency_installed_project_execute peinstalled; fi; length=${#installed[@]}; lastIndex=$(( ${length} - 1 )); count=0; if [[ ${source} == "framework" ]];then length=${#installed[@]}; lastIndex=$(( ${length} - 1 )); count=0; for i in "${!installed[@]}" ; do vf_metadata_string+="\"$i\":{ \"meet_requirement\": \"${checked[$i]}\", \"installed_version\": \"${installed[$i]}\" }"; if [[ $count != $lastIndex ]];then vf_metadata_string+=','; fi; count=$((count + "1")); done; vf_metadata_string+='}'; elif [[ ${source} == "project_make" ]];then length=${#pminstalled[@]}; lastIndex=$(( ${length} - 1 )); count=0; for i in "${!pminstalled[@]}" ; do vf_metadata_string+="\"$i\":{ \"meet_requirement\": \"${pmchecked[$i]}\", \"installed_version\": \"${pminstalled[$i]}\" }"; if [[ $count != $lastIndex ]];then vf_metadata_string+=','; fi; count=$((count + "1")); done; vf_metadata_string+='}'; elif [[ ${source} == "project_execute" ]];then length=${#peinstalled[@]}; lastIndex=$(( ${length} - 1 )); count=0; for i in "${!peinstalled[@]}" ; do vf_metadata_string+="\"$i\":{ \"meet_requirement\": \"${pechecked[$i]}\", \"installed_version\": \"${peinstalled[$i]}\" }"; if [[ $count != $lastIndex ]];then vf_metadata_string+=','; fi; count=$((count + "1")); done; vf_metadata_string+='}'; vf_metadata_string+='}'; fi; };  f_dependency_version_text(){     local source; source="${1}"; if [[ ${source} == "framework" ]];then         vf_metadata_string+='"framework_dependency":{'; f_dependency_array_copy A_dependency_checked A_checked; f_dependency_array_copy A_dependency_installed A_installed; elif [[ ${source} == "project" ]];then         vf_metadata_string+='"project_dependency":{'; f_dependency_array_copy A_dependency_checked_project A_checked; f_dependency_array_copy A_dependency_installed_project A_installed; fi; for i in "${!A_checked[@]}"; do         printf "%b\n" "dependency: $i"; printf "%b\n" "meet_requirement: ${A_checked[$i]}"; printf "%b\n" "installed_version: ${A_installed[$i]}"; done; };  f_display_banner(){ if [[ "${vf_framework_flags_display_color}" == "true" ]];then printf "%b\n" "${cl}"; fi; ${equalsLine}; ${spacer}; printf "%b\n" "${cyB}██████   █████  ███████ ██   ██       ██   ██ "; printf "%b\n" "${rdB}██   ██ ██   ██ ██      ██   ██        ██ ██  "; printf "%b\n" "${ylB}██████  ███████ ███████ ███████ █████   ███   "; printf "%b\n" "${grB}██   ██ ██   ██      ██ ██   ██        ██ ██  ${rs}"; printf "%b\n" "${bold}██████  ██   ██ ███████ ██   ██       ██   ██ ${rs}"; ${spacer}; ${equalsLine}; printf "%b\n" "${yl}--> Framework name:${cy}       ${vj_framework_name}"; printf "%b\n" "${yl}--> About:${cy}                A lightweight SRE framework${rs}"; printf "%b\n" "${yl}--> Framework repo:${cy}       ${vj_framework_repo}${rs}"; printf "%b\n" "${yl}--> Git branch:${cy}           ${vf_git_branch}${rs}"; printf "%b\n" "${yl}--> Version:${cy}              ${vj_framework_version}${rs}"; printf "%b\n" "${yl}--> Framework Path:${cy}       ${vf_path_framework_home}${rs}"; printf "%b\n" "${yl}--> Framework settings:${cy}   ${vf_path_framework_home}json/framework.json${rs}"; ${equalsLine}; };  f_display_colors(){ local param1; param1=${1}; dashLine=$(printf   "%s\n" "printf %b\n     "${rs}------------------------------------------------------------""); plusLine=$(printf   "%s\n" "printf %b\n     "${rs}++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++""); equalsLine=$(printf "%s\n" "printf %b\n     "${rs}============================================================""); tick=$(tput setaf 2 && printf "\xE2\x9C\x94" && tput sgr0); spacer=$(printf "%s\n" "printf %s\n """); if [[ "${param1}" == "true" ]];then     rs="$(tput init)"; cl="$(tput clear && printf '\e[2J\e[3J\e[H')"; bk="$(tput setaf 0)"; rd="$(tput setaf 1)"; gr="$(tput setaf 2)"; yl="$(tput setaf 3)"; bl="$(tput setaf 4)"; mg="$(tput setaf 5)"; cy="$(tput setaf 6)"; wh="$(tput setaf 7)"; bkB="$(tput bold; tput setaf 0)"; rdB="$(tput bold; tput setaf 1)"; grB="$(tput bold; tput setaf 2)"; ylB="$(tput bold; tput setaf 3)"; blB="$(tput bold; tput setaf 4)"; mgB="$(tput bold; tput setaf 5)"; cyB="$(tput bold; tput setaf 6)"; whB="$(tput bold; tput setaf 7)"; bold="$(tput bold)"; else     bk=""; rd=""; gr=""; yl=""; bl=""; mg=""; cy=""; wh=""; bkB=""; blB=""; cyB=""; grB=""; rdB=""; ylB=""; whB=""; fi; };  f_display_help_framework(){ ${spacer}; printf "%b\n" "${cyB}Help page for bash-x.${rs}"; ${spacer}; ${equalsLine}; printf "\n%b\n" "${cyB}Flags (-short --long)${rs}                  About                                              ${yl}Defaults${rs} (as defined in framework.json)"; ${equalsLine}; printf "%b\n" "Note: to namespace from project flags, all framework flags are CAPITALISED."; ${spacer}; printf "%s\t\t%s\n"   "${cy}-AA          --AUTHAPPROACH    ${cy}        How to connect to remote servers                   ${yl}${vj_framework_flags_ssh_approach}${rs}"            ${cy}"Either 'user_pass','user_key','user_pass_key' or 'cicd_user_pass'"; printf "%s\t\t\t%s\n" "${rs}-CD          --COLORDISPLAY    ${rs}        Display output using colors                        ${yl}${vj_framework_flags_display_color}${rs}"           ${rs}"Either 'true' or 'false'."; printf "%s\t\t\t%s\n" "${cy}-H           --HELP            ${cy}        This menu + list of locally available projects     ${yl}n/a${rs}"                                           ${cy}"Just pass the flag to set to true. No argument required.".; printf "%s\t\t\t%s\n" "${rs}-I           --INSPECT         ${rs}        Get metadata about machine + verify dependencies   ${yl}${vj_framework_flags_tools_inspect}${rs}"           ${rs}"Either 'json' or 'text'."; printf "%s\t\t\t%s\n" "${cy}-FF          --FASTFAIL        ${cy}        Exit project on first failure                      ${yl}${vj_framework_flags_behaviour_fastfail}${rs}"      ${cy}"Just pass the flag to set to true. No argument required."; printf "%s\t\t\t%s\n" "${rs}-L           --LIMIT           ${rs}        Run project on a subset of servers                 ${yl}${vj_framework_flags_behaviour_limit}${rs}"         ${rs}"Regex matches exactly on hostname or on pattern. See example below."; printf "%s\t\t\t%s\n" "${cy}-MF          --MINFRAMEWORK    ${cy}        Minimise framework code into single file           ${yl}n/a${rs}"                                           ${cy}"Just pass the flag to set to true. No argument required."; printf "%s\t\t\t%s\n" "${rs}-MP          --MINPROJECT      ${rs}        Minimise project code into single file             ${yl}n/a${rs}"                                           ${rs}"Just pass the flag to set to true. Requires a specified project to preceed it."; printf "%s\t%s\n"     "${cy}-P           --PROJECT         ${cy}        The name of the project to run                     ${yl}\"project-name\"${rs}"                              ${cy}"Locally 'installed' projects are listed below."; printf "%s\t\t\t%s\n" "${rs}-DC          --REMOTECOMPUTE   ${rs}        Distribute project compute to remote servers       ${yl}${vj_framework_flags_behaviour_remotecompute}${rs}" ${rs}"Special flag for projects to implement, not meant for end-users."; printf "%s\t\t\t%s\n" "${cy}-S           --SETUP           ${cy}        Prepare local machine to run bash-x                ${yl}n/a${rs}"                                           ${cy}"Just pass the flag to set to true. No argument required."; printf "%s\t\t\t%s\n" "${rs}-SK          --SKELETON        ${rs}        For development, create a template project.        ${yl}${vj_framework_flags_tools_skeleton}${rs}"          ${rs}"Creates a named project folder with templated files. No argument required."; printf "%s\t\t%s\n"   "${cy}-SS          --SKIPSTAGES      ${cy}        Do no run the stage(s). Take care when using!      ${yl}\"1,2,3\"${rs}"                                     ${cy}"The effect is project dependent, see example usage below."; printf "%s\t\t%s\n"   "${rs}-SSHI        --SSHINTERFACE    ${rs}        Which server interface to connect to               ${yl}${vj_framework_flags_ssh_interface}${rs}"           ${rs}"The interface is specified in the inventory.json"; printf "%s\t\t%s\n"   "${cy}-SSHKP       --SSHKEYPATH      ${cy}        The local path to the ssh key for connections      ${yl}${vj_framework_flags_ssh_keypath}${rs}"             ${cy}"A path that may start with '~/' (resolved to \${HOME})"; printf "%s\t\t%s\n"   "${rs}-SSHTP       --SSHTARGETPATH   ${rs}        The remote path to where ssh connects              ${yl}${vj_framework_flags_ssh_targetpath}${rs}"          ${rs}"A path that may start with '~/' (resolved to \${HOME})"; printf "%s\t\t%s\n"   "${cy}-SSHU        --SSHUSER         ${cy}        The remote user account for ssh connections        ${yl}${vj_framework_flags_ssh_user}${rs}"                ${cy}"A valid remote account that can be logged into."; printf "%s\t\t\t%s\n" "${rs}-TU          --TIDYUP          ${rs}        Remove bash-x framework from remote servers        ${yl}${vj_framework_flags_behaviour_tidyup}${rs}"        ${rs}"Valid SSH credentials and SSHTARGETPATH for bash-x framework."; printf "%s\t\t\t%s\n" "${cy}-TR          --TRACE           ${cy}        Add detailed tracing to sub process logs           ${yl}${vj_framework_flags_behaviour_trace}${rs}"         ${cy}"Just pass the flag to set to true. No argument required."; printf "\n%b\n" "${cyB}Example usage:${rs}"; ${equalsLine}; printf "%b\n" "Note: if used, the '--PROJECT' flag must be passed first."; ${spacer}; printf "%b\n" "${yl}$ bash-x ${rs}                                         // No flag defaults to the --HELP flag."; printf "%b\n" "${yl}$ bash-x --PROJECT name-of-project -H ${rs}            // Show the help menu for a named project."; printf "%b\n" "${yl}$ bash-x -P name-of-project -CD false ${rs}            // Run a project with display colors turned off."; printf "%b\n" "${yl}$ bash-x --INSPECT text ${rs}                          // Inspect local machine with output as text (not json)."; printf "%b\n" "${yl}$ bash-x --SETUP ${rs}                                 // Check machine is ready to run framework."; printf "%b\n" "${yl}$ bash-x --FASTFAIL ${rs}                              // Exit project on first failure."; printf "%b\n" "${yl}$ bash-x --SKELETON ${rs}                              // Create a templated project skeleton."; printf "%b\n" "${yl}$ bash-x -P name-of-project -L \"stag11,stag12\" ${rs}   // Comma separate the servers where the application should run."; printf "%b\n" "${yl}$ bash-x -P name-of-project -L \"stag1,stag21\" ${rs}    // Pattern match example: cluster1 servers and stag21 in cluster2."; printf "%b\n" "${yl}$ bash-x -P name-of-project -SS \"1,2,3\" ${rs}          // Comma separate the stages that will not be run. Take care to include dependent stages!"; ${equalsLine}; printf "\n%b\n" "${cyB}Local projects in:${rs} ${yl}${vf_path_projects} ${rs}"; ${equalsLine}; output=$(ls ${vf_path_projects} 2>/dev/null) && availableProjects=$(echo "$output" | grep -v "README*"); if [[ "${?}" == "1" ]];then     printf "%b\n" "${yl}--> ${rs}The path to the 'bash-x-projects' folder cannot be found."; printf "%b\n" "${yl}--> ${rs}Please check the 'projectspath' flag in the framework.json"; elif [[ "${availableProjects}" == "" ]];then     printf "%b\n" "${yl}--> ${rs}The specified 'bash-x-projects' folder is empty."; printf "%b\n" "${yl}--> ${rs}Go get some projects!"; else     printf "%s\n" "${availableProjects}"; fi; ${spacer}; printf "%b\n" "${ylB}See framework README.md for more information.${rs}"; ${spacer}; };  f_display_help_project(){ ${spacer}; printf "%b\n" "${cyB}Project help page.${rs}"; ${spacer}; ${equalsLine}; printf "%b\n" "${yl}--> Project name:${cy}         ${vj_project_name}"; printf "%b\n" "${yl}--> Description:${cy}          ${vp_project_description}"; printf "%b\n" "${yl}--> Version:${cy}              ${vp_project_version}"; printf "%b\n" "${yl}--> Repo:${cy}                 ${vp_project_repo}"; printf "%b\n" "${yl}--> Project stages:${cy}       ${vp_project_rootpath}json/project/project.json"; printf "%b\n" "${yl}--> Project flags:${cy}        ${vp_project_rootpath}json/project/help.json"; printf "%b\n" "${yl}--> Project error codes:${cy}  ${vp_project_rootpath}json/project/errors.json"; printf "%b\n" "${yl}--> Project arrays:${cy}       ${vp_project_rootpath}json/project/arrays.json${rs}"; ${spacer}; printf '%s\t\t %s\t\t\t\t\t\t\t %s\n' "${cy}Flags (-short --long)${rs}" "${wh}About${rs}" "${yl}Defaults${rs} (as defined in the project's help.json)"; ${equalsLine}; for i in ${!A_json_help[@]} ; do     string="vj_help_flags_"; charcount=$(f_utils_strings "count_chars" "${i}" "_"); stem=$(echo ${i} | ${vf_cmd_sed} 's/_[^_]*$//'); if [[ "${i}" == *"${string}"* ]] && [[ "${charcount}" -eq 4 ]] && [[ "${done_array[*]}" != *"${stem}"* ]];then          longflag="$(echo ${i} | cut -f 4 -d_)"; shortflag="${A_json_help[${stem}_shortflag]}"; about="${A_json_help[${stem}_about]}"; default="${A_json_help[${stem}_default]}"; printf '%s\t %-35s\t %-50s\t %s\n' "${cy}-${shortflag}" "--${longflag}${rs}" "${about}" "${yl}${default}${rs}"; done_array+=( "${stem}" ); fi; done; printf "\n%b\n" "${cyB}Example usage.${rs}"; ${equalsLine}; flag_count="1"; while :; do     string="vj_help_usage_usage${flag_count}"; if [[ "${A_json_help[${string}_description]}" == "" ]];then break; fi; description="${A_json_help[${string}_description]}"; example="${A_json_help[${string}_example]}"; printf "%s\n" "${yl}[${flag_count}] ${description}${rs}"; printf "%b\n\n" "$ ${example}"; flag_count=$((flag_count+1)); done; f_stages_display_schedule; ${spacer}; };  f_errors_codes(){ A_framework_stage_errcodes["bashx"]="Critical framework error,${vf_dynamic_error_msg}"; A_framework_stage_errcodes["framework_flags"]="Badly passed flags,${vf_dynamic_error_msg}"; A_framework_stage_errcodes["project_json"]="Missing project json file!,${vf_dynamic_error_msg}"; A_framework_stage_errcodes["authentication"]="Authentication error!,${vf_dynamic_error_msg}"; };  f_errors_count(){ local stage_number; local count; local pid_stage_exitcode; local pid; local stage; local exitcode; local array_stage_exitcode; stage_number="${1}"; count="0"; for pid_stage_exitcode in ${!A_project_stage_errors[@]}; do     pid=$(echo ${pid_stage_exitcode}      | cut -d ',' -f1); stage=$(echo ${pid_stage_exitcode}    | cut -d ',' -f2); exitcode=$(echo ${pid_stage_exitcode} | cut -d ',' -f3); array_stage_exitcode="vj_errors_s${stage}_e${exitcode}"; if [[ "${stage}" == "${stage_number}" ]]; then         ((count++)); fi; done; printf "${count}"; };  f_errors_exitmessages(){ local exitlocation; local errcode; local pid; local message_string; local hint_string; exitlocation="${1}"; errcode="${2}"; pid="${3}"; if [[ "${pid}" == "" ]]; then pid="nopid"; fi; message_string="vj_errors_s${vp_stage_number}_e${errcode}_message"; hint_string="vj_errors_s${vp_stage_number}_e${errcode}_hint"; f_arrays_set_var "vf_status_exitlocation" "${exitlocation}"; f_arrays_set_var "vf_status_exitcode"     "${errcode}"; f_arrays_set_var "vf_status_stackTrace"   "$(for i in ${!FUNCNAME[@]}; do printf "%s" "${FUNCNAME[$i]},"; done;)"; f_arrays_set_var "vf_status_exitmessage"  "$(echo ${!message_string})"; f_arrays_set_var "vf_status_exithint"     "$(echo ${!hint_string})"; A_project_stage_errors["${pid},${vp_stage_number},${vf_status_exitcode}"]="${vf_status_exitmessage},${vf_status_exithint}"; if [[ "${vf_framework_flags_behaviour_fastfail}" == "true" ]];then f_stages_functions_final; fi; };  f_errors_exitmessages_framework(){ local exitlocation; local errcode; local message_string; local hint_string; exitlocation="${1}"; errcode="${2}"; f_errors_codes; message_string="$(echo ${A_framework_stage_errcodes[${errcode}]} | cut -d ',' -f1)"; hint_string="$(echo    ${A_framework_stage_errcodes[${errcode}]} | cut -d ',' -f2)"; if [[ ${hint_string} == "vf_"* ]] || [[ ${hint_string} == "vp_"* ]] ||    [[ ${hint_string} == "vj_"* ]] || [[ ${hint_string} == **"USER"** ]]; then vf_status_exithint=${!hint_string}; fi; final_exitcode=1; if [[ "${vf_framework_flags_display_color}" == "true" ]];then    f_display_colors "true"; else    f_display_colors "false"; fi; f_display_banner; printf "\n"; printf "%b\n" "${rdB}--> Framework failure:${rs}"; printf "%b\n" "${yl}--> Info - Duration:            ${rs}$(f_utils_time "script_duration")s"; printf "%b\n" "${yl}--> Info - Message:             ${rs}${message_string}"; printf "%b\n" "${yl}--> Info - Hint:                ${rs}${hint_string}"; printf "%b\n" "${yl}--> Info - Framework-err-code:  ${rs}${errcode}"; printf "%b\n" "${yl}--> Info - Exit-code:           ${rs}${final_exitcode}"; if [[ "${exitlocation}" != "" ]]; then     printf "%b\n" "${yl}--> Info - Where:               ${rs}${exitlocation}"; fi; printf "\n"; function_trace=$(for i in ${!FUNCNAME[@]}; do printf "%s" "${FUNCNAME[$i]},"; done;); if [[ "${function_trace}" != "" ]]; then     printf "%s\n" "============================================================"; printf "\n"; printf "%b\n" "${yl}--> Info - Function trace:${rs}"; IFS=',' read -r -a array <<< "${function_trace}"; count=0; for i in "${array[@]}"; do         printf "%b\n" "${cy}Level:    ${rs}${count}"; printf "%s\n" "${i}"; ((count=count+1)); done; printf "\n"; printf "%s\n" "============================================================"; printf "\n"; fi; exit ${final_exitcode}; };  f_framework(){ if [[ "${1}" != "-P" ]]  && [[ "${1}" != "--PROJECT" ]] && [[ "${1}" != "-H" ]]  && [[ "${1}" != "--HELP" ]] && [[ "${1}" != "-I" ]]  && [[ "${1}" != "--INSPECT" ]] && [[ "${1}" != "-S" ]]  && [[ "${1}" != "--SETUP" ]] && [[ "${1}" != "-SK" ]] && [[ "${1}" != "--SKELETON" ]] && [[ "${1}" != "-MF" ]] && [[ "${1}" != "--MINFRAMEWORK" ]] && [[ "${1}" != "-MP" ]] && [[ "${1}" != "--MINPROJECT" ]] && [[ "${1}" != "" ]]; then   f_display_colors "true"; f_arrays_set_var "vf_dynamic_error_msg" "Wrong flag or flag order with: ${vf_args_passed}"; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "framework_flags"; fi; if [[ "${#}" -gt 0 ]]; then   while test $# -gt 0; do  case "$1" in     -AA|--AUTHAPPROACH) shift; f_arrays_set_var "vf_framework_flags_ssh_approach" "${1}"; shift;; -CD|--COLORDISPLAY) shift; f_arrays_set_var "vf_framework_flags_display_color" "${1}"; if [[ "${vf_framework_flags_display_color}" != "true" ]];then f_display_colors "false"; fi; shift;; -FF|--FASTFAIL) f_arrays_set_var "vf_framework_flags_behaviour_fastfail" "true"; shift;; -H|--HELP) f_arrays_set_var "vf_framework_flags_help" "true"; shift;; -I|--INSPECT) f_arrays_set_var "vf_framework_flags_tools_inspect" "true"; shift;; -L|--LIMIT) shift; f_arrays_set_var "vf_framework_flags_behaviour_limit" "${1}"; if [[ "${vf_framework_flags_behaviour_limit}" == "" ]];then          f_arrays_set_var "vf_framework_flags_behaviour_limit" "false"; else           a_limit=(${vf_framework_flags_behaviour_limit//,/ }); fi; shift;; -MF|--MINFRAMEWORK) f_arrays_set_var "vf_framework_flags_tools_minframework" "true"; if [[ "${vf_bashx_minified}" == "true" ]];then         f_display_colors "true"; printf "%b\n" "${yl}--> Info - ${rs}Exiting as the '--MINFRAMEWORK' flag is reserved for ${cy}bash-x-dev${rs}."; exit 1; fi; shift;; -MP|--MINPROJECT) f_arrays_set_var "vf_framework_flags_tools_minproject" "true"; shift;; -P|--PROJECT) shift; f_arrays_set_var "vp_project_name" "${1}"; f_arrays_set_var "vp_project_rootpath" "${vf_path_projects}${vp_project_name}/"; f_arrays_set_var "vp_stage_number" "0"; if [[ "${vp_project_name}" == "" ]] || [[ ! -d "${vp_project_rootpath}" ]];then         f_arrays_set_var "vf_dynamic_error_msg" "Bad project rootpath: ${vp_project_rootpath}"; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "framework_flags"; elif [[ ! -f "${vp_project_rootpath}lib/fp_project_start" ]] && [[ ! -f "${vp_project_rootpath}${vp_project_name}" ]];then         f_arrays_set_var "vf_dynamic_error_msg" "Project code not found using this path: ${vp_project_rootpath}${vp_project_name}"; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "framework_flags"; else         if [[ "${vp_project_name}" == *".min"* ]];then           source "${vp_project_rootpath}${vp_project_name}"; else           filesToSource="$(find ${vp_project_rootpath}lib -type f ! -name "*.json")"; for file in $(printf "%s\n" "$filesToSource"); do             [ -f $file ] && . $file; done; fi; f_check_project_json_exist; if [[ "${vf_args_passed}" == *"-H"* ]] || [[ "${vf_args_passed}" == *"--HELP"* ]];then           f_display_colors "true"; printf "%b\n" "${yl}--> Info - ${rs}Generating --HELP screen for project: ${cy}${vp_project_name}${rs}"; elif [[ "${vf_args_passed}" == *"-MP"* ]] || [[ "${vf_args_passed}" == *"--MINPROJECT"* ]];then           f_display_colors "true"; printf "%b\n" "${yl}--> Info - ${rs}Generating minimised version of project: ${cy}${vp_project_name}${rs}"; elif [[ "${vf_args_passed}" == *"-I"* ]] || [[ "${vf_args_passed}" == *"--INSPECT"* ]];then           f_display_colors "true"; printf "%b\n" "${yl}--> Info - ${rs}Generating json inspection for project: ${cy}${vp_project_name}${rs}"; else           f_display_colors "true"; printf "%b\n" "${yl}--> Info - ${rs}Reading the json files for project: ${cy}${vp_project_name}${rs}"; fi; if [[ "${vf_args_passed}" == *"-I"* ]] || [[ "${vf_args_passed}" == *"--INSPECT"* ]];then           project_json_file="${vp_project_rootpath}json/project/project.json"; printf "%b\n" "--> [1/1]: ${rs}Processing ${project_json_file}"; if [ $(cat "${project_json_file}" | ${jq} empty > /dev/null 2>&1; echo $?) -ne 0 ]; then               echo "Bad json in: ${json_file}!"               exit 1; else               f_json_recurse "$(cat ${project_json_file})" "vj"; f_arrays_declare_vars "json_project"; fi; elif [[ "${vf_args_passed}" == *"-MP"* ]] || [[ "${vf_args_passed}" == *"--MINPROJECT"* ]];then           :; else           f_json_project_process; fi; for key in "${!A_json_arrays[@]}"         ; do           array_name=$(f_utils_strings_bpe "del_fromleft_upto_including" "${key}" "arrays_index_"); if [[ "${key}" == *"_name" ]] && [[ "${key}" == *"arrays_keypair"* ]];then             value=${A_json_arrays[${key}]}; declare -A "A_${value}"; elif [[ "${key}" == *"_name" ]] && [[ "${key}" == *"arrays_index"* ]];then             value=${A_json_arrays[${key}]}; declare -a "a_${value}"; fi; done; mkdir -p "${vp_project_rootpath}input_output"; fi; shift;; -RC|--REMOTECOMPUTE) f_arrays_set_var "vf_framework_flags_behaviour_remotecompute" "true"; shift;; -SK|--SKELETON) f_arrays_set_var "vf_framework_flags_tools_skeleton" "true"; shift;; -SS|--SKIPSTAGES) shift; f_arrays_set_var "vf_framework_flags_behaviour_skipstages" "${1}"; if [[ "${vf_framework_flags_behaviour_skipstages}" == "" ]];then          f_arrays_set_var "vf_framework_flags_behaviour_skipstages" "false"; else           a_skipstages=(${vf_framework_flags_behaviour_skipstages//,/ }); fi; shift;; -SSHI|--SSHINTERFACE) shift; f_arrays_set_var "vf_framework_flags_ssh_interface" "${1}"; shift;; -SSHKP|--SSHKEYPATH) shift; f_arrays_set_var "vf_framework_flags_ssh_keypath" "${1}"; shift;; -SSHPP|--SSHPASSPATH) shift; f_arrays_set_var "vf_framework_flags_ssh_passpath" "${1}"; shift;; -SSHTP|--SSHTARGETPATH) shift; f_arrays_set_var "vf_framework_flags_ssh_targetpath" "${1}"; shift;; -SSHU|--SSHUSER) shift; f_arrays_set_var "vf_framework_flags_ssh_user" "${1}"; shift;; -TU|--TIDYUP) shift; f_arrays_set_var "vf_framework_flags_behaviour_tidyup" "${1}"; shift;; -TR|--TRACE) f_arrays_set_var "vf_framework_flags_behaviour_trace" "true"; shift;; *) vf_flag_current="${1}"; vf_flag_current_value=$(shift && echo "${1}"); f_check_project_flags; shift; shift;; esac; done; else   f_arrays_set_var "vf_framework_flags_help" "true"; fi; f_arrays_paths_clean_framework; if [[ "${vf_framework_flags_authapproach}" != "false" ]] && [[ "${vf_framework_flags_behaviour_remotecompute}" != "true" ]];then   f_auth; fi; count=1; while :; do     stage="vp_project_stages_s${count}"; stage_title="${stage}_title"; title="${A_project_vars[${stage_title}]}"; if [[ -z "${title}" ]]; then         count=$((count-1)); break; fi; count=$((count+1)); done; f_arrays_set_var "vp_stage_count" "${count}"; if [[ "${vf_framework_flags_display_color}" == "true" ]];then    f_display_colors "true"; else    f_display_colors "false"; fi; if [[ "${vf_framework_flags_tools_inspect}" == "true" ]];then   f_dependency_step1 "true"; exit 0; fi; f_display_banner; if [[ "${vf_framework_flags_help}" == "true"  ]];then   if [[ "${vp_project_name}" == "" ]];then     f_display_help_framework; else     f_display_help_project; f_arrays_set_var "vp_stage_number" "HELP"; fp_project_custom_runorder; fi; exit 0; fi; if [[ "${vf_framework_flags_tools_skeleton}" == "true"  ]];then   f_skeleton; exit 0; fi; if [[ "${vf_framework_flags_tools_minframework}" == "true"  ]];then   f_minimise_framework; exit 0; fi; if [[ "${vf_framework_flags_tools_minproject}" == "true"  ]];then   f_minimise_project; exit 0; fi; if [[ "${vf_framework_flags_behaviour_remotecompute}" == "true" ]]; then   fp_project_start_remote; else   fp_project_start; fi; };  f_json_project_process(){ local project_json_folder; local json_file; project_json_folder="${vp_project_rootpath}json/project/"; json_file="${project_json_folder}arrays.json"; printf "%b\n" "--> [1/4]: ${rs}Processing ${json_file}"; if [ $(cat "${json_file}" | ${jq} empty > /dev/null 2>&1; echo $?) -ne 0 ]; then     echo "Bad json in: ${json_file}!"     exit 1; else     f_json_recurse "$(cat ${json_file})" ""; fi; json_file="${project_json_folder}project.json"; printf "%b\n" "--> [2/4]: ${rs}Processing ${json_file}"; if [ $(cat "${json_file}" | ${jq} empty > /dev/null 2>&1; echo $?) -ne 0 ]; then     echo "Bad json in: ${json_file}!"     exit 1; else     f_json_recurse "$(cat ${json_file})" "vj"; f_arrays_declare_vars "json_project"; fi; json_file="${project_json_folder}help.json"; printf "%b\n" "--> [3/4]: ${rs}Processing ${json_file}"; if [ $(cat "${json_file}" | ${jq} empty > /dev/null 2>&1; echo $?) -ne 0 ]; then     echo "Bad json in: ${json_file}!"     exit 1; else     f_json_recurse "$(cat ${json_file})" "vj"; f_arrays_declare_vars "json_help"; fi; json_file="${project_json_folder}errors.json"; printf "%b\n" "--> [4/4]: ${rs}Processing ${json_file}"; if [ $(cat "${json_file}" | ${jq} empty > /dev/null 2>&1; echo $?) -ne 0 ]; then     echo "Bad json in: ${json_file}!"     exit 1; else     f_json_recurse "$(cat ${json_file})" "vj"; f_arrays_declare_vars "json_errors"; fi; };  f_json_recurse(){ local json_content; local key_prefix; local input_params_count; local key_lineage; local json_pair_keyvalue; local json_pair_key; local key_current; local value_type; json_content="${1}"; key_prefix="${2}"; input_params_count="${#}"; json_content_map=$(${jq} -r "to_entries|map(\"\(.key)=\(.value|tostring)\")|.[]" <<< "${json_content}"); if [[ "${input_params_count}" -lt 3 ]]; then key_lineage=""; else key_lineage="${2}"; fi; while read -r json_pair_keyvalue; do if [ -z "${json_pair_keyvalue}" ]; then break; fi; key_current=""; IFS== read json_pair_key json_pair_value <<< "${json_pair_keyvalue}"; if [ -z "${key_lineage}" ]; then if [[ "${key_prefix}" == "" ]]; then key_current="${json_pair_key}"; else key_current="${key_prefix}_${json_pair_key}"; fi; else key_current="${key_lineage}"_"${json_pair_key}"; fi; value_type=""; if [[ "${json_pair_value}" =~ ^[+-]?[0-9]+$ ]]; then value_type="integer"; elif [[ "${json_pair_value}" =~ ^[+-]?[0-9]+\.$ ]]; then value_type="string"; elif [[ "${json_pair_value}" =~ ^[+-]?[0-9]+\.?[0-9]*$ ]]; then value_type="float"; elif [[ "${json_pair_value}" =~ ^(true|false|True|False|TRUE|FALSE)$ ]]; then value_type="bool"; else value_type="string"; fi; if [[ "${value_type}" == "string" ]] && [[ "${json_pair_value}" == "" ]]; then value_type="integer"; fi; if ${jq} -e . >/dev/null 2>&1 <<< "${json_pair_value}" && [[ "${value_type}" != "float" ]] && [[ "${value_type}" != "integer" ]] && [[ "${value_type}" != "bool" ]]; then f_json_recurse "${json_pair_value}" "${key_current}" "dummy"; else case "${key_lineage}" in "vj_inventory"*) f_arrays_set_var "${key_current}" "${json_pair_value}"; key_current=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${key_current}" "_"); f_arrays_set_var "vp_${key_current}" "${json_pair_value}";; "vj_framework"*) f_arrays_set_var "${key_current}" "${json_pair_value}"; key_current=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${key_current}" "_"); f_arrays_set_var "vf_${key_current}" "${json_pair_value}";; "vj_project"*) f_arrays_set_var "${key_current}" "${json_pair_value}"; key_current=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${key_current}" "_"); f_arrays_set_var "vp_${key_current}" "${json_pair_value}";; "vj_help"*) A_json_help["${key_current}"]="${json_pair_value}"; if [[ "${key_current}" == *"_shortflag" ]] || [[ "${key_current}" == *"_about" ]] || [[ "${key_current}" == *"_type" ]];then key_current=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${key_current}" "_"); f_arrays_set_var "vp_${key_current}" "${json_pair_value}"; elif [[ "${key_current}" == *"_default" ]];then key_current=$(echo $key_current | ${vf_cmd_sed} 's|\(.*\)_.*|\1|'); f_arrays_set_var "${key_current}" "${json_pair_value}"; key_current=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "${key_current}" "_"); f_arrays_set_var "vp_${key_current}" "${json_pair_value}"; fi;; "vj_errors"*) A_json_errors["${key_current}"]="${json_pair_value}";; "arrays"*) A_json_arrays["${key_current}"]="${json_pair_value}";; *) fp_project_custom_json "${key_current}" "${json_pair_value}";; esac; fi; done <<< "${json_content_map}"; };  f_multipids_arrays(){ suffix="fp_multipids_create"; index="0"; if declare -F "${suffix}_S${vp_stage_number}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}_S${vp_stage_number}"; elif declare -F "${suffix}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}"; else a_multipds_runorder[${index}]="f_multipids_create"; fi; suffix="fp_multipids_display_details"; index="1"; if declare -F "${suffix}_S${vp_stage_number}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}_S${vp_stage_number}"; elif declare -F "${suffix}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}"; else a_multipds_runorder[${index}]="f_multipids_display_details"; fi; suffix="fp_multipids_wait"; index="2"; if declare -F "${suffix}_S${vp_stage_number}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}_S${vp_stage_number}"; elif declare -F "${suffix}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}"; else a_multipds_runorder[${index}]="f_multipids_wait"; fi; suffix="fp_multipids_display_success"; index="3"; if declare -F "${suffix}_S${vp_stage_number}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}_S${vp_stage_number}"; elif declare -F "${suffix}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}"; else a_multipds_runorder[${index}]="f_multipids_display_success"; fi; suffix="fp_multipids_display_fail"; index="4"; if declare -F "${suffix}_S${vp_stage_number}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}_S${vp_stage_number}"; elif declare -F "${suffix}" > /dev/null; then a_multipds_runorder[${index}]="${suffix}"; else a_multipds_runorder[${index}]="f_multipids_display_fail"; fi; };  f_multipids_create(){ local loop_source_hostname; local loop_source_domain; local loop_source_interface; local loop_source_pubIp; local loop_source_gateway; if [[ "${#A_tests_to_all[@]}" -eq "0" ]];then f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "2" ""; fi; for i in "${!A_tests_to_all[@]}" ; do source_hostname="$(echo ${A_tests_to_all[$i]} | cut -d ',' -f1)"; source_domain="$(echo ${A_tests_to_all[$i]} | cut -d ',' -f2)"; source_pubIp="$(echo ${A_tests_to_all[$i]} | cut -d ',' -f3)"; source_interface="$(echo ${A_tests_to_all[$i]} | cut -d ',' -f4)"; source_gateway="$(echo ${A_tests_to_all[$i]} | cut -d ',' -f5)"; source_parent="$(echo ${A_tests_to_all[$i]} | cut -d ',' -f6)"; ip_string="vj_inventory_servers_${source_parent}_service_${vf_framework_flags_ssh_interface}_${source_hostname}"; do_string="vj_inventory_servers_${source_parent}_service_${vf_framework_flags_ssh_interface}_domain"; gw_string="vj_inventory_servers_${source_parent}_service_${vf_framework_flags_ssh_interface}_gateway"; loop_source_pubIp="${A_variables_inventory[$ip_string]}"; loop_source_domain="${A_variables_inventory[$do_string]}"; loop_source_gateway="${A_variables_inventory[$gw_string]}"; A_loop_array["${source_hostname},${loop_source_domain},${vf_framework_flags_ssh_interface},${loop_source_pubIp}","${loop_source_gateway}"]=""; done; for i in "${!A_loop_array[@]}" ; do loop_source_hostname="$(echo ${i} | cut -d ',' -f1)"; loop_source_domain="$(echo ${i} | cut -d ',' -f2)"; loop_source_interface="$(echo ${i} | cut -d ',' -f3)"; loop_source_pubIp="$(echo ${i} | cut -d ',' -f4)"; loop_source_gateway="$(echo ${i} | cut -d ',' -f5)"; f_stages_functions >> "${vp_path_folder_timestamp_tests_logs_sublocal}${loop_source_hostname}.log" 2>&1 & pid=${!}; details="${loop_source_hostname},${loop_source_domain},${loop_source_interface},${loop_source_pubIp},${vp_stage_number}"; A_stage_pid_details["${pid}"]="${details}"; done; };  f_multipids_display_details(){ printf "\n%b\n" "${cyB}--> ${vp_stage_concurrentMsg_value}${rs}"; for i in "${!A_stage_pid_details[@]}" ; do     stageid="$(echo ${A_stage_pid_details[$i]} | cut -d ',' -f6)"; if [[ "${vp_stage_number}" == "${stageid}" ]];then             source_hostname="$(echo ${A_stage_pid_details[$i]}   | cut -d ',' -f1)"; source_domain="$(echo ${A_stage_pid_details[$i]}     | cut -d ',' -f2)"; source_interface="$(echo ${A_stage_pid_details[$i]}  | cut -d ',' -f3)"; source_pubIp="$(echo ${A_stage_pid_details[$i]}      | cut -d ',' -f4)"; source_gateway="$(echo ${A_stage_pid_details[$i]}    | cut -d ',' -f5)"; ${dashLine}; printf "%b\n" "${yl}--> Info - ${rs}PID:                 ${i}"; printf "%b\n" "${yl}--> Info - ${rs}Remote hostname:     ${source_hostname}"; printf "%b\n" "${yl}--> Info - ${rs}Remote pubIp:        ${source_pubIp}"; printf "%b\n" "${yl}--> Info - ${rs}Remote interface:    ${source_interface}"; printf "%b\n" "${yl}--> Info - ${rs}Remote folder:       ${SSH_PATH_TARGET}${vj_framework_name}"; fi; done; ${spacer}; printf "%b\n" "${cyB}--> Results to follow..${rs}"; };  f_multipids_display_fail(){ local count; local stageid; local source_hostname; local source_pubIp; local source_test; local source_interface; local json_code; local message; local hint; ${spacer}; printf "%b\n" "${rdB}--> Stage ${vp_stage_number} failed pids${rs}.."; count=0; for i in "${!A_stage_pid_fails[@]}" ; do     stageid="$(echo ${A_stage_pid_details[$i]} | cut -d ',' -f6)"; if [[ "${vp_stage_number}" == "${stageid}" ]];then          ((count++)); fi; done; if [[ ${#A_stage_pid_fails[@]} -ne 0 ]] && [[ ${count} -gt 0 ]];then     for i in "${!A_stage_pid_fails[@]}"     ; do         stageid="$(echo ${A_stage_pid_details[$i]} | cut -d ',' -f6)"; if [[ "${vp_stage_number}" == "${stageid}" ]];then                 source_hostname="$(echo ${A_stage_pid_details[$i]}   | cut -d ',' -f1)"; source_domain="$(echo ${A_stage_pid_details[$i]}     | cut -d ',' -f2)"; source_interface="$(echo ${A_stage_pid_details[$i]}  | cut -d ',' -f3)"; source_pubIp="$(echo ${A_stage_pid_details[$i]}      | cut -d ',' -f4)"; source_gateway="$(echo ${A_stage_pid_details[$i]}    | cut -d ',' -f5)"; json_code="$(echo vj_${A_stage_pid_fails[$i]}  | cut -d ',' -f1)"; message="$(echo ${A_stage_pid_fails[$i]}       | cut -d ',' -f2)"; hint="$(echo ${A_stage_pid_fails[$i]}          | cut -d ',' -f3)"; if [[ ${hint} == "vf_"* ]] || [[ ${hint} == "vp_"* ]] || [[ ${hint} == "vj_"* ]]; then hint=${!hint}; fi; ${dashLine}; printf "%b\n" "${yl}--> Info - ${rs}PID:                 ${i}"; printf "%b\n" "${yl}--> Info - ${rs}Remote hostname:     ${source_hostname}"; printf "%b\n" "${yl}--> Info - ${rs}Remote pubIp:        ${source_pubIp}"; printf "%b\n" "${yl}--> Info - ${rs}Remote interface:    ${source_interface}"; printf "%b\n" "${yl}--> Info - ${rs}error.json:          ${json_code}"; printf "%b\n" "${yl}--> Info - ${rs}Message:             ${message}"; printf "%b\n" "${yl}--> Info - ${rs}Hint:                ${hint}"; fi; done; else     printf "%b\n" "${yl}--> Info - ${rs}All pids were successful!"; fi; };  f_multipids_display_success(){ local count; local stageid; local pid; local source_hostname; local source_pubIp; local source_test; local source_interface; ${spacer}; printf "%b\n" "${grB}--> Stage ${vp_stage_number} successful pids${rs}.."; count=0; for pid in ${a_stage_pid_success[@]} ; do     stageid="$(echo ${pid} | cut -d '_' -f2)"; if [[ "${vp_stage_number}" == "${stageid}" ]];then         ((count++)); fi; done; if [[ ${count} -gt 0 ]];then     for pidstage in "${a_stage_pid_success[@]}"     ; do         pid="$(echo ${pidstage} | cut -d '_' -f1)"; stageid="$(echo ${pidstage} | cut -d '_' -f2)"; if [[ "${vp_stage_number}" == "${stageid}" ]];then              source_hostname="$(echo ${A_stage_pid_details[$i]}   | cut -d ',' -f1)"; source_domain="$(echo ${A_stage_pid_details[$i]}     | cut -d ',' -f2)"; source_interface="$(echo ${A_stage_pid_details[$i]}  | cut -d ',' -f3)"; source_pubIp="$(echo ${A_stage_pid_details[$i]}      | cut -d ',' -f4)"; source_gateway="$(echo ${A_stage_pid_details[$i]}    | cut -d ',' -f5)"; ${dashLine}; printf "%b\n" "${yl}--> Info - ${rs}PID:                 ${pid}"; printf "%b\n" "${yl}--> Info - ${rs}Remote hostname:     ${source_hostname}"; printf "%b\n" "${yl}--> Info - ${rs}Remote pubIp:        ${source_pubIp}"; printf "%b\n" "${yl}--> Info - ${rs}Remote interface:    ${source_interface}"; fi; done; else     printf "%b\n" "${yl}--> Info - ${rs} All pids failed!"; fi; };  f_multipids_wait(){ for p in "${!A_stage_pid_details[@]}" ; do stageid="$(echo ${A_stage_pid_details[$p]} | cut -d ',' -f6)"; if [[ "${vp_stage_number}" == "${stageid}" ]];then if wait $p; then errcode="${?}"; if [[ "${errcode}" == "0" ]];then a_stage_pid_success+=(${p}_${vp_stage_number}); else json_err_code="errors_s${vp_stage_number}_e${errcode}"; json_err_message="vj_${json_err_code}_message"; json_err_hint="vj_${json_err_code}_hint"; A_stage_pid_fails[$p]="${json_err_code},${!json_err_message},${!json_err_hint}"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${errcode}" "${p}"; fi; else errcode="${?}"; json_err_code="errors_s${vp_stage_number}_e${errcode}"; json_err_message="vj_${json_err_code}_message"; json_err_hint="vj_${json_err_code}_hint"; A_stage_pid_fails[$p]="${json_err_code},${!json_err_message},${!json_err_hint}"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${errcode}" "${p}"; fi; fi; done; }; f_remote_connectivity_permissions() { f_ssh_cmd "touch ${SSH_PATH_TARGET}bash-x.test && rm ${SSH_PATH_TARGET}bash-x.test" "1"; };  f_remote_copy_framework(){ f_ssh_scp_send "${vf_path_framework_home}" "${SSH_PATH_TARGET}bash-x" "4"; f_ssh_cmd "chmod -R 777 ${SSH_PATH_TARGET}bash-x" "6"; };  f_remote_copy_framework_project(){ f_remote_copy_framework; f_remote_copy_project; };  f_remote_copy_framework(){ f_ssh_scp_send "${vf_path_projects}${vp_project_name}" "${vf_framework_flags_ssh_targetpath}" "5"; };  f_remote_fetch_logs(){ f_ssh_scp_fetch "${vp_path_remote_logs}" "${vp_path_folder_timestamp_tests_logs_subremote}" "1"; };  f_remote_project_start(){ if [[ "${vf_bashx_minified}" == "true" ]];then f_ssh_cmd "${SSH_PATH_TARGET}bash-x ${vf_args_passed} --REMOTECOMPUTE"; else f_ssh_cmd "${SSH_PATH_TARGET}bash-x/lib/bash-x ${vf_args_passed} --REMOTECOMPUTE"; fi; };  f_remote_remove_folder(){ local result; local remote_path; remote_path="${1}"; if [[ "${remote_path}" == "" ]];then f_arrays_set_var "vf_framework_flags_behaviour_fastfail" "true"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "1"; fi; result=$(f_ssh_cmd "[[ -d ${remote_path} ]] && echo 0 || echo 1" "return_result"); if [[ "${result}" == "0" ]];then result=$(f_ssh_folder_actions "${remote_path}" "permission"); if [[ "${result}" == "0" ]];then result=$(f_ssh_folder_actions "${remote_path}" "delete"); if [[ "${result}" != "0" ]];then f_arrays_set_var "vp_dynamic_error_msg" "${remote_path}"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${result}"; exit "3"; fi; else f_arrays_set_var "vp_dynamic_error_msg" "${remote_path}"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${result}"; exit "2"; fi; elif [[ "${result}" == "255" ]];then f_arrays_set_var "vp_dynamic_error_msg" "${remote_path}"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${result}"; exit "1"; else echo "Folder path not present, skipping delete of: ${remote_path}"; fi; };  f_remote_remove_framework(){ f_remote_remove_folder "${SSH_PATH_TARGET}bash-x"; };  f_remote_remove_framework_project(){ f_remote_remove_framework; f_remote_remove_project; };  f_remote_remove_framework(){ f_remote_remove_folder "${SSH_PATH_TARGET}bash-x-projects"; };  f_setup(){ local brew_dependencies; local vf_architecture; local profiles; local source_needed; local used_profile; if [[ "${vf_os_identify}" == "Mac" ]]; then     ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step1 - ${rs}Checking framework packages:"; ${spacer}; vf_architecture=$(uname -m); if [[ "$vf_architecture" == *"arm64"* ]];then         brew_home=/opt/homebrew/bin; printf "%b\n" "${yl}--> Info - ${rs}${tick} This Mac has Apple silicon - will use correct jq package!"; else         brew_home=/usr/local/bin; printf "%b\n" "${yl}--> Info - ${rs}${tick} This Mac has Intel silicon - will use correct jq package!"; fi; which brew > /dev/null 2>&1; if [[ $? != 0 ]];then         printf "%b\n" "${yl}--> Info - ${rs}${tick} Installing Homebrew package manager.."; /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"; else         printf "%b\n" "${yl}--> Info - ${rs}${tick} Homebrew package manager is installed."; fi; brew_dependencies=( bash grep gawk gnu-sed coreutils jq ); for dependency in "${brew_dependencies[@]}"     ; do         brew list | grep -i ${dependency} > /dev/null 2>&1; if [[ $? != 0 ]];then             printf "%b\n" "${yl}--> Info - ${rs}${tick} Installing Homebrew package: ${dependency}"; brew install ${dependency}; else             printf "%b\n" "${yl}--> Info - ${rs}${tick} Homebrew package is installed: ${dependency}"; fi; done; fi; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step2 - ${rs}Checking local session profile:"; ${spacer}; if [[ "$SHELL" == *"zsh"* ]]; then     printf "%b\n" "${yl}--> Info - ${rs}${tick} The default shell is: zsh"; profiles=( ~/.zshrc ~/.zprofile ~/.zshenv ); else     printf "%b\n" "${yl}--> Info - ${rs}${tick} The default shell is: bash"; profiles=( ~/.bash_profile ~/.bash_login ~/.profile ~/.bashrc ~/.pam_environment ); fi; source_needed="false"; used_profile=""; sleep 1; for profile in "${profiles[@]}" ; do     if [[ -f "$profile" ]]; then         used_profile=$profile; printf "%b\n" "${yl}--> Info - ${rs}${tick} The profile is: ${used_profile}"; break; fi; done; if [[ $used_profile == "" ]]; then     used_profile=${profiles[0]}; printf "%b\n" "${yl}--> Info - ${rs}${tick} The profile is: ${used_profile}"; fi; sleep 1; if [[ "${vf_os_identify}" == "Mac" ]]; then     ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step3 - ${rs}Checking the PATH contains Homebrew:"; ${spacer}; if [[ "${vf_path_before}" != *"${brew_home}"* ]]; then         printf "%b\n" "${yl}--> Info - ${rs}${tick} Homebrew added to PATH."; printf "\n%b\n" "export PATH=$brew_home:\$PATH" >> $used_profile; printf "%b\n" "${yl}--> Info - ${rs}${PATH}"; source_needed="true"; else         printf "%b\n" "${yl}--> Info - ${rs}${tick} PATH already contains Homebrew."; printf "%b\n" "${yl}--> Info - ${rs}${PATH}"; fi; fi; sleep 1; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step4 - ${rs}Checking the PATH contains the framework:"; ${spacer}; if [[ "${vf_path_framework_home}" == *"/bash-x-dev/"* ]];then     vf_path_lib="${vf_path_framework_home}lib"; else     vf_path_lib="${vf_path_framework_home}"; fi; if [[ "${vf_path_before}" != *"${vf_path_lib}"* ]]; then     printf "%b\n" "${yl}--> Info - ${rs}${tick} Adding the framework to the PATH in ${used_profile}.."; printf "\n%b\n" "export BASHX_HOME=${vf_path_lib}" >> $used_profile; printf "%b\n" "export PATH=\${BASHX_HOME}:\$PATH" >> $used_profile; source_needed="true"; else     printf "%b\n" "${yl}--> Info - ${rs}${tick} PATH already contains the framework.."; printf "%b\n" "${yl}--> Info - ${rs}${PATH}"; fi; sleep 1; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step5 - ${rs}Create framework folder:"; ${spacer}; sleep 1; echo ${vf_path_framework_home}jq/; echo ${vf_path_framework_home}json/; echo ${vf_path_framework_home}README/; echo ${vf_path_framework_home}.gitignore; mkdir -p ${vf_path_framework_home}jq/; mkdir -p ${vf_path_framework_home}json/inventory/platform1/; mkdir -p ${vf_path_framework_home}README/; touch ${vf_path_framework_home}.gitignore; f_setup_json_array_framework; f_setup_json_array_inventory; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step6 - ${rs}Setup summary:"; ${spacer}; if [[ "${source_needed}" == "false" ]]; then     printf "%b\n" "${yl}--> Info - ${rs}${tick} All good - framework can be run from any folder."; printf "%b\n" "${yl}--> Info - ${rs}\$ bash-x --HELP"; else     printf "%b\n" "${yl}--> Info - ${rs}${tick} All good, but please apply the profile changes:"; printf "%b\n" "${yl}--> Info - ${rs}\$ source ${used_profile}"; fi; ${spacer}; };  f_skeleton(){ local project_name; local arrays; local errors; local help; local project; declare -A display_array; display_array["input_output"]=""; display_array["json/project"]=""; display_array["lib"]=""; display_array["pipelines/jenkins"]=""; display_array["pipelines/gitlab"]=""; display_array["lib/functions/fp_multipids"]=""; display_array["lib/functions/fp_S0"]=""; display_array["lib/functions/fp_S1"]=""; display_array["lib/functions/fp_S2"]=""; project_name=""; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step1 - ${rs}Name the project:"; ${spacer}; echo "What is the name of your new project? (default: skeleton)"; read project_name; if [[ "${project_name}" == "" ]];then     project_name="skeleton"; fi; if [ -d "${vf_path_framework_home}projects/${project_name}" ]; then     printf "%b\n" "Exiting as the project with the name ${project_name} already exists in ${vf_path_framework_home}projects!"; printf "%b\n" "${yl}--> info - ${rs} Exiting as a project named ${project_name} already exists in ${vf_path_framework_home}projects/"; fi; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step2 - ${rs}Create the project folder structure:"; ${spacer}; for key in ${!display_array[@]} ; do     printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/${key}"; mkdir -p ${vf_path_framework_home}projects/${project_name}/${key}; done; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step3 - ${rs}Write the templated project json files:"; ${spacer}; f_skeleton_json; template_path="${vf_path_framework_home}projects/${project_name}/json/project/"; for j in ${!A_json_project_template[@]} ; do   printf "%b\n" "${yl}--> info - ${rs}${template_path}${j}"; printf "%s\n" "${A_json_project_template[${j}]}" | ${jq} --indent 4 . > "${template_path}${j}"; done; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step4 - ${rs}Write the templated function files:"; ${spacer}; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/fp_project_start"; f_skeleton_start; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/fp_project_start_remote"; f_skeleton_start_remote; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/fp_project_custom_json"; f_skeleton_project_jsonarrays; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/fp_project_custom_runorder"; f_skeleton_stage_alterations; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_S0/fp_S0_ui_banner"; f_skeleton_S0_ui_banner; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_S0/fp_S0_set_vars"; f_skeleton_S0_set_vars; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_S0/fp_S0_logs_create"; f_skeleton_S0_logs_create; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step5 - ${rs}Write the templated function files for parallel processing:"; ${spacer}; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_create"; f_skeleton_multipids_create; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_details"; f_skeleton_multipids_display_details; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_details_S1"; f_skeleton_multipids_display_details_S1; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_fail"; f_skeleton_multipids_display_fail; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_success"; f_skeleton_multipids_display_success; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_wait"; f_skeleton_multipids_wait; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step6 - ${rs}Write the templated README.md:"; ${spacer}; printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/README.md"; f_skeleton_readme; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step7 - ${rs}Write the templated Jenkinsfile:"; ${spacer}; f_skeleton_jenkinsfiles; ${spacer}; ${dashLine}; printf "%b\n" "${cy}--> Step8 - ${rs}Skeleton project template summary:"; ${spacer}; printf "%b\n" "${yl}--> info - ${rs}The project has been created: ${cy}${vf_path_framework_home}projects/${project_name}${rs}"; printf "%b\n" "${yl}--> info - ${rs}See the framework README for more tips and happy rapid-bashing!${rs}"; ${spacer}; };  f_skeleton_json(){ A_json_project_template["arrays.json"]='{"comments":{"note1":"Arrays can be associative (unordered keypairs) or normal (ordered index).","note2":"The only required / processed field in this file is the 'name' and the other fields are included to be informative.","note3":"The name of the array will subsequently be prepended with 'a_' (index) or 'A_' (keypair).","do_nots":{"dn1":"Do NOT prepend the name below with 'a_' or 'A_' as it will be added by the framework.","dn2":"Do NOT forget to fill in the other fields as these will help to keep you on top of all of your arrays!"}},"arrays":{"project":"${project_name}","description":"These are all the arrays required by the project before it is called.","instructions":"Add section under either index or keypair. Only the name is required but other info will speed up development!","index":{"description":"The 'name' of arrays in this section are prepended with 'a_' (simple / index arrays)","array1":{"name":"relevant_index_name1","rationale":"what is this normal array used for?","populated":"name of function where this array is first populated","structure":"show what it contains e.g --> a_source_servers( tcsmsc-ref12 tcsmsc-ref11 tcsmsc-ref13 )"},"array2":{"name":"relevant_index_name2","rationale":"what is this normal array used for?","populated":"name of function where this array is first populated e.g. --> fp_S0_this_function","structure":"show what it contains e.g --> a_source_servers( tcsmsc-ref12 tcsmsc-ref11 tcsmsc-ref13 )"}},"keypair":{"description":"The name of arrays in this section are prepended with 'A_' (associative / keypair arrays)","array1":{"name":"relevant_keypair_name1","rationale":"what is this associative array used for?","populated":"name of function where this array is first populated e.g. --> fp_S1_this_function","structure":"show what it contains e.g --> A_variables_tests[vj_tests_group1_t1_from]={inventory_servers_prod1_service_default}"},"array2":{"name":"relevant_keypair_name2","rationale":"what is this associative array used for?","populated":"name of function where this array is first populated e.g. --> fp_S2_this_function","structure":"show what it contains e.g --> A_variables_tests[vj_tests_group1_t1_from]={inventory_servers_prod1_service_default}"}}}}'; A_json_project_template["errors.json"]='{"comments":{"note1":"Each stage has zero or more numbered errors. Below s0 has e1 and e2.","note2":"Each error has a message and a hint. Both can be either a static message or a runtime variable.","note3":"The reserved framework variable 'vf_dynamic_variable' can be assigned when catching an error and used.","do_nots":{"dn1":"Do NOT forget to remove this comments json block before deployment!","dn2":"Do NOT use commas in message and hint strings!"}},"errors":{"note":"Do NOT use commas in message and hint strings","s0":{"e1":{"message":"Relevant message!","hint":"either a static msg or use the dynamic variable 'vf_dynamic_error_msg'"},"e2":{"checktype":"check_path_file","path":"vf_framework_flags_ssh_keypath","message":"Bad path to private key!","hint":"static message or use a variable - e.g. --> vf_dynamic_error_msg"}},"s1":{"e1":{"message":"Failed to process json files!","hint":"Check creds + local / remote logs and file paths!"},"e2":{"message":"Inconsistent inventory / tests environment!","hint":"Use same environment for both!"}},"s2":{"e1":{"message":"short relevant message","hint":"vf_dynamic_error_msg"}}}}'; A_json_project_template["help.json"]='{"comments":{"note1":"The help json file is used for two purposes. To generate the help screen for the project and to define and set default values for all project flags.","note2":"The longname of the flag holds the other details within parenthsis. i.e. --longflag -shortflag","note3":"The flag type is used by the framework for display purpose and needs to be filled in if it a path.","do_nots":{"dn1":"Do NOT forget to define project flags in lowercase as UPPERCASE is reserved for the framework.","dn2":"Do NOT forget to REMOVE this comments block!"}},"help":{"project":"network-connectivity-checker","description":"Content for project help screen and where project flags are added.","instructions":"Add a new flag by inserting a new json block. For help screen add entries under usage section. Check framework help to avoid flag name clashes.","flags":{"cspath":{"shortflag":"csp","type":"path_folder_remote","about":"Remote path to checkerscript.","default":"/home/omndocker/scripts/"},"csname":{"shortflag":"csn","type":"","about":"Remote checkerscript name without file extension.","default":"network_connectivity_checker_cronjob"},"inventory":{"shortflag":"i","type":"path_file_local","about":"Json framework path.","default":"~/Workspace/eigental/bash-x-inventory/TC6000/ref/inventory.json"}},"usage":{"usage1":{"description":"Show the help menu for this project.","example":"bash-x --PROJECT project-name --HELP"},"usage2":{"description":"Run project using default values for all flags (set in project.json).","example":"bash-x --PROJECT project-name"}}}}'; A_json_project_template["project.json"]='{"comments":{"note1":"A project consists of one or more stages and each stage consists of one or more tasks. A task consists of one or more functions.","note2":"Stages must be numbered from 's1' upwards. i.e. s1,s2,s3 and within a stage, tasks and their functions must be numbered from '1' upwards. i.e. t1,t2,t3 and f1,f2,f3","note3":"Concurrent stages run their tasks/functions in a loop using the multipid functions.","do_nots":{"dn1":"Do NOT forget to REMOVE this comments block!"}},"project":{"name":"project-name-here","description":"Short description of what the project does.","version":"e.g. --> 1.0.1","repo":"git repo url","stages":{"s1":{"title":"Title of stage displayed to screen.","concurrent":"true (will create subprocesses) or false (single process)","concurrentMsg":"add display message if concurrent is true or leave empty","t1":{"title":"Title of task displayed to screen.","f1":"fp_S1_func_name"},"t2":{"title":"Title of task displayed to screen.","f1":"fp_S1_func_name","f2":"fp_S1_func_name"}},"s2":{"title":"Title of stage displayed to screen.","concurrent":"false","concurrentMsg":"","t1":{"title":"Title of task displayed to screen.","f1":"fp_S2_func_name","f2":"fp_S2_func_name"}},"s3":{"title":"Title of stage displayed to screen.","concurrent":"true","concurrentMsg":"add display message if concurrent is true or leave empty","t1":{"title":"Title of task displayed to screen.","f1":"fp_S3_func_name"}}}}}'; };  f_ssh_cmd(){ cmd_remote="${1}"; err_code="${2}"; if [[ "${vf_framework_flags_behaviour_remotecompute}" == "true" ]];then log_path="${vp_project_rootpath}input_output/logs/subprocesses_${vf_local_hostname_short}.log"; else log_path="${vp_path_folder_timestamp_tests_logs_sublocal}${loop_source_hostname}.log"; fi; case "${AUTH_APPROACH}" in "cicd_user_pass") sshpass -p ${PASSWORD} -P ass ssh -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 ${USERNAME}@${loop_source_pubIp} "${cmd_remote}" >> "${log_path}";; "user_pass") sshpass -p ${PASSWORD} -P ass ssh -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 ${USERNAME}@${loop_source_pubIp} "${cmd_remote}" >> "${log_path}";; "user_pass_key") sshpass -p ${PASSWORD} -P ass ssh -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -i ${SSH_PATH_KEY} ${USERNAME}@${loop_source_pubIp} "${cmd_remote}" >> "${log_path}";; "user_key") ssh -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -i ${SSH_PATH_KEY} ${USERNAME}@${loop_source_pubIp} "${cmd_remote}" >> "${log_path}";; esac; res="${?}"; if [[ "${err_code}" == "return_result" ]];then echo "${res}"; elif [[ "$res" != "0" ]]; then f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${err_code}"; if [[ "${vf_framework_flags_behaviour_fastfail}" == "true" ]]; then f_stages_functions_final; else exit ${err_code}; fi; fi; };  f_ssh_folder_actions(){ local path="${1}"; local action="${2}"; path=$(f_utils_strings_bpe "paths_end_slash" "${path}"); case "${action}" in "delete") result=$(f_ssh_cmd "[[ -d ${path} ]] && rm -rf ${path} && echo 0 || echo 1" "return_result");; "permission") result=$(f_ssh_cmd "mkdir -p ${path}McTest && rm -rf ${path}McTest && echo 0 || echo 1" "return_result");; esac; echo "${result}"; };  f_ssh_scp_fetch(){ remote_path="${1}"; local_path="${2}"; err_code="${3}"; if [[ "${vf_framework_flags_behaviour_remotecompute}" == "true" ]];then log_path="${vp_project_rootpath}input_output/logs/subprocesses_${vf_local_hostname_short}.log"; else log_path="${vp_path_folder_timestamp_tests_logs_sublocal}${loop_source_hostname}.log"; fi; case "${AUTH_APPROACH}" in "cicd_user_pass") sshpass -p ${PASSWORD} -P ass scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 ${USERNAME}@${loop_source_pubIp}:${remote_path} ${local_path} >> "${log_path}";; "user_pass") sshpass -p ${PASSWORD} -P ass scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 ${USERNAME}@${loop_source_pubIp}:${remote_path} ${local_path} >> "${log_path}";; "user_pass_key") sshpass -p ${PASSWORD} -P ass scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -i ${SSH_PATH_KEY} ${USERNAME}@${loop_source_pubIp}:${remote_path} ${local_path} >> "${log_path}";; "user_key") scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -i ${SSH_PATH_KEY} ${USERNAME}@${loop_source_pubIp}:${remote_path} ${local_path} >> "${log_path}";; esac; res="${?}"; if [[ "${err_code}" == "return_result" ]];then echo "${res}"; elif [[ "$res" != "0" ]]; then f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${err_code}"; if [[ "${vf_framework_flags_behaviour_fastfail}" == "true" ]]; then f_stages_functions_final; else exit ${err_code}; fi; fi; };  f_ssh_scp_send(){ local_path="${1}"; remote_path="${2}"; err_code="${3}"; if [[ "${vf_framework_flags_behaviour_remotecompute}" == "true" ]];then log_path="${vp_project_rootpath}input_output/logs/subprocesses_${vf_local_hostname_short}.log"; else log_path="${vp_path_folder_timestamp_tests_logs_sublocal}${loop_source_hostname}.log"; fi; case "${AUTH_APPROACH}" in "cicd_user_pass") sshpass -p ${PASSWORD} -P ass scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -r ${local_path} ${USERNAME}@${loop_source_pubIp}:${remote_path} >> "${log_path}";; "user_pass") sshpass -p ${PASSWORD} -P ass scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -r ${local_path} ${USERNAME}@${loop_source_pubIp}:${remote_path} >> "${log_path}";; "user_pass_key") sshpass -p ${PASSWORD} -P ass scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -i ${SSH_PATH_KEY} -r ${local_path} ${USERNAME}@${loop_source_pubIp}:${remote_path} >> "${log_path}";; "user_key") scp -o LogLevel=INFO -oStrictHostKeyChecking=no -o ConnectTimeout=7 -i ${SSH_PATH_KEY} -r ${local_path} ${USERNAME}@${loop_source_pubIp}:${remote_path} >> "${log_path}";; esac; res="${?}"; if [[ "${err_code}" == "return_result" ]];then echo "${res}"; elif [[ "$res" != "0" ]]; then f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "${err_code}"; if [[ "${vf_framework_flags_behaviour_fastfail}" == "true" ]]; then f_stages_functions_final; else exit ${err_code}; fi; fi; };  f_stages_display_schedule(){  local s; local stage; local stage_title; local stage_concurrent; local stage_concurrentMsg; ${spacer}; ${plusLine}; printf "%b\n" "${cyB}Project stages.${rs}"; ${plusLine}; ${spacer}; sleep 1; for s in $(seq 1 ${vp_stage_count}) ; do     stage="vp_project_stages_s${s}"; stage_title="${stage}_title"; stage_concurrent="${stage}_concurrent"; stage_concurrentMsg="${stage}_concurrentMsg"; stage_mode="${stage}_mode"; f_arrays_set_var "vp_stage_number"               "${s}"; f_arrays_set_var "vp_stage_title_value"          "${A_project_vars[${stage_title}]}"; f_arrays_set_var "vp_stage_concurrent_value"     "${A_project_vars[${stage_concurrent}]}"; f_arrays_set_var "vp_stage_concurrentMsg_value"  "${A_project_vars[${stage_concurrentMsg}]}"; f_arrays_set_var "vp_stage_mode"                 "${A_project_vars[${stage_mode}]}"; if [[ "${vp_stage_title_value}" == "" ]]; then break; fi; skip="false"; if [[ "${vf_framework_flags_behaviour_skipstages}" != "false" ]] || [[ "${#a_skipstages[@]}" -gt "0" ]];then         for k in ${a_skipstages[@]}         ; do             if [[ "${s}" == "${k}" ]];then                 skip="true"; fi; done; fi; if [[ ${vp_stage_concurrent_value} == "false" ]]; then         concurrent_message="serial  "; else         concurrent_message="parallel"; fi; if [[ "${vf_framework_flags_help}" == "true" ]];then         printf "%s\t%s\t%s\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}:${rs}" "${concurrent_message}" "${vp_stage_title_value}"; else         if [[ "${skip}" == "true" ]];then              printf "%s\t%s\t%s\t%s\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}:${rs}" "${yl}${concurrent_message}${rs}" "${rd}skipping stage${rs}" "${vp_stage_title_value}"; else             printf "%s\t%s\t%s\t%s\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}:${rs}" "${yl}${concurrent_message}${rs}" "${gr}running stage${rs}" "${vp_stage_title_value}"; fi; sleep 0.5; fi; done; };  f_stages_display_schedule_remote(){  local s; local r; local stage; local stage_title; local stage_concurrent; local stage_concurrentMsg; ${spacer}; ${plusLine}; printf "%b\n" "${cyB}Remote project stages.${rs}"; ${plusLine}; ${spacer}; sleep 1; for s in $(seq 1 ${vp_stage_count}) ; do     rstage_count="1"; while :; do         stage="vp_project_stages_s${s}_remote${rstage_count}"; stage_title="${stage}_title"; stage_concurrent="${stage}_concurrent"; stage_concurrentMsg="${stage}_concurrentMsg"; f_arrays_set_var "vp_stage_number"               "${s}"; f_arrays_set_var "vp_stage_title_value"          "${A_project_vars[${stage_title}]}"; f_arrays_set_var "vp_stage_concurrent_value"     "${A_project_vars[${stage_concurrent}]}"; f_arrays_set_var "vp_stage_concurrentMsg_value"  "${A_project_vars[${stage_concurrentMsg}]}"; if [[ "${vp_stage_title_value}" == "" ]]; then continue; fi; skip="false"; if [[ "${vf_framework_flags_behaviour_skipstages}" != "false" ]] || [[ "${#a_skipstages[@]}" -gt "0" ]];then             for k in ${a_skipstages[@]}             ; do                 if [[ "${s}" == "${k}" ]];then                     skip="true"; fi; done; fi; if [[ ${vp_stage_concurrent_value} == "false" ]]; then             concurrent_message="serial process    "; else             concurrent_message="parallel processes"; fi; if [[ "${vf_framework_flags_help}" == "true" ]];then             printf "%b\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}:${rs} ${concurrent_message} - ${yl}${vp_stage_title_value}${rs}"; else             if [[ "${skip}" == "true" ]];then                  printf "%b\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}:${yl} - Skipping - ${concurrent_message} - ${vp_stage_title_value}${rs}"; else                 printf "%b\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}:${gr} - Running  - ${concurrent_message} - ${vp_stage_title_value}${rs}"; fi; sleep 0.5; fi; rstage_count=$((rstage_count+1)); done; done; };  f_stages_functions(){ local stage_json_key; local num_tasks; local task; local task_title; local task_title_value; local function; local function_value; if [[ ${1} == "--multipid" ]] && [[ "${vf_framework_flags_behaviour_trace}" == "true" ]];then     set -x; fi; stage_json_key="vp_project_stages_s${vp_stage_number}"; num_tasks=0; task_count="1"; while :; do     task="${stage_json_key}_t${task_count}"; task_title="${task}_title"; task_title_value="${A_project_vars[${task_title}]}"; if [[ "${task_title_value}" == "" ]]; then break; fi; ((num_tasks++)); ((task_count++)); done; stage_task="1"; while :; do     task="${stage_json_key}_t${stage_task}"; task_title="${task}_title"; task_title_value="${A_project_vars[${task_title}]}"; if [[ "${task_title_value}" == "" ]]; then break; fi; ${spacer}; ${dashLine}; printf "%b\n" "${ylB}Task ${stage_task}/${num_tasks}: ${yl}${task_title_value}${rs}"; ${dashLine}; sleep 2; stage_task_function="1"; while :; do         function="${task}_f${stage_task_function}"; function_value="${A_project_vars[${function}]}"; if [[ "${function_value}" == "" ]]; then break; fi; if [[ "${function_value}" == "skip_function" ]]; then              continue; else             ${function_value}; fi; ((stage_task_function++)); done; ((stage_task++)); done; ${spacer}; };  f_stages_functions_final(){ error_array_size=${#A_project_stage_errors[@]}; errcode_array_size=${#A_json_errors[@]}; if [[ "${error_array_size}" == "0" ]] && [[ "${vf_status_exitcode}" == "0" ]];then   final_exitcode="0"; else   final_exitcode="1"; fi; ${spacer}; ${plusLine}; printf "%b\n" "${cyB}Final project summary:${rs}"; ${plusLine}; ${spacer}; sleep 1; printf "%b\n" "${yl}--> Info - ${rs}Duration:             $(f_utils_time "script_duration")s"; printf "%b\n" "${yl}--> Info - ${rs}Fastfail:             ${vf_framework_flags_behaviour_fastfail}"; printf "%b\n" "${yl}--> Info - ${rs}Exit-code:            ${final_exitcode}"; if [[ "${final_exitcode}" != "0" ]];then   printf "%b\n" "${yl}--> Info - ${rs}Total errors:         ${error_array_size}"; printf "\n%b\n" "${yl}--> Info - ${rs}Error table by stage:"; ${spacer}; printf '%s\t %-35s\t %-30s\t %-65s\t %s\n' "${bold}#" "${cy}Stage errorcode${rs}" "${wh}Amount${rs}" "${yl}Message${rs}" "${wh}Hint${rs}"; printf '%s\n' "=================================================================================================================================="; index=1; for i in $(seq 0 ${vp_stage_count}) ; do     count=0; if [[ "${get_out}" == "true" ]];then break; fi; for j in $(seq 1 ${errcode_array_size}) ; do       if [[ "${get_out}" == "true" ]];then break; fi; loop_stage_exitcode="vj_errors_s${i}_e${j}"; [ ${A_json_errors["${loop_stage_exitcode}_message"]+abc} ] &&       for pid_stage_exitcode in ${!A_project_stage_errors[@]}; do           pid=$(echo ${pid_stage_exitcode}      | cut -d ',' -f1); stage=$(echo ${pid_stage_exitcode}    | cut -d ',' -f2); exitcode=$(echo ${pid_stage_exitcode} | cut -d ',' -f3); array_stage_exitcode="vj_errors_s${stage}_e${exitcode}"; if [[ "${loop_stage_exitcode}" == "${array_stage_exitcode}" ]]; then             err_id=${loop_stage_exitcode}; message=$(echo ${A_project_stage_errors[${pid_stage_exitcode}]} | cut -d ',' -f1); hint=$(echo ${A_project_stage_errors[${pid_stage_exitcode}]}    | cut -d ',' -f2); if [[ ${hint} == "vf_"* ]] || [[ ${hint} == "vp_"* ]] || [[ ${hint} == "vj_"* ]] || [[ ${hint} == **"USER"** ]]; then hint=${!hint}; fi; (( count++ )); if [[ "${loop_stage_exitcode}" == *"s0_"* ]]; then get_out="true"; fi; fi; done; done; if [[ "${count}" != "0" ]] && [[ "${message}" != "" ]];then       if [[ "${index}" != "1" ]];then         printf '%s\n' "----------------------------------------------------------------------------------------------------------------------------------"; fi; printf '%s\t %-35s\t %-30s\t %-65s\t %s\n' "${bold}${index}${rs}" "${cy}${err_id}${rs}" "${wh}${count}${rs}" "${yl}${message}${rs}" "${wh}${hint}${rs}"; ((index++)); fi; done; fi; ${spacer}; if [[ "${vp_stage_number}" != "0" ]];then   vp_project_files_log="$(find ${vp_path_folder_logs} -name "*.log")"; for file in $(printf "%s\n" "${vp_project_files_log}"); do [ -f $file ] && f_utils_strings_sed "del_colorcodes" $file; done; if [[ "${vf_framework_flags_behaviour_fastfail}" == "true" ]] ;then     orphan_pids=$(echo $(jobs -p)); if [[ "${orphan_pids}" != "" ]] ;then       printf "%b\n" "${yl}--> Info - ${rs}Killing any orphan pids:\t    ${orphan_pids}"; ${spacer}; trap 'kill $(jobs -p) 2> /dev/null' EXIT      ; fi; exit ${final_exitcode}; fi; trap "exit ${final_exitcode}" EXIT ; fi; exit ${final_exitcode}; };  f_stages_loop(){  local s; local skip; local stage; local stage_title; local stage_concurrent; local stage_concurrentMsg; for s in $(seq 1 ${vp_stage_count}) ; do     stage="vp_project_stages_s${s}"; stage_title="${stage}_title"; if [[ "${stage_title}" == "" ]];then break; fi; f_arrays_set_var "vp_stage_number" "${s}"; fp_project_custom_runorder; done; f_stages_display_schedule; for s in $(seq 1 ${vp_stage_count}) ; do     stage="vp_project_stages_s${s}"; stage_title="${stage}_title"; stage_concurrent="${stage}_concurrent"; stage_concurrentMsg="${stage}_concurrentMsg"; f_arrays_set_var "vp_stage_number"               "${s}"; f_arrays_set_var "vp_stage_title_value"          "${A_project_vars[${stage_title}]}"; f_arrays_set_var "vp_stage_concurrent_value"     "${A_project_vars[${stage_concurrent}]}"; f_arrays_set_var "vp_stage_concurrentMsg_value"  "${A_project_vars[${stage_concurrentMsg}]}"; if [[ "${vp_stage_title_value}" == "" ]];then break; fi; ${spacer}; ${plusLine}; printf "%b\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}: ${vp_stage_title_value}${rs}"; ${plusLine}; ${spacer}; sleep 2; skip="false"; if [[ "${vf_framework_flags_behaviour_skipstages}" != "false" ]] || [[ "${#a_skipstages[@]}" -gt "0" ]];then         for k in ${a_skipstages[@]}         ; do             if [[ "${s}" == "${k}" ]];then                 skip="true"; fi; done; fi; if [[ "${skip}" == "true" ]];then          printf "%b\n" "${yl}--> Info - ${rs}This stage is being skipped."; sleep 1; continue; else         f_arrays_set_var "vf_status_exitcode" "0"; if [[ "${vp_stage_concurrent_value}" == "false" ]];then                  f_stages_functions; else             f_multipids_arrays; for function in ${a_multipds_runorder[@]}             ; do                 $function; done; fi; fi; done; };  f_stages_loop_remote(){  local s; local stage_remote; local skip; local stage; local stage_title; local stage_concurrent; local stage_concurrentMsg; for s in $(seq 1 ${vp_stage_count}) ; do     stage_remote="1"; while :; do         stage="vp_project_stages_s${s}_remote${stage_remote}"; stage_title="${stage}_title"; if [[ "${stage_title}" == "" ]];then break; fi; f_arrays_set_var "vp_stage_number" "${s}_remote${stage_remote}"; fp_project_custom_runorder; ((stage_remote++)); done; done; f_stages_display_schedule_remote; for s in $(seq 1 ${vp_stage_count}) ; do     stage_remote="1"; while :; do         stage="vp_project_stages_s${s}_remote${stage_remote}"; stage_title="${stage}_title"; stage_concurrent="${stage}_concurrent"; stage_concurrentMsg="${stage}_concurrentMsg"; f_arrays_set_var "vp_stage_number"               "${s}"; f_arrays_set_var "vp_stage_title_value"          "${A_project_vars[${stage_title}]}"; f_arrays_set_var "vp_stage_concurrent_value"     "${A_project_vars[${stage_concurrent}]}"; f_arrays_set_var "vp_stage_concurrentMsg_value"  "${A_project_vars[${stage_concurrentMsg}]}"; if [[ "${vp_stage_title_value}" == "" ]];then break; fi; ${spacer}; ${plusLine}; printf "%b\n" "${cyB}Stage ${vp_stage_number}/${vp_stage_count}: ${vp_stage_title_value}${rs}"; ${plusLine}; ${spacer}; sleep 2; skip="false"; if [[ "${vf_framework_flags_behaviour_skipstages}" != "false" ]] || [[ "${#a_skipstages[@]}" -gt "0" ]];then             for k in ${a_skipstages[@]}             ; do                 if [[ "${s}" == "${k}" ]];then                     skip="true"; fi; done; fi; if [[ "${skip}" == "true" ]];then              printf "%b\n" "${yl}--> Info - ${rs}This stage is being skipped."; sleep 1; ((stage_remote++)); continue; else             f_arrays_set_var "vf_status_exitcode" "0"; if [[ "${vp_stage_concurrent_value}" == "false" ]];then                      f_stages_functions; else                 f_multipids_arrays; for function in ${a_multipds_runorder[@]}                 ; do                     $function; done; fi; fi; ((stage_remote++)); done; done; };  f_stages_skip(){ flag="${1}"; value="${2}"; skip="false"; if [[ "${vf_framework_flags_behaviour_skipstages}" == "true" ]];then for k in ${a_skipstages[@]} ; do if [[ "${k}" == "${vp_stage_number}" ]];then skip="true"; fi; done; fi; if [[ "${skip}" == "true" ]] || [[ "${flag}" == "${value}" ]];then a_skipstages+=( "${vp_stage_number}" ); fi; };  f_utils_containers(){ local action; local action_string; action="${1}"; action_string="${2}"; case "${action}" in 	"get_container_id") result="$(${vf_cmd_docker} ps)"; OLDIFS=$IFS; IFS="|"; for v in ${action_string}         ; do             if [[ "${v}" == *"-v"* ]];then                 v=$(f_utils_strings_bpe "del_fromleft_upto_including" "${v}" "-v"); result=$(grep -v ${v} <(echo ${result})); else                 v=$(f_utils_strings_bpe "del_fromleft_upto_including" "${v}" "grep"); result=$(grep ${v} <(echo ${result})); fi; done; IFS=$OLDIFS; result=$(echo ${result} | awk '{print $1}');; esac; printf "%s" "${result}"; };  f_utils_curl(){ local username; local password; local path_to_file; local curl_resource_type; local endpoint_url; username="${1}"; password="${2}"; path_to_file="${3}"; curl_resource_type="${4}"; endpoint_url="${5}"; curl --user "${username}:${password}" -H "Accept: application/json" -F "file=@${path_to_file};type=${curl_resource_type}" "${endpoint_url}" | ${jq} '.id'; }; f_utils_join_lines() { local file="$1"; if [[ ! -f "$file" ]]; then echo "File not found!"; return 1; fi; tr '\n' ' ' < "$file" | gsed 's/ *$//g' > "${file}.tmp"; echo "" >> "${file}.tmp"; mv "${file}.tmp" "$file"; };  f_utils_logs_rotate(){ local strategy; local filefolder; local condition; strategy="${1}"; filefolder="${2}"; condition="${3}"; case "${strategy}" in "folder_writetime") find "${filefolder}" -mmin +${condition} -type d ! -name ${filefolder} -exec rm -rf {} \; 2>/dev/null;; esac; };  f_utils_network(){ local action; local result; action="${1}"; case "${action}" in   "calc_ip_local") if [[ "${vf_os_identify}" == "Mac" ]];then       result=$(ifconfig | grep "inet " | grep -Fv 127.0.0.1 | awk '{print $2}'); else       hostname_cmd="$(which hostname)"; result=$($hostname_cmd | awk '{print $1}'); fi;; "calc_ip_local2") if [[ "${vf_os_identify}" == "Mac" ]];then       result=$(ifconfig | grep "inet " | grep -Fv 127.0.0.1 | awk '{print $2}'); else       result=$(ip route get 1| grep -o 'src.*'| cut -d ' ' -f2); fi;; "calc_ip_public") result=$(curl -s ifconfig.me);; esac; printf "${result}"; };  f_utils_os(){ local os; os=$(uname -a); os=$(echo "${os}" | tr '[:upper:]' '[:lower:]'); if [[ "${os}"    == *"darwin"* ]]; then   os="Mac"; elif [[ "${os}" == *"ubuntu"* ]]; then   os="Ubuntu"; else   os=$(cat /etc/system-release-cpe); os=$(echo "${os}" | tr '[:upper:]' '[:lower:]'); if [[ "${os}" == *"centos"* ]]; then     os="Centos"; elif [[ "${os}" == *"redhat"* ]]; then     os="Redhat"; else     os=$(cat /etc/*release); os=$(echo "${os}" | tr '[:upper:]' '[:lower:]'); if [[ "${os}" == *"debian"* ]] || [[ "${os}" == *"ubuntu"* ]]; then       os="Ubuntu"; else       os="Unrecognised"; fi; fi; fi; printf "%s" "${os}"; };  f_utils_strings(){ local action; local result; local param1; local param2; action="${1}"; param1="${2}"; param2="${3}"; case "${action}" in   "bashvar_swap") result="${param1//-/d}"; result="${result//:/c}"; result="${result//./p}"; result="${result////s}"; result="${result//\\/s}"; printf "%s" "${result}";; "has_substring") while IFS=';' read -ra sub; do         for i in "${sub[@]}"; do             if [[ "${param1}" == *"${i}"* ]]; then                 printf "%s" "${i}"; break; fi; done; done <<< "$param2";; "convert_case") if [[ "${param1}" == "upper" ]];then         result=$(echo $param2 | ${vf_cmd_awk} '{print toupper($0)}'); elif [[ "${param1}" == "lower" ]];then         result=$(echo $param2 | ${vf_cmd_awk} '{print tolower($0)}'); else         echo "specify either upper or lower"; fi; printf "${result}";; "count_chars") result="${param1//[^${param2}]}"; printf "${#result}";; "del_all_occurrence") result="${param1//$param2}"     printf "${result}";; esac; };  f_utils_strings_bpe(){ local action; local string; local substring; local result; action="${1}"; string="${2}"; substring="${3}"; result=""; case "${action}" in 	"unescape_string") result="${string//\\/}";; "del_fromleft_upto_including") result="${string##*${substring}}";; "del_fromleft_upto_including_first") result="${string#*${substring}}";; "del_fromleft_upto_including_first_or") length_str=${#string}; length_sub=${#substring}; lastIndex=$(( $length_sub - 1 )); result=""; for i in `seq 0 $lastIndex`; do 			char=${substring:$i:1}; result="${string#*${char}}"; length_res=${#result}; if [[ $length_res -ne $length_str ]];then 				break; fi; done;; "keep_fromleft_upto_excluding") result="${string%${substring}*}";; "keep_fromleft_upto_excluding_first") result="${string%%${substring}*}";; "keep_fromleft_upto_excluding_first_or") length_str=${#string}; length_sub=${#substring}; lastIndex=$(( $length_sub - 1 )) result=""; for i in `seq 0 $lastIndex`; do 			char=${substring:$i:1}; result="${string%%${char}*}"; length_res=${#result}; if [[ $length_res -ne $length_str ]];then 				break; fi; done;; "paths_single_slash") result=$(echo ${string//\}/\}/}); result=$(echo ${result//\/\//\/}); result=$(echo ${result//\/\//\/});; "paths_end_slash") [[ "${string}" != */ ]] && string="${string}/"; result="$(echo ${string%/}/)";; "paths_end_no_slash") [[ "${string}" != */ ]] && string="${string}/"; result="$(echo ${string%/})";; "get_numbers_from_string") result=$(echo ${string//[!0-9]/});; "del_whitespace_leading") result=$(echo ${string#"${string%%[![:space:]]*}"});; "del_whitespace_trailing") result=$(echo ${string%"${string##*[![:space:]]}"});; esac; printf "%s" "${result}"; };  f_utils_strings_printf(){ local action; local string; local substring; local result; action="${1}"; string="${2}"; substring="${3}"; result=""; case "${action}" in 	"escape_string") result="$(printf "%q" "${string}")";; esac; printf "%s" "${result}"; };  f_utils_strings_sed(){ local cmd; local action; local file_path; local string_search; local string_replace; action="${1}"; file_path="${2}"; string_search="${3}"; string_replace="${4}"; case "${action}" in "del_colorcodes") ${vf_cmd_sed} -i 's/\x1B[@A-Z\\\]^_]\|\x1B\[[0-9:;<=>?]*[-!"#$%&'"'"'()*+,.\/]*[][\\@A-Z^_`a-z{|}~]//g' "${file_path}" && ${vf_cmd_sed} -i 's/\x1b//g' "${file_path}"; result="$?";; "del_line_by_empty") ${vf_cmd_sed} -i '/^$/d' "${file_path}"; result="$?";; "del_line_by_last") ${vf_cmd_sed} -i '$ d' "${file_path}"; result="$?";; "del_line_by_linenumber") ${vf_cmd_sed} -i "${string_search}d" "${file_path}"; result="$?";; "del_line_by_linenumber_range") ${vf_cmd_sed} -i "${string_search},${string_replace}d" "${file_path}"; result="$?";; "del_line_by_starting_whitespace") ${vf_cmd_sed} -i '/^ .*/d' "${file_path}"; result="$?";; "del_line_by_substring") ${vf_cmd_sed} -i "/${string_search}/d" "${file_path}"; result="$?";; "del_linecontent_hash_whitespace") ${vf_cmd_sed} -i "/${string_search}/s/^#\s*//" "${file_path}"; result="$?";; "del_linecontent_from_substring") ${vf_cmd_sed} -i "s/${string_search}.*/${string_replace}/" "${file_path}"; result="$?";; "replace_by_substring") ${vf_cmd_sed} -i "s,${string_search},${string_replace},g" "${file_path}"; result="$?";; esac; if [[ "${result}" != "0" ]]; then f_arrays_set_var "vf_dynamic_error_msg" "cmd: ${vf_cmd_sed} -i, action: ${action}, filepath: ${file_path}, string_search: ${string_search}, string_replace: ${string_replace}"; f_errors_exitmessages "${FUNCNAME[0]}: $((LINENO))" "10"; fi; };  f_utils_time(){ local action; local result; action="${1}"; case "${action}" in   "script_duration") result=$(date +%s); result=$((result-vf_starttime));; esac; printf "${result}"; };
function f_arrays_declare_vars(){

# About:   
# - This function declares as bash variables the k value pairs held in the arrays.
# - Prior to bash 4.3 - the only way to do this is declaring a block for each array.
# - This function works on bash 4.0 and above but requires the array to be added to the case statement below.
# - After bash 4.3 it is possible to dynamically name the array as follows:
#   - Pass in the array name as a parameter.
#   local -n array=$1;
#   for k in ${!array[@]};
#   do
#     value=${array[${k}]};
#     printf -v "${k}" "${value}";
#   done

# Usage:
# f_arrays_declare_vars "json_framework";
# - Pass as parameter the name of the array to declare - this is matched to the case statement below.

# ---------------------------------------------------------------
# [1] Declare variables with local scope to this function only.

local array_to_declare;
local key;
local value;

# ---------------------------------------------------------------
# [2] Assign passed parameter(s).

array_to_declare="${1}";

# ---------------------------------------------------------------
# [3] Match the array to declare from the case statement. 

case "${array_to_declare}" in

# ---------------------------------------------------------------
  "variables_all")
    for k in "${!A_variables_all[@]}"
    do
      key=$(f_utils_strings "bashvar_swap" "${k}");
      value=${A_variables_all[${k}]};
      # Declare the variable and its value - now available globally.
      printf -v "${key}" "${value}";
    done;;

# ---------------------------------------------------------------
  "variables_all_empty")
    for k in "${!A_variables_all_empty[@]}"
    do
      key=$(f_utils_strings "bashvar_swap" "${k}");
      value=${A_variables_all_empty[${k}]};
      # Declare the variable and its value - now available globally.
      printf -v "${key}" "${value}";
    done;;

# ---------------------------------------------------------------
  "json_help")
    for k in "${!A_json_help[@]}"
    do
      key=$(f_utils_strings "bashvar_swap" "${k}");
      value=${A_json_help[${k}]};
      # Declare the variable and its value - now available globally.
      printf -v "${key}" "${value}";
    done;;

# ---------------------------------------------------------------
  "json_errors")
    for k in "${!A_json_errors[@]}"
    do
      key=$(f_utils_strings "bashvar_swap" "${k}");
      value=${A_json_errors[${k}]};
      # Declare the variable and its value - now available globally.
      printf -v "${key}" "${value}";
    done;;

# ---------------------------------------------------------------
  "json_stages")
    for k in "${!A_json_stages[@]}"
    do
      key=$(f_utils_strings "bashvar_swap" "${k}");
      value=${A_json_stages[${k}]};
      # Declare the variable and its value - now available globally.
      printf -v "${key}" "${value}";
    done;;

esac;
};
function f_minimise_framework(){

# About:
# - minify bash-x lib folder into one file.

# ---------------------------------------------
# [1] Remove any existing minimised script folder and /tmp files.

${spacer};
printf "%b\n" "${cyB}Minifier for bash-x framework.${rs}";

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 1: Remove any existing minifier related files.${rs}";
${spacer};
printf "%b\t%s\n" "${yl}--> info:${rs} Remove any existing minified files in the /tmp folder:" "${cy}/tmp/bx-*${rs}";
printf "%b\t%s\n" "${yl}--> info:${rs} Remove any existing minified version of bash-x framework:" "${cy}${vf_path_bashx}${rs}";
rm -rf /tmp/bx-*;
if [[ -d "${vf_path_bashx}" ]];then 
    find "${vf_path_bashx}" ! -name '.git' -type d ! -path "${vf_path_bashx}/.git" ! -name 'README' ! -name 'README.md' -maxdepth 1 -mindepth 1 -exec rm -rf {} \;
fi;

# ---------------------------------------------
# [2] Create single file with all project function code.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 2: Create single file with all project function code.${rs}";
${spacer};
printf "%b\t%s\n" "${yl}--> info:${rs} Create an edit file:" "${cy}tmp/bx-framework${rs}";
printf "%b\n" "${yl}--> info:${rs} - append all function files to it except ones containing heredoc functions.";
printf "%b\n" "${yl}--> info:${rs} For each appended file:";
printf "%b\n" "${yl}--> info:${rs} - remove all newlines from the end of the file.";
printf "%b\n" "${yl}--> info:${rs} - ensure that the '}' on the last line is followed by a semicolon.";
printf "%b\n" "${yl}--> info:${rs} - add a final newline after the '};' and make it the last line of the file.";
${spacer};

# Loop through all framework functions and append these all to the file /temp/bash-x.
for filename in ${vf_path_framework_home}lib/functions/*/* 
do
    if [[ "${filename}" == *"f_minimise_"* ]]; then
        process="false";
    fi;
    if grep -qE '<< *EOF|cat *<< *EOF' ${filename}; then
        process="false";
    fi;
    if [[ "${process}" == "true" ]];then 
        
        # Remove all newlines from the end of the file.
        ${vf_cmd_sed} -i -e :a -e '/^\n*$/{$d;N;ba' -e '}' "${filename}";
        
        # Ensure that the '}' on the last line is followed by a semicolon if it's not already.
        ${vf_cmd_sed} -i '$s/}$/};/' "${filename}";
        
        # Add a final newline after the '};' and make it the last line of the file.
        ${vf_cmd_sed} -i -e '$a\' "${filename}";

        # Display to screen on same line the file in the loop.
        printf "\r${yl}--> Appending function file:${rs} %s" "${filename}";
        
        # Append the content to "/tmp/bx-framework".
        cat "${filename}" >> "/tmp/bx-framework";
        # Clear the line for the next iteration.
        printf "\033[K";
    fi;
    process="true";
done;
${spacer};

# ---------------------------------------------
# [3] Prepare the file for minimisation.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 3: Prepare the file for minimisation.${rs}";
${spacer};
printf "%b\t%s\n" "${yl}--> info:${rs} Create a copy of the bash-x main script:" "${cy}/tmp/bx-main${rs}";
printf "%b\n" "${yl}--> info:${rs} - remove from this file the hashbang.";
printf "%b\n" "${yl}--> info:${rs} From both '/tmp/bx-framework' and '/tmp/bx-main' remove:";
printf "%b\n" "${yl}--> info:${rs} - all comments.";
printf "%b\n" "${yl}--> info:${rs} - all empty lines.";
printf "%b\n" "${yl}--> info:${rs} - all trailing backslashes used to join lines.";

# Treat the bash-x script differently as it needs to be appended last.
cat ${vf_path_framework_home}lib/bash-x >> /tmp/bx-main;
# Remove bash hashbang.
gsed -i '1d' "/tmp/bx-main";

tmp_files=( "/tmp/bx-framework" "/tmp/bx-main" );

for filename in ${tmp_files[@]}
do
    # Remove the 'function' keyword from script.
    # This searches for 'function f_' and replaces with 'f_'.
    ${vf_cmd_sed} -i -e 's/function[[:space:]]\+f_/f_/g' "${filename}";

    # Remove all comments including the hashbang from the bash-x script.
    ${vf_cmd_sed} -e '/^\s*#/d' -e '/^#[^!].*$/d' -e :a -e '$!N;s/\n#.*$//;ta' -e 'P;D' -i "${filename}";

    # Remove all empty lines.
    ${vf_cmd_sed} -i -e '/^[[:space:]]*$/d' "${filename}";

    # Ensure semicolon after 'fi' and 'done'. 
    # - Its much easier to do this now rather than adding a rule post joining lines.
    ${vf_cmd_sed} -E -i "s/(^|[[:space:]])fi([[:space:]]|$)/\1fi;\2/" "${filename}";
    ${vf_cmd_sed} -E -i "s/(^|[[:space:]])done([[:space:]]|$)/\1done;\2/" "${filename}";

    # Remove all trailing backslashes that join lines and bring following line up.
    ${vf_cmd_sed} -i ':a;N;$!ba;s/\\\n//g' "${filename}";
done;

# ---------------------------------------------
# [4] Join the lines for both files.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 4: Join lines.${rs}";
${spacer};
printf "%b\n" "${yl}--> info:${rs} For both '/tmp/bx-framework' and '/tmp/bx-main':";
printf "%b\n" "${yl}--> info:${rs} - join each line to the one above.";
printf "%b\n" "${yl}--> info:${rs} - move each function onto own line for the .debug version of the minimised file.";

# Join each line to the one above.
f_utils_join_lines "/tmp/bx-framework";
f_utils_join_lines "/tmp/bx-main";

# For easier debugging, move each function onto its own line.
${vf_cmd_sed} -E -i 's/([a-zA-Z0-9_]+)\(\)\{/\n\1\(\)\{/g' "/tmp/bx-framework";
${vf_cmd_sed} -E -i 's/([a-zA-Z0-9_]+)\(\)\{/\n\1\(\)\{/g' "/tmp/bx-main";

# ---------------------------------------------
# [5] Make corrections to file so that it runs.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 5: Make final corrections.${rs}";
${spacer};
echo "${yl}--> info:${rs} Apply rules for both '/tmp/bx-framework' and '/tmp/bx-main':";
${spacer};
IFS=",";
a_correction_titles[0]="Strings that must be followed by a semicolon";
a_correction_titles[1]="Strings that must be preceded by a semicolon";
a_correction_titles[2]="Strings with one space and then a semicolon";
a_correction_titles[3]="Strings with no semicolons after them";
a_correction_titles[4]="Add semicolon after 'else' if followed by";
a_correction_titles[5]="Remove semicolon if found after";
a_correction_titles[6]="Remove semicolon if found after these special chars";
a_correction_titles[7]="Replace '; ;' with ';'";
a_correction_titles[8]="Remove semicolons between '{' and";
a_correction_titles[9]="Remove semicolons before '<<<' and";

a_correction_values[0]="done,fi";
a_correction_values[1]="do,done,case,fi";
a_correction_values[2]="for";
a_correction_values[3]="do,then,else";
a_correction_values[4]="if,while,until,case";
a_correction_values[5]="case";
a_correction_values[6]="&";
a_correction_values[7]="n/a";
a_correction_values[8]="if,case";
a_correction_values[9]="done";

count=0;
for f in ${tmp_files[@]}
do
   ((++count));
    for i in "${!a_correction_titles[@]}"
    do
        rule_num="${i}";
        rule_desc="${a_correction_titles[$i]}";
        rule_items="${a_correction_values[${rule_num}]}";

        if [[ "${count}" == "1" ]];then
            printf '%s\t %-50s\t %s\n' "${yl}--> rule: ${rule_num}${rs}" "${rule_desc}: ${about}" "${cy}${rule_items}${rs}";
        fi;

        edit_count=0;

        for e in $rule_items
        do
            case "${rule_num}" in
            # ---------------------------------------------------------------
            "0")
                ${vf_cmd_sed} -E -i "s/(^|[[:space:]])${e}([[:space:]]|$)/\1${e};\2/"        "${f}";;
            # ---------------------------------------------------------------
            "1")
                ${vf_cmd_sed} -E -i "s/;+\b${e}\b/; ${e}/g; s/([^;])\b${e}\b/\1; ${e}/g"     "${f}";;
            # ---------------------------------------------------------------
            "2")
                ${vf_cmd_sed} -E -i "s/;[[:space:]]*${e}/; ${e}/g"                           "${f}";;
            # ---------------------------------------------------------------
            "3")
                ${vf_cmd_sed} -E -i "s/${e}\s*;/${e} /g"                                     "${f}";;
            # ---------------------------------------------------------------
            "4")
                ${vf_cmd_sed} -E -i "s/${e}\s*;/${e} /g"                                     "${f}";;        
            # ---------------------------------------------------------------
            "5")
                ${vf_cmd_sed} -E -i "s/${e}\s*;/${e} /g"                                     "${f}";;  
            # ---------------------------------------------------------------
            "6")
                ${vf_cmd_sed} -E -i "s/\\${e}\s*;/\\${e} /g"                                 "${f}";;  
            # ---------------------------------------------------------------
            "7")
                ${vf_cmd_sed} -E -i "s/;[[:space:]]+;/;/g"                                   "${f}";;         
            # ---------------------------------------------------------------
            "8")
                ${vf_cmd_sed} -i "s/{\s*;\s*${e}/{ ${e}/g"                                   "${f}";;
            # ---------------------------------------------------------------
            "9")
                ${vf_cmd_sed} -E -i "s/${e};[[:space:]]*<<</${e} <<</g"                      "${f}";;

            esac;
        done;
    done;
    # Some whitespace and tab clearing.
    gsed -i -E \
        -e '/printf/ s/^/PRINTF_LINE: /' \
        -e '/^PRINTF_LINE: /!s/[ \t]+/ /g' \
        -e 's/;\s+/; /g' \
        -e 's/;;\s+/;; /g' \
        -e 's/\)\s+/\) /g' \
        -e 's/;\s+/; /g' \
        -e 's/\;\s+do/; do/g' \
        -e 's/fi\s+;/fi;/g' \
        -e 's/^PRINTF_LINE: //g' \
        "${f}";
done;
unset IFS;

# ---------------------------------------------
# [6] Create a debug copy of the file

cp /tmp/bx-framework /tmp/bx-framework.debug;

# Join each line to the one above for the final minimised file.
# The debug version is left with each function on its own line.
f_utils_join_lines "/tmp/bx-framework";

# ---------------------------------------------
# [7] Append the heredoc functions last as they cannot be minimised.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 6: Append the heredoc functions (cannot be minimised) to '/tmp/bx-framework'.${rs}";
${spacer};

for filename in ${vf_path_framework_home}lib/functions/*/* 
do
    if [[ "${filename}" == *"f_minimise_"* ]]; then
        process="true";
    fi;
    if grep -qE '<< *EOF|cat *<< *EOF' ${filename}; then
        process="true";
    fi;
    if [[ "${process}" == "true" ]];then 
        # Remove all newlines from the end of the file.
        ${vf_cmd_sed} -i -e :a -e '/^\n*$/{$d;N;ba' -e '}' "${filename}";
        
        # Ensure that the '}' on the last line is followed by a semicolon if it's not already.
        ${vf_cmd_sed} -i '$s/}$/};/' "${filename}";
        
        # Add a final newline after the '};' and make it the last line of the file.
        ${vf_cmd_sed} -i -e '$a\' "${filename}";
        
        # Display to screen on same line the file in the loop.
        printf "\r${yl}--> Appending heredoc function file:${rs} %s" "${filename}";
        
        # Append the content to '/tmp/bx-framework' and '/tmp/bx-framework.debug'.
        cat "${filename}" >> "/tmp/bx-framework";
        cat "${filename}" >> "/tmp/bx-framework.debug";

        # Clear the line for the next iteration.
        printf "\033[K";
    fi;
    process="false";
done;
${spacer};

# ---------------------------------------------
# [8] Append last minimised functions after heredoc functions.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 7: Append '/tmp/bx-main' to '/tmp/bx-framework'.${rs}";
${spacer};
printf "%b\n" "${yl}--> info:${rs} Create debug file.";
printf "%b\n" "${yl}--> info:${rs} Insert hashbang into minimised files.";

cat /tmp/bx-main >> "/tmp/bx-framework";
cat /tmp/bx-main >> "/tmp/bx-framework.debug";

# Insert the new hashbang at line 1.
gsed -i '1i #!/usr/bin/env bash' "/tmp/bx-framework";
gsed -i '1i #!/usr/bin/env bash' "/tmp/bx-framework.debug";

# ---------------------------------------------
# [9] Move edit file to the bash-x folder.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 8: Move tmp files to bash-x folder.${rs}";
${spacer};

printf "%b\t\t%s\n" "${yl}--> info: ${rs} Create target folders in:" "${cy}${vf_path_bashx}${rs}";
mkdir -p  "${vf_path_bashx}";
mkdir -p  "${vf_path_bashx}json";
mkdir -p  "${vf_path_bashx}jq";
mkdir -p  "${vf_path_bashx}README";

cp -r ${vf_path_framework_home}json          "${vf_path_bashx}";
cp -r ${vf_path_framework_home}jq            "${vf_path_bashx}";
#cp -r ${vf_path_framework_home}README        "${vf_path_bashx}";
#cp    ${vf_path_framework_home}README.md     "${vf_path_bashx}";
cp    ${vf_path_framework_home}.gitignore    "${vf_path_bashx}";

# Change these two json elements from bash-x-dev to bash-x.
${jq} '.framework.name = "bash-x"' ${vf_path_framework_home}json/framework.json  > /tmp/bx-tmpjson.json && mv /tmp/bx-tmpjson.json ${vf_path_bashx}json/framework.json;
${jq} '.framework.repo = "git.swisscom.com/projects/CSL/repos/bash-x/"' ${vf_path_bashx}json/framework.json  > /tmp/bx-tmpjson.json && mv /tmp/bx-tmpjson.json ${vf_path_bashx}json/framework.json;

mv /tmp/bx-framework        "${vf_path_bashx}bash-x";
mv /tmp/bx-framework.debug  "${vf_path_bashx}bash-x.debug";

printf "%b\t%s\n" "${yl}--> info: ${rs} Assign execute permission on file." "${cy}${vf_path_bashx}bash-x${rs}";
printf "%b\t%s\n" "${yl}--> info: ${rs} Assign execute permission on file." "${cy}${vf_path_bashx}bash-x.debug${rs}";
chmod +x "${vf_path_bashx}bash-x";
chmod +x "${vf_path_bashx}bash-x.debug";
printf "%s\n" "";
};
function f_minimise_project(){

# About:
# - minify bash-x lib folder into one file.

# ---------------------------------------------
# [1] Remove any existing minimised script folder and /tmp files.

${spacer};
printf "%b\n" "${cyB}Minifier for bash-x project.${rs}";

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 1: Remove any existing minifier related files.${rs}";
${spacer};
printf "%b\t%s\n" "${yl}--> info:${rs} Remove any existing minified files in the /tmp folder:" "${cy}/tmp/bx-*${rs}";
printf "%b\t%s\n" "${yl}--> info:${rs} Remove any existing minified version of bash-x project:" "${cy}${vf_path_projects}${vp_project_name}.min${rs}";

rm -rf /tmp/bx-*;
if [[ -d "${vf_path_projects}${vp_project_name}.min" ]];then 
    find "${vf_path_projects}${vp_project_name}.min" ! -name '.git' -maxdepth 1 -mindepth 1 -exec rm -rf {} \;
fi;

# ---------------------------------------------
# [2] Create single file with all project function code.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 2: Create single file with all project function code.${rs}";
${spacer};
printf "%b\t%s\n" "${yl}--> info:${rs} Create an edit file:" "${cy}tmp/bx-project${rs}";
printf "%b\n" "${yl}--> info:${rs} - append all function files to it except ones containing heredoc functions.";
printf "%b\n" "${yl}--> info:${rs} For each appended file:";
printf "%b\n" "${yl}--> info:${rs} - remove all newlines from the end of the file.";
printf "%b\n" "${yl}--> info:${rs} - ensure that the '}' on the last line is followed by a semicolon.";
printf "%b\n" "${yl}--> info:${rs} - add a final newline after the '};' and make it the last line of the file.";
${spacer};

# Loop through all framework functions and append these all to the file /temp/bash-x.
for filename in ${vf_path_projects}${vp_project_name}/lib/functions/*/*
do
    if ! grep -qE '<< *EOF|cat *<< *EOF' ${filename}; then
        
        # Remove all newlines from the end of the file.
        ${vf_cmd_sed} -i -e :a -e '/^\n*$/{$d;N;ba' -e '}' "${filename}";
        
        # Ensure that the '}' on the last line is followed by a semicolon if it's not already.
        ${vf_cmd_sed} -i '$s/}$/};/' "${filename}";
        
        # Add a final newline after the '};' and make it the last line of the file.
        ${vf_cmd_sed} -i -e '$a\' "${filename}";

        # Display to screen on same line the file in the loop.
        printf "\r${yl}--> Appending function file:${rs} %s" "${filename}";
        
        # Append the content to "/tmp/bx-project".
        cat "${filename}" >> "/tmp/bx-project";
        # Clear the line for the next iteration.
        printf "\033[K";
    fi;
done;
${spacer};

# Copy these four required functions to their own file for now. They need to be appended after the other functions later.
cat "${vf_path_projects}${vp_project_name}/lib/fp_project_custom_json"      >  "/tmp/bx-project-fp";
cat "${vf_path_projects}${vp_project_name}/lib/fp_project_custom_runorder"   >> "/tmp/bx-project-fp";
cat "${vf_path_projects}${vp_project_name}/lib/fp_project_start_remote"     >> "/tmp/bx-project-fp";
cat "${vf_path_projects}${vp_project_name}/lib/fp_project_start"            >> "/tmp/bx-project-fp";

# ---------------------------------------------
# [3] Prepare the file for minimisation.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 3: Prepare the file for minimisation.${rs}";
${spacer};
printf "%b\n" "${yl}--> info:${rs} From both '/tmp/bx-project' and '/tmp/bx-project-fp' remove:";
printf "%b\n" "${yl}--> info:${rs} - all comments.";
printf "%b\n" "${yl}--> info:${rs} - all empty lines.";
printf "%b\n" "${yl}--> info:${rs} - all trailing backslashes used to join lines.";

tmp_files=( "/tmp/bx-project" "/tmp/bx-project-fp" );

for filename in ${tmp_files[@]}
do
    # Remove the 'function' keyword from script.
    # This searches for 'function fp_' and replaces with 'fp_'.
    ${vf_cmd_sed} -i -e 's/function[[:space:]]\+fp_/fp_/g' "${filename}";

    # Remove all comments including the hashbang from the bash-x script.
    ${vf_cmd_sed} -e '/^\s*#/d' -e '/^#[^!].*$/d' -e :a -e '$!N;s/\n#.*$//;ta' -e 'P;D' -i "${filename}";

    # Remove all empty lines.
    ${vf_cmd_sed} -i -e '/^[[:space:]]*$/d' "${filename}";

    # Remove all trailing backslashes that join lines and bring following line up.
    ${vf_cmd_sed} -i ':a;N;$!ba;s/\\\n//g' "${filename}";
done;

# ---------------------------------------------
# [4] Join the lines for both files.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 4: Join lines.${rs}";
${spacer};
printf "%b\n" "${yl}--> info:${rs} For both '/tmp/bx-project' and '/tmp/bx-project-fp':";
printf "%b\n" "${yl}--> info:${rs} - join each line to the one above.";
printf "%b\n" "${yl}--> info:${rs} - move each function onto own line for the .debug version of the minimised file.";

# Join each line to the one above.
f_utils_join_lines "/tmp/bx-project";
f_utils_join_lines "/tmp/bx-project-fp";

# For easier debugging, move each function onto its own line.
${vf_cmd_sed} -E -i 's/([a-zA-Z0-9_]+)\(\)\{/\n\1\(\)\{/g' "/tmp/bx-project";
${vf_cmd_sed} -E -i 's/([a-zA-Z0-9_]+)\(\)\{/\n\1\(\)\{/g' "/tmp/bx-project-fp";

# ---------------------------------------------
# [5] Make corrections to file so that it runs.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 5: Make final corrections.${rs}";
${spacer};
echo "${yl}--> info:${rs} Apply rules for both '/tmp/bx-project' and '/tmp/bx-main':";
${spacer};
IFS=",";
a_correction_titles[0]="Strings that must be followed by a semicolon";
a_correction_titles[1]="Strings that must be preceded by a semicolon";
a_correction_titles[2]="Strings with one space and then a semicolon";
a_correction_titles[3]="Strings with no semicolons after them";
a_correction_titles[4]="Add semicolon after 'else' if followed by";
a_correction_titles[5]="Remove semicolon if found after";
a_correction_titles[6]="Remove semicolon if found after these special chars";
a_correction_titles[7]="Replace '; ;' with ';'";
a_correction_titles[8]="Remove semicolons between '{' and";
a_correction_titles[9]="Remove semicolons before '<<<' and";

a_correction_values[0]="done,fi";
a_correction_values[1]="do,done,case,fi";
a_correction_values[2]="for";
a_correction_values[3]="do,then,else";
a_correction_values[4]="if,while,until,case";
a_correction_values[5]="case";
a_correction_values[6]="&";
a_correction_values[7]="n/a";
a_correction_values[8]="if,case";
a_correction_values[9]="done";

count=0;
for f in ${tmp_files[@]}
do
   ((++count));
    for i in "${!a_correction_titles[@]}"
    do
        rule_num="${i}";
        rule_desc="${a_correction_titles[$i]}";
        rule_items="${a_correction_values[${rule_num}]}";

        if [[ "${count}" == "1" ]];then
            printf '%s\t %-50s\t %s\n' "${yl}--> rule: ${rule_num}${rs}" "${rule_desc}: ${about}" "${cy}${rule_items}${rs}";
        fi;

        edit_count=0;

        for e in $rule_items
        do
            case "${rule_num}" in
            # ---------------------------------------------------------------
            "0")
                ${vf_cmd_sed} -E -i "s/(^|[[:space:]])${e}([[:space:]]|$)/\1${e};\2/"        "${f}";;
            # ---------------------------------------------------------------
            "1")
                ${vf_cmd_sed} -E -i "s/;+\b${e}\b/; ${e}/g; s/([^;])\b${e}\b/\1; ${e}/g"     "${f}";;
            # ---------------------------------------------------------------
            "2")
                ${vf_cmd_sed} -E -i "s/;[[:space:]]*${e}/; ${e}/g"                           "${f}";;
            # ---------------------------------------------------------------
            "3")
                ${vf_cmd_sed} -E -i "s/${e}\s*;/${e} /g"                                     "${f}";;
            # ---------------------------------------------------------------
            "4")
                ${vf_cmd_sed} -E -i "s/${e}\s*;/${e} /g"                                     "${f}";;        
            # ---------------------------------------------------------------
            "5")
                ${vf_cmd_sed} -E -i "s/${e}\s*;/${e} /g"                                     "${f}";;  
            # ---------------------------------------------------------------
            "6")
                ${vf_cmd_sed} -E -i "s/\\${e}\s*;/\\${e} /g"                                 "${f}";;  
            # ---------------------------------------------------------------
            "7")
                ${vf_cmd_sed} -E -i "s/;[[:space:]]+;/;/g"                                   "${f}";;         
            # ---------------------------------------------------------------
            "8")
                ${vf_cmd_sed} -i "s/{\s*;\s*${e}/{ ${e}/g"                                   "${f}";;
            # ---------------------------------------------------------------
            "9")
                ${vf_cmd_sed} -E -i "s/${e};[[:space:]]*<<</${e} <<</g"                      "${f}";;

            esac;
        done;
    done;
done;
unset IFS;

# ---------------------------------------------
# [6] Create a debug copy of the file

cp /tmp/bx-project /tmp/bx-project-debug;

# Join each line to the one above for the final minimised file.
f_utils_join_lines "/tmp/bx-project";

# ---------------------------------------------
# [7] Append the heredoc functions last as they cannot be minimised.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 6: Append the heredoc functions (cannot be minimised) to '/tmp/bx-project'.${rs}";
${spacer};

for filename in ${vf_path_projects}${vp_project_name}/lib/functions/*/*; do
    if grep -qE '<< *EOF|cat *<< *EOF' ${filename}; then

        # Remove all newlines from the end of the file.
        ${vf_cmd_sed} -i -e :a -e '/^\n*$/{$d;N;ba' -e '}' "${filename}";
        
        # Ensure that the '}' on the last line is followed by a semicolon if it's not already.
        ${vf_cmd_sed} -i '$s/}$/};/' "${filename}";

        # Add a final newline after the '};' and make it the last line of the file.
        ${vf_cmd_sed} -i -e '$a\' "${filename}";
        
        # Display to screen on same line the file in the loop.
        printf "\r${yl}--> Appending heredoc function file:${rs} %s" "${filename}";
        
        # Append the content to '/tmp/bx-framework' and '/tmp/bx-framework.debug'.
        cat "${filename}" >> "/tmp/bx-project";
        cat "${filename}" >> "/tmp/bx-project-debug";

        # Clear the line for the next iteration.
        printf "\033[K";
    fi;
done;
${spacer};

# ---------------------------------------------
# [8] Append last minimised functions after heredoc functions.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 7: Append temp files to each other.${rs}";
${spacer};

echo "${yl}--> info:${rs} Append '/tmp/bx-project-fp' to '/tmp/bx-project'";
echo "${yl}--> info:${rs} Append '/tmp/bx-project-fp' to '/tmp/bx-project-debug'";

cat /tmp/bx-project-fp >> "/tmp/bx-project";
cat /tmp/bx-project-fp >> "/tmp/bx-project-debug";

# ---------------------------------------------
# [9] Move edit file to the bash-x folder.

${spacer};
${equalsLine};
printf "%b\n" "${cyB}Step 8: Move tmp files to bash-x folder.${rs}";
${spacer};

echo "${yl}--> info: ${rs} Create target folders in ${cy}${vf_path_projects}${vp_project_name}.min${rs}";
mkdir -p  "${vf_path_projects}${vp_project_name}.min";
mkdir -p  "${vf_path_projects}${vp_project_name}.min/input_output";
mkdir -p  "${vf_path_projects}${vp_project_name}.min/json";
mkdir -p  "${vf_path_projects}${vp_project_name}.min/cicd";

cp -r ${vf_path_projects}${vp_project_name}/json "${vf_path_projects}${vp_project_name}.min/";
cp -r ${vf_path_projects}${vp_project_name}/README "${vf_path_projects}${vp_project_name}.min/";
cp ${vf_path_projects}${vp_project_name}/README.md "${vf_path_projects}${vp_project_name}.min/";

# Change these two json elements to have the .min extension.
${jq} ".project.name = \"${vp_project_name}.min\"" "${vf_path_projects}${vp_project_name}.min/json/project/project.json" > "/tmp/bx-tmpjson.json" && mv "/tmp/bx-tmpjson.json" "${vf_path_projects}${vp_project_name}.min/json/project/project.json";
min_repo="https://git.swisscom.com/projects/CSL/repos/bash-x-projects/browse/network-connectivity-checker.min";
${jq} ".project.repo = \"${min_repo}\"" "${vf_path_projects}${vp_project_name}.min/json/project/project.json" > "/tmp/bx-tmpjson.json" && mv "/tmp/bx-tmpjson.json" "${vf_path_projects}${vp_project_name}.min/json/project/project.json";

mv /tmp/bx-project        "${vf_path_projects}${vp_project_name}.min/${vp_project_name}.min";
mv /tmp/bx-project-debug  "${vf_path_projects}${vp_project_name}.min/${vp_project_name}.debug";

echo "${yl}--> info: ${rs} Assign execute permissions on folder ${cy}${vf_path_projects}${vp_project_name}.min${rs}";
chmod +x "${vf_path_projects}${vp_project_name}.min/${vp_project_name}.min"; 
chmod +x "${vf_path_projects}${vp_project_name}.min/${vp_project_name}.debug";
${spacer};
};
function f_setup_json_array_framework(){

cat << EOF > ${vf_path_framework_home}json/framework.json
{
    "framework":{
        "description":          "A lightweight SRE framework",
        "name":                 "bash-x",
        "repo":                 "git.swisscom.com/projects/CSL/repos/bash-x-dev/",
        "bashxpath":            "../bash-x/",
        "projectspath":         "../bash-x-projects/",
        "version":              "1.0.0",
        "flags":{
            "authapproach":     "local_user_key",
            "clear":            "true",
            "colordisplay":     "true",
            "fastfail":         "false",
            "help":             "false",
            "inspect":          "json",
            "limit":            "false",
            "minproject":       "false",
            "project":          "false",
            "remotestart":      "false",
            "setup":            "false",
            "skeleton":         "false",
            "skipstages":       "false",
            "sshinterface":     "default",
            "sshkeypath":       "~/.ssh/id_rsa",
            "sshpasspath":      "~/.pass",
            "sshtargetpath":    "/home/devops/",
            "sshuser":          "devops",
            "tidyup":           "false"
        },
        "dependencies":{
            "os":{
                "all":{
                    "bash":     ">4.0.0",
                    "jq":       "^1.5",
                    "ssh":      ">8.0"
                },
                "mac":{
                    "gsed":     "^4.8",
                    "ggrep":    "^3.0",
                    "gawk":     "^5.0"
                },
                "debian":{
                    "sed":      "latest",
                    "grep":     "^3.0",
                    "awk":      ">4.0"
                },
                "rhel":{
                    "sed":      "^4.8",
                    "grep":     "^3.0",
                    "awk":      "^4.0"
                }
            }
        }
    }
}

EOF
};
function f_setup_json_array_inventory(){

cat << EOF > ${vf_path_framework_home}json/inventory/platform1/platform.json
{
"inventory":{
    "name":                                 "platform1",
    "description":                          "customer platform1 in the acme cloud.",
    "environment":                          "prod",
    "servers":{
        "prod1":{
            "service":{
                "service1":{
                    "domain":               ".acme.ch",   
                    "interface":            "eth0",
                    "gateway":              "10.x.x.x",
                    "platform1-prod11":     "10.x.x.x",
                    "platform1-prod12":     "10.x.x.x",
                    "platform1-prod13":     "10.x.x.x",
                    "platform1-prod14":     "10.x.x.x",
                    "platform1-prod15":     "10.x.x.x",
                    "platform1-prod16":     "10.x.x.x"
                },
                "service2":{
                    "domain":               ".sharedtcs.net",   
                    "interface":            "eth1",
                    "gateway":              "10.x.x.x",
                    "platform1-prod11":     "10.x.x.x",
                    "platform1-prod12":     "10.x.x.x",
                    "platform1-prod13":     "10.x.x.x",
                    "platform1-prod14":     "10.x.x.x",
                    "platform1-prod15":     "10.x.x.x",
                    "platform1-prod16":     "10.x.x.x"
                },
                "service3":{   
                    "domain":               "",
                    "interface":            "eth2",
                    "gateway":              "10.x.x.x",
                    "platform1-prod11":     "10.x.x.x",
                    "platform1-prod12":     "10.x.x.x",
                    "platform1-prod13":     "10.x.x.x",
                    "platform1-prod14":     "10.x.x.x",
                    "platform1-prod15":     "10.x.x.x",
                    "platform1-prod16":     "10.x.x.x"
                }
            }
        },
        "prod2":{
            "service":{
                "service1":{
                    "domain":               ".acme.ch",   
                    "interface":            "eth0",
                    "gateway":              "10.x.x.x",
                    "platform2-prod21":     "10.x.x.x",
                    "platform2-prod22":     "10.x.x.x",
                    "platform2-prod23":     "10.x.x.x",
                    "platform2-prod24":     "10.x.x.x",
                    "platform2-prod25":     "10.x.x.x",
                    "platform2-prod26":     "10.x.x.x"
                },
                "service2":{
                    "domain":               ".sharedtcs.net",   
                    "interface":            "eth1",
                    "gateway":              "10.x.x.x",
                    "platform2-prod21":     "10.x.x.x",
                    "platform2-prod22":     "10.x.x.x",
                    "platform2-prod23":     "10.x.x.x",
                    "platform2-prod24":     "10.x.x.x",
                    "platform2-prod25":     "10.x.x.x",
                    "platform2-prod26":     "10.x.x.x"
                },
                "service3":{   
                    "domain":               "",
                    "interface":            "eth2",
                    "gateway":              "10.x.x.x",
                    "platform2-prod21":     "10.x.x.x",
                    "platform2-prod22":     "10.x.x.x",
                    "platform2-prod23":     "10.x.x.x",
                    "platform2-prod24":     "10.x.x.x",
                    "platform2-prod25":     "10.x.x.x",
                    "platform2-prod26":     "10.x.x.x"
                }
            }
        } 
    },
    "services":{     
        "acme":{   
            "apps":{   
                "domain":                       ".acme.com",
                "git":                          "138.x.x.x",
                "jira":                         "138.x.x.x",
                "bin":                          "138.x.x.x",
                "artifactory":                  "138.x.x.x",
                "s3appcloud":{
                    "domain":                   ".acme.com",
                    "ds11s3-scs":               "138.x.x.x",
                    "ds11s3-scs2":              "138.x.x.x"
                },
                "splunk":{
                    "domain":                   ".acme.net",
                    "hsplsiemits":              "138.x.x.x",
                    "hsplfwdp01":               "138.x.x.x",
                    "hsplfwdt01":               "138.x.x.x"
                }    
            },
            "ntp":{   
                "domain":                       ".acme.net",
                "dns1":                         "138.x.x.x",
                "dns2":                         "138.x.x.x"
            }
        }
    }
  }
}
EOF
};
function f_skeleton_S0_logs_create(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/functions/fp_S0/fp_S0_logs_create 
function fp_S0_logs_create(){

# About:
# Create the folders used for logs and results.
# The paths are set in 'fp_S0_set_vars'.

# Usage:
# fp_S0_logs_create;

mkdir -p "\${vp_path_folder_timestamp_tests_logs}";
mkdir -p "\${vp_path_folder_timestamp_tests_logs_sublocal}";
mkdir -p "\${vp_path_folder_timestamp_tests_logs_subremote}";
touch    "\${vp_path_folder_timestamp_tests_logs}console.log";
};
EOF
};
function f_skeleton_S0_set_vars(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/functions/fp_S0/fp_S0_set_vars 
# About:
# Assign all variables that can be assigned at this point in the project code.
# - Variables that are dependent on loops in multipids should be assigned in the 'multipids_create' loop. 
# - Use 'vp_' as opposed to the 'vj_' versions of the variables as they may have been changed with passed flags by this point.
# - the 'vp_' ones are altered by any runtime passed flags, wheras the 'vj_' ones are static. 

# Usage:
# fp_S0_set_vars;
# - No passed parameters.

# ---------------------------------------------------------------
# [1] Assign variable that isolates the short tests json file path.

f_arrays_set_var "vp_path_tests_short" "$(f_utils_strings_bpe 'del_fromleft_upto_including' \${vp_help_flags_tests} 'json/tests/')";

# ---------------------------------------------------------------
# [2] Create variables for the timestamped log folders.

f_arrays_set_var "vp_path_folder_timestamp"                         "\${vp_project_rootpath}input_output/\${vf_timestamp}/";
f_arrays_set_var "vp_path_folder_timestamp_tests"                   "\${vp_path_folder_timestamp}\${vp_path_tests_short}/";
f_arrays_set_var "vp_path_folder_timestamp_tests_logs"              "\${vp_path_folder_timestamp_tests}logs/";
f_arrays_set_var "vp_path_folder_timestamp_tests_logs_sublocal"     "\${vp_path_folder_timestamp_tests_logs}subprocesses_local/";
f_arrays_set_var "vp_path_folder_timestamp_tests_logs_subremote"    "\${vp_path_folder_timestamp_tests_logs}subprocesses_remote/";

# Always include this variable as the framework uses it to resolve the log folder path.
f_arrays_set_var "vp_path_folder_logs" "\${vp_path_folder_timestamp_tests}logs/";

# Remote server paths.
f_arrays_set_var "vp_path_file_prometheus"       "\${vp_help_flags_prompath}\${vp_help_flags_promname}";
f_arrays_set_var "vp_path_file_prometheus_sping" "\${vp_help_flags_prompath}sping_\${vp_help_flags_promname}";
f_arrays_set_var "vp_path_file_cronjob"    "\${vp_help_flags_cspath}\${vp_help_flags_csname}";
f_arrays_set_var "vp_path_file_prometheus_sping_raw"       "/tmp/network-connectivity-checker-ping-stats.txt";

# ---------------------------------------------------------------
# [3] Initialise any project global variables.

f_arrays_set_var "vp_total_test_count" "0";

# ---------------------------------------------------------------
# [4] Perform remaining checks.

# Check tests json file path.
f_check_project_dependencies "4";
# Check inventory json file path.
f_check_project_dependencies "5";
# Check for scp.
f_check_project_dependencies "7";
};
EOF
};
function f_skeleton_S0_ui_banner(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/functions/fp_S0/fp_S0_ui_banner 
function fp_S0_ui_banner(){

# About:
# - Banner that is shown beneath the framework banner.
# - This is project specific and adapted from the template version of this function.

# Usage:
# fp_S0_ui_banner;
# - Add information as below as required to be shown.

local path_short_inventory;
local path_short_test;

declare -A A_paths_local
declare -A A_paths_remote

path_short_inventory=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "\${vp_help_flags_inventory}" "\${vf_path_framework_home}"); 
path_short_tests=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "\${vp_help_flags_tests}" "\${vf_path_framework_home}"); 

# Display project banner.
printf "%b\n" "\${yl}--> Project name:\${cy}         \${vj_project_name}";
printf "%b\n" "\${yl}--> Project repo:\${cy}         \${vj_project_repo}";
printf "%b\n" "\${yl}--> Project version:\${cy}      \${vj_project_version}\${rs}";
\${dashLine};
\${spacer};
printf "%b\n" "\${yl}--> Project started with these passed flags.\${rs}";
\${spacer};
printf "%b\n" "\${vf_args_passed}";
\${spacer};
printf "%b\n" "Note: for '\${yl}Flag overide\${rs}'";
printf "%b\n" "--> any passed flags with a different value to the json default will appear as an overide.";
printf "%b\n" "--> paths that are 'forward-slash-corrected' will appear as an overide. Check the json!";
printf "%b\n" "--> paths that are relative to the framework or project are resolved.";
printf "%b\n" "--> paths specified with '~/' are resolved using the environment variable \\${HOME}.";
\${spacer}; 
printf '%s\t\t %s\t %s\n' "\${cy}Flags (-short --long)" "\${yl}Flag overide?" "\${rs}Runtime-value";
\${dashLine};
for i in \${!A_json_help[@]}
do
    string="vj_help_flags_"
    charcount=$(f_utils_strings "count_chars" "\${i}" "_");
    stem=$(echo \${i} \| \${vf_cmd_sed} 's/_[^_]*$//');

    if [[ "\${i}" == *"\${string}"* ]] && [[ "\${charcount}" -eq 4 ]] && [[ "\${done_array[*]}" != *"\${stem}"* ]];then 
        
        longflag="$(echo \${i} | cut -f 4 -d_)";
        shortflag="\${A_json_help[\${stem}_shortflag]}";
        about="\${A_json_help[\${stem}_about]}";
        default="\${A_json_help[\${stem}_default]}";
        type="\${A_json_help[\${stem}_type]}";

        # This maybe different to the default value if the flag has been passed in.
        project_var="vp_help_flags_\${longflag}";

        # Paths are displayed below as they can span the entire screen. 
        if [[ "\${type}" == *"path_file_local"* ]] || [[ "\${type}" == *"path_folder_local"* ]];then
            A_paths_local["\${shortflag},\${longflag},\${default},\${type}"]="\${!project_var}";
        elif [[ "\${type}" == *"path_file_remote"* ]] || [[ "\${type}" == *"path_folder_remote"* ]];then
            A_paths_remote["\${shortflag},\${longflag},\${default},\${type}"]="\${!project_var}";
        elif [[ "\${!project_var}" != "\${default}" ]];then
            printf '%s\t %-20s\t %s\t\t %s\n' "\${cy}-\${shortflag}" "--\${longflag}" "\${yl}yes" "\${!project_var}\${rs}"; 
        else
            printf '%s\t %-20s\t %s\t\t %s\n' "\${cy}-\${shortflag}" "--\${longflag}" "\${rs}no " "\${!project_var}";
        fi;
        done_array+=( "\${stem}" );
    fi;
done
\${dashLine};

printf "%b\n" "\${yl}--> Project flags with local paths.\${rs}";
\${dashLine};
for i in \${!A_paths_local[@]}
do
    shortflag="$(echo \${i} | cut -d ',' -f1)";
    longflag="$(echo \${i}  | cut -d ',' -f2)";
    default="$(echo \${i}   | cut -d ',' -f3)";
    type="$(echo \${i}      | cut -d ',' -f4)";
    flag_value="$(echo \${A_paths_local[$i]})"; 
    suffix_path="";

    if [[ "\${type}" == *"path_file_local_relative_framework"* ]];then
        suffix_path="\${vf_path_framework_home}";
    elif [[ "\${type}" == *"path_file_local_relative_project"* ]];then
        suffix_path="\${vp_project_rootpath}";
    elif [[ "\${type}" == "path_file_local" ]] || [[ "\${type}" == "path_folder_local" ]];then
        
        if [[ "\${default}" == *"~/"* ]];then
        
            # Strip the tilde and forward slash and swap in the path to the user home.
            default=$(f_utils_strings_bpe "del_fromleft_upto_including" "\${default}" "~/");
            suffix_path="\${HOME}/";
        fi;
    fi;

    if [[ "\${flag_value}" != "\${suffix_path}\${default}" ]];then
        printf '%s\t %-20s\t %s\t\t %s\n' "\${cy}-\${shortflag}" "--\${longflag}" "\${yl}yes" "\${flag_value}\${rs}"; 
    
    else
        printf '%s\t %-20s\t %s\t\t %s\n' "\${cy}-\${shortflag}" "--\${longflag}" "\${rs}no " "\${flag_value}"; 

    fi;

done;

\${dashLine};
printf "%b\n" "\${yl}--> Project flags with remote paths.\${rs}";
\${dashLine};
for i in \${!A_paths_remote[@]}
do
    shortflag="$(echo \${i} | cut -d ',' -f1)";
    longflag="$(echo \${i}  | cut -d ',' -f2)";
    default="$(echo \${i}   | cut -d ',' -f3)";
    type="$(echo \${i}      | cut -d ',' -f4)";
    flag_value="$(echo \${A_paths_remote[$i]})"; 

    if [[ "\${flag_value}" != "\${default}" ]];then
        printf '%s\t %-20s\t %s\t\t %s\n' "\${cy}-\${shortflag}" "--\${longflag}" "\${yl}yes" "\${flag_value}\${rs}"; 
    else
        printf '%s\t %-20s\t %s\t\t %s\n' "\${cy}-\${shortflag}" "--\${longflag}" "\${rs}no " "\${flag_value}"; 
    fi;
done;
\${equalsLine};
};
EOF
};
function f_skeleton_jenkinsfiles(){

envf_array=( ref stag prod );

for i in ${envf_array[@]}
do
    printf "%b\n" "${yl}--> info - ${rs}${vf_path_framework_home}projects/${project_name}/pipelines/jenkins/${i}";
    sleep 0.2;
    mkdir -p "${vf_path_framework_home}projects/${project_name}/pipelines/jenkins/${i}";

mkdir -p "${vf_path_framework_home}projects/${project_name}/pipelines/jenkins/${i}";
cat << EOF > ${vf_path_framework_home}projects/${project_name}/pipelines/jenkins/${i}/Jenkinsfile
pipeline{
  agent { 
      docker{
      label '${i}'
      image 'smsc-bash-x:latest'
      registryUrl 'https://css-docker.artifactory.swisscom.com'
      registryCredentialsId 'artifactory-css'
      alwaysPull true
      }
  }
  environment {
    BITBUCKET_COMMON_CREDS = credentials('artifactory-css')
  }
  stages {
      stage('Select branch and environment to deploy'){
          steps {
              sh "rm -f branches.txt && git branch -r | sort -r > branches.txt"
              sh "sed -i '1s/^/bash-x\\/master\\n/' branches.txt"
              script{
                featurebranchlist = readFile 'branches.txt'
                timeout(time: 300, unit: 'SECONDS'){
                deploymentparam = input message: 'Please choose the branch to deploy', ok: 'Ok',
                                      parameters: [ 
                                                      choice(choices: '${i}', description: '', name: 'env'),
                                                      choice(choices: "\${featurebranchlist}", name: 'branch') 
                                                  ]
                }
              env.BRANCH = deploymentparam.branch.replaceAll(" ","");
            }
        }
      }
      stage("Make user selections"){
      steps{
          sh "pwd; ls -la";
          sh "git checkout -b + \${env.BRANCH}";
          sh "rm -rf inventory.txt && find inventory/TC6000/prod -type f -name '*.json' > inventory.txt";
          sh "rm -rf tests.txt && find projects/network-connectivity-checker/json/tests/TC6000/${i} -type f -name '*.json' > tests.txt";
          script {
            inventoryList = readFile 'inventory.txt'
            testsList   = readFile 'tests.txt'
            timeout(time: 300, unit: 'SECONDS'){
            deploymentparam = input message: 'Pipeline options...', ok: 'Ok',
                                parameters: [ choice(choices: "\${inventoryList}",description: 'Required: The inventory json file to use.', name: 'inventory'),
                                            choice(choices: ['false','true'],  description: 'Optional: Delete bash-x folder from remote VMs.', name: 'tidyup'),
                                            choice(choices: ['false','true'],  description: 'Optional: Delete checkerscript + prometheus files from remote VMs.', name: 'tidyupproject'),
                                            choice(choices: ['true', 'false'], description: 'Optional: Display output using colors.', name: 'colordisplay'),
                                            choice(choices: ['','--FASTFAIL'], description: 'Optional: Select flag to exit project on first failure.', name: 'fastfail') ,
                                            string(defaultValue: '', description: 'Optional: Limit with a comma separated string. E.g: for cluster1 and tcsmsc-21 only: \'tcsmsc-stag1,tcsmsc-stag21\'', name: 'limit'),
                                            string(defaultValue: '', description: 'Optional: Skip stages. For example, if removing framework and project files, only run stages 1,6 and 7. Skip: \'2,3,4,5\'', name: 'skipstages') ]
            }
            env.DEPLOY = '${i}';
            env.INVENTORY = deploymentparam.inventory;
            env.TIDYUP = deploymentparam.tidyup;
            env.TIDYUPPROJECT = deploymentparam.tidyupproject;
            env.FASTFAIL = deploymentparam.fastfail;
            env.COLORDISPLAY = deploymentparam.colordisplay;
            env.LIMIT = deploymentparam.limit.replaceAll("[\\t\\n\\r]+",",");
            env.SKIPSTAGES = deploymentparam.skipstages.replaceAll("[\\t\\n\\r]+",",");
    
            if (env.LIMIT != '') {
                env.LIMIT = '--LIMIT '+ env.LIMIT
            }
    
            if (env.SKIPSTAGES != '') {
                env.SKIPSTAGES = '--SKIPSTAGES '+ env.SKIPSTAGES
            }
  
          }
          ansiColor('xterm'){
          echo "**********************************************************";
          echo 'Jenkins JOB_BASE_NAME: '+ env.JOB_BASE_NAME
          echo 'Jenkins JOB_NAME:      '+ env.JOB_NAME
          echo 'Environment:           '+ env.DEPLOY
          echo 'Git branch:            '+ env.BRANCH
          echo "**********************************************************";
          echo "Running the 'bash-x' bash framework:"
          echo 'Framework flags:'
          echo '--PROJECT              project-name'
          echo '--COLORDISPLAY         '+ env.COLORDISPLAY
          echo '--FASTFAIL             '+ env.FASTFAIL
          echo '--LIMIT                '+ env.LIMIT
          echo '--SKIPSTAGES           '+ env.SKIPSTAGES
          echo 'Project flags:'
          echo '--inventory            '+ env.INVENTORY
          echo '--tests                '+ env.TESTS
          echo '--tidyup               '+ env.TIDYUP
          echo '--tidyupproject        '+ env.TIDYUPPROJECT
          echo '--authapproach         jenkins_user_pass'
          echo "**********************************************************";
          }
          script{
          timeout(time: 300, unit: 'SECONDS'){input message: 'OK to proceed?', ok: 'Ok'}
          }
          
          sh ("rm -rf inventory.txt tests.txt branches.txt")
          withCredentials([usernamePassword(credentialsId: "platform-creds-${i}", passwordVariable: 'PASSWORD', usernameVariable: 'USERNAME')]) {
          sh("./lib/bash-x --PROJECT project-name \\
          --COLORDISPLAY \${env.COLORDISPLAY} \\
          --LIMIT \${env.LIMIT} \\
          --SKIPSTAGES \${env.SKIPSTAGES} \\
          --FASTFAIL \${env.FASTFAIL} \\
          --inventory \${env.INVENTORY} \\
          --tidyup \${env.TIDYUP} \\
          --tidyupproject \${env.TIDYUPPROJECT} \\
          --authapproach jenkins_user_pass \\
          --sshuser devops \\
          --sshtargetpath /home/devops/ \\
          --sshinterface default")
        }
      }
    }
  }
  post{
      always{
      cleanWs()
      }
   }
}
EOF
done;
};
function f_skeleton_multipids_create(){

cat << EOF > "${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_create"
function fp_multipids_create(){

# ---------------------------------------------------------------
# [1] These variables are local to this function.

local loop_source_hostname;
local loop_source_domain;
local loop_source_interface;
local loop_source_pubIp;
local loop_source_gateway;
local string_domain;
local string_gateway;

# ---------------------------------------------------------------
# [2] Add any tests to ensure required arrays are not empty.

# In this example '2' matches to error code '2' for the current stage ('0') as defined in 'errors.json'. 
if [[ "\${#A_array_to_test[@]}" -eq "0" ]];then 
    f_errors_exitmessages "\${FUNCNAME[0]}: $((LINENO))" "2" "";  
fi;

# ---------------------------------------------------------------
# [3] Create the array that will be looped through for the project stages.

# Below is an example of how to create an array of all the servers to connect to.
# The array of all variables 'A_variables_all' is filtered and the values are put into a new array.
# - The name of the new array is the first passed parameter.
# To adapt this for your project:
#  - Change the use of 'f_arrays_filter' as required.
#  - Or instead directly handle the required project array to obtain the desired loopable structure. 
# Note:
# - 'A_loop_array' has already been declared by the framework.
# - If using another name ensure to add it first to the project's 'arrays.json'.

# This example of 'f_arrays_filter' function will:
# - Filter the array of all variables 'A_variables_all' into a new array called 'A_loop_array'.
# - Match all clusters with the '*'.
# - Match all hostnames starting with 'abcd-'. 
f_arrays_filter "A_loop_array" "vj_inventory_servers_*_service_\${vf_framework_flags_ssh_interface}_abcd-";

# Loop through the filtered array to run the stage functions as sub-processes.
for i in \${!A_loop_array[@]}
do

    # Take these from the json string key, as used in the filter function example above.
    loop_source_parent="$(echo   \${i} | cut -d '_' -f4)";
    loop_source_hostname="$(echo \${i} | cut -d '_' -f7)";
    # This is the value of the key for the hostname.
    loop_source_pubIp="$(echo    \${A_loop_array[\${i}]})";

    # Create strings to use with the inventory array.
    # The parent is the grouping or cluster that the 'source_hostname' belogs to, e.g. 'ref1' or 'ref2'.
    string_domain="vj_inventory_servers_\${loop_source_parent}_service_\${vf_framework_flags_ssh_interface}_domain"; 
    string_gateway="vj_inventory_servers_\${loop_source_parent}_service_\${vf_framework_flagss_sshinterface}_gateway";  
    
    # Grab the domain, interface and gateway for the specified interface that will be used to connect to each source server.
    # These values are all held in the 'A_variables_inventory' array (or use the 'A_variables_all' array).
    loop_source_domain="\${A_variables_inventory[\${string_domain}]}";
    loop_source_gateway="\${A_variables_inventory[\${string_gateway}]}";

    # For each source server run the stage functions as a subprocess and pipe output to a local 'source_hostname' specific log file.
    f_stages_functions >> "\${vp_path_folder_timestamp_tests_logs_sublocal}\${loop_source_hostname}.log" 2>&1 &
    pid=\${!};
    details="\${loop_source_hostname}\${loop_source_domain},\${loop_source_interface},\${loop_source_pubIp},\${vp_stage_number}";
    
    # This array will be used by all the other multipid functions.
    A_stage_pid_details["\${pid}"]="\${details}";

done;
};
EOF
};
function f_skeleton_multipids_display_details(){

cat << EOF > "${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_details";
function fp_multipids_display_details(){

# About:
# - This function displays the details of each pid as it is being run.
# - The array 'A_stage_pid_details' is populated by the 'fp_multipids_create' function.
# - The key is the unique pid id and the standard value is:
#   "\${loop_source_hostname}\${loop_source_domain},\${loop_source_interface},\${loop_source_pubIp},\${vp_stage_number}";  
# - Additional values may have been added after these.

# Template instructions:
# - Use as is or adapt below what is displayed for this stage.

printf "\n%b\n" "\${cyB}--> \${vp_stage_concurrentMsg_value}\${rs}";   
for i in "\${!A_stage_pid_details[@]}"
do
    stageid="\$(echo \${A_stage_pid_details[\${i}]} | cut -d ',' -f4)";
    if [[ "\${vp_stage_number}" == "\${stageid}" ]];then    
        
        source_hostname="\$(echo  \${A_stage_pid_details[\${i}]} | cut -d ',' -f1)";
        source_interface="\$(echo \${A_stage_pid_details[\${i}]} | cut -d ',' -f2)";
        source_pubIp="\$(echo     \${A_stage_pid_details[\${i}]} | cut -d ',' -f3)";

        \${dashLine};
        printf "%b\n" "\${yl}--> Info - \${rs}PID:                 \${i}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote hostname:     \${source_hostname}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote pubIp:        \${source_pubIp}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote interface:    \${source_interface}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote folder:       \${SSH_PATH_TARGET}\${vj_framework_name}";
    fi;
done;
\${spacer}; 
printf "%b\n" "\${cyB}--> Results to follow..\${rs}";
};
EOF
};
function f_skeleton_multipids_display_details_S1(){

cat << EOF > "${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_details_S1"
function fp_multipids_display_details_S1(){

# This function is the same as the 'fp_multipids_display_details' but with the stage number appended '_S1'.
# It optionally allows the stage to display different info for its sub processes.
# For each stage run with sub-processess, it checks for the existence of a function with its stage number appended '_Sx'.
# If no bespoke function exists, it defaults to the function 'fp_multipids_display_details'. 

printf "\n%b\n" "\${cyB}--> \${vp_stage_concurrentMsg_value}\${rs}";   
for i in "\${!A_stage_pid_details[@]}"
do
    stageid="$(echo \${A_stage_pid_details[\$i]} | cut -d ',' -f4)";
    if [[ "\${vp_stage_number}" == "\${stageid}" ]];then    
        source_hostname="$(echo \${A_stage_pid_details[\${i}]}  | cut -d ',' -f1)";
        source_interface="$(echo \${A_stage_pid_details[\${i}]} | cut -d ',' -f2)";
        source_pubIp="$(echo \${A_stage_pid_details[\${i}]}     | cut -d ',' -f3)";

        \${dashLine};
        printf "%b\n" "\${yl}--> Info - \${rs}PID:                 \${i}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote hostname:     \${source_hostname}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote pubIp:        \${source_pubIp}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote interface:    \${source_interface}";
        printf "%b\n" "\${yl}--> Info - \${rs}Remote folder:       \${SSH_PATH_TARGET}\${vj_framework_name}";
    fi;
done;
\${spacer}; 
printf "%b\n" "\${cyB}--> Results to follow..\${rs}";
};
EOF
};
function f_skeleton_multipids_display_fail(){

cat << EOF > "${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_fail"
function fp_multipids_display_fail(){

local count;
local stageid;
local source_hostname;
local source_pubIp;
local source_test;
local source_interface;
local json_code;
local message;
local hint;

\${spacer};
printf "%b\n" "\${rdB}--> Showing failed pids..\${rs}";

count=0;
for i in "\${!A_stage_pid_fails[@]}"
do
    stageid="$(echo \${A_stage_pid_details[$i]} | cut -d ',' -f4)";
    if [[ "\${vp_stage_number}" == "\${stageid}" ]];then 
        ((count++));
    fi;
done;

if [[ \${#A_stage_pid_fails[@]} -ne 0 ]] && [[ \${count} -gt 0 ]];then

    for i in "\${!A_stage_pid_fails[@]}"
    do
        stageid="$(echo \${A_stage_pid_details[$i]} | cut -d ',' -f4)";
        if [[ "\${vp_stage_number}" == "\${stageid}" ]];then    
            source_hostname="$(echo \${A_stage_pid_details[\${i}]}   | cut -d ',' -f1)";
            source_interface="$(echo \${A_stage_pid_details[\${i}]}  | cut -d ',' -f2)";
            source_pubIp="$(echo \${A_stage_pid_details[\${i}]}      | cut -d ',' -f3)";

            json_code="$(echo vj_\${A_stage_pid_fails[\${i}]}  | cut -d ',' -f1)";
            message="$(echo \${A_stage_pid_fails[\${i}]}       | cut -d ',' -f2)";
            hint="$(echo \${A_stage_pid_fails[\${i}]}          | cut -d ',' -f3)";
            
            # Check if hint is a variable - if so use '!' for indirection to resolve to value.
            if [[ \${hint} == "vf_"* ]] || [[ \${hint} == "vp_"* ]] || [[ \${hint} == "vj_"* ]]; then hint=\${!hint}; fi;

            \${dashLine};
            printf "%b\n" "\${yl}--> Info - \${rs}PID:                 \${i}";
            printf "%b\n" "\${yl}--> Info - \${rs}Remote hostname:     \${source_hostname}";
            printf "%b\n" "\${yl}--> Info - \${rs}Remote pubIp:        \${source_pubIp}";
            printf "%b\n" "\${yl}--> Info - \${rs}Remote interface:    \${source_interface}";
            printf "%b\n" "\${yl}--> Info - \${rs}error.json:          \${json_code}";
            printf "%b\n" "\${yl}--> Info - \${rs}Message:             \${message}";
            printf "%b\n" "\${yl}--> Info - \${rs}Hint:                \${hint}";
        fi;
    done;

else
    printf "%b\n" "\${yl}--> Info - \${rs}All pids were successful!";
fi;
};
EOF
};
function f_skeleton_multipids_display_success(){

cat << EOF > "${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_display_success"
function fp_multipids_display_success(){

local count;
local stageid;
local pid;
local source_hostname;
local source_pubIp;
local source_test;
local source_interface;

\${spacer};
printf "%b\n" "\${grB}--> Showing successful pids..\${rs}";

# For the current stage count the number of successful pids.
count=0;
for pid in \${a_stage_pid_success[@]}
do
    stageid="$(echo \${pid} | cut -d '_' -f2)";
    if [[ "\${vp_stage_number}" == "\${stageid}" ]];then
        ((count++));
    fi;
done;

if [[ \${count} -gt 0 ]];then

    for pidstage in "\${a_stage_pid_success[@]}"
    do
        pid="$(echo \${pidstage} | cut -d '_' -f1)";
        stageid="$(echo \${pidstage} | cut -d '_' -f2)";
        if [[ "\${vp_stage_number}" == "\${stageid}" ]];then 
            source_hostname="$(echo \${A_stage_pid_details[\${i}]}   | cut -d ',' -f1)";
            source_interface="$(echo \${A_stage_pid_details[\${i}]}  | cut -d ',' -f2)";
            source_pubIp="$(echo \${A_stage_pid_details[\${i}]}      | cut -d ',' -f3)";

            \${dashLine};
            printf "%b\n" "\${yl}--> Info - \${rs}PID:                 \${pid}";
            printf "%b\n" "\${yl}--> Info - \${rs}Remote hostname:     \${source_hostname}";
            printf "%b\n" "\${yl}--> Info - \${rs}Remote pubIp:        \${source_pubIp}";
            printf "%b\n" "\${yl}--> Info - \${rs}Remote interface:    \${source_interface}";
            
        fi;
    done;

else
    printf "%b\n" "\${yl}--> Info - \${rs} All pids failed!";
fi;
};
EOF
};
function f_skeleton_multipids_wait(){

cat << EOF > "${vf_path_framework_home}projects/${project_name}/lib/functions/fp_multipids/fp_multipids_wait"
function fp_multipids_wait(){

# Loop through each pid.
for p in "\${!A_stage_pid_details[@]}"
do
  stageid="$(echo \${A_stage_pid_details[\${p}]} | cut -d ',' -f4)";
  if [[ "\${vp_stage_number}" == "\${stageid}" ]];then
  
    # [1] If pid is still running wait for it to complete.
    if wait \${p}; then
      errcode="\${?}";
      if [[ "\${errcode}" == "0" ]];then
        a_stage_pid_success+=(\${p}_\${vp_stage_number});
      else              
        json_err_code="errors_s\${vp_stage_number}_e\${errcode}";
        json_err_message="vj_\${json_err_code}_message";
        json_err_hint="vj_\${json_err_code}_hint";
        A_stage_pid_fails[\${p}]="\${json_err_code},\${!json_err_message},\${!json_err_hint}";
        f_errors_exitmessages "\${FUNCNAME[0]}: $((LINENO))" "\${errcode}" "\${p}";  
      fi;
      
    # [2] If pid has finished with a fail. 
    else
      errcode="\${?}";    
      json_err_code="errors_s\${vp_stage_number}_e\${errcode}";
      json_err_message="vj_\${json_err_code}_message";
      json_err_hint="vj_\${json_err_code}_hint";
      A_stage_pid_fails[\${p}]="\${json_err_code},\${!json_err_message},\${!json_err_hint}";
      f_errors_exitmessages "\${FUNCNAME[0]}: $((LINENO))" "\${errcode}" "\${p}";  
    fi;
  fi;
done;
};
EOF
};
function f_skeleton_project_jsonarrays(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/functions/fp_project_custom_json
function fp_project_custom_json(){

# About:
# - This function is called by the framework function 'f_json_recurse' to process any project specific json files.
# - 'f_json_recurse' calls this function in a CASE statement for any match other than predefined framework json files. 
# - These are the predefined json files with their respective match patterns. 
#   - 'framework.json', 'project.json', 'arrays.json','help.json' and 'errors.json'.
#   - 'vj_framework', 'vj_project', 'vj_arrays', 'vj_help' and 'vj_errors'.
# - So the above names are protected and are not available for project specific json that is handled below. 

# ---------------------------------------------------------------
# [1] Declare local variables.

local key;
local value;

# ---------------------------------------------------------------
# [2] Assign the key and value params passed by 'f_json_recurse'. 

key="\${1}";
value="\${2}";

# When a json file is processed, two variables a created.
# One is prepended with 'vj_' and a copy of this is prepended with 'vp_'.
# The 'vj_' version is a representation of what is in the json file and should never have its value reassigned.
# The 'vp_' value can be reassigned by say the presence of a passed flag or if a certain condition is met.
# As such the 'vp_' version of the variable should be the one that is referenced in downstrem logic, unless the json value is specifically required.


# Instructions: 
# - If project does not use any bespoke json files then there is nothing to do here :)
# - If project does have bespoke json files then repeat the following example CASE block to handle each one.
# - Change the array name in [A] and make sure this array is declared in arrays.json
# - [B,C,D] do not need to be changed. 
# - Note that the last line in each CASE staement block finishes with two semi-colons!

# ---------------------------------------------------------------
# [3] Select the project arrays to populate based on the key. 

case "\${key}" in

  # ---------------------------------------------------------------
  # These matches are reserved and unavailable!
  
  # vj_framework*)
  # vj_project*)
  # vj_arrays*) 
  # vj_help*) 
  # vj_errors*)

  # ---------------------------------------------------------------
  "vj_tests"*)

    # [A] Add the key value pair to a bespoke project array.
    A_variables_tests["\${key}"]="\${value}";

    # [B] Declare the key value pair as a bash variable and add to array of all variables - 'A_variables_all'
    f_arrays_set_var "\${key}" "\${value}";
    
    # [C] Remove the prefix 'vj_' and add the prefix 'vp_'.
    key=$(f_utils_strings_bpe "del_fromleft_upto_including_first" "\${key}" "_");
    
    # [D] Declare this project variable ('vp_') as a bash variable.
    # Also add it to the array of all project variables - 'A_project_vars'
    f_arrays_set_var "vp_\${key}" "\${value}";;

esac;
};
EOF

};
function f_skeleton_readme(){
cat 2>/dev/null << EOF > ${vf_path_framework_home}projects/${project_name}/README.md
# Project: network-connectivity-checker

***    

<a name="MENU"></a>
# Quick links:
   
1. [About](#AB)        
1. [Local 'install'](#LI)            
1. [Project setup](#PS)  
1. [Project json](#PJ)                      
1. [CI/CD setup](#CICD)               
1. [Project --HELP screen](#PH)     

***

<a name="AB"></a>
[menu](#MENU)          
## About.     

- This project runs using the 'bash-x' framework.   
- It does this....       
- etc        

***

<a name="LI"></a>
[menu](#MENU)           
## Local 'install'.      

- Pull the bash-x framework repository and this project is contained within it.    

```
$ git clone https://git.swisscom.com/scm/MMO/bash-x.git
```       

- For framework setup and background information refer to the [bash-x README.](https://git.swisscom.com/scm/MMO/bash-x/README.md)     
    - This explains how to setup the framework on the local machine.    
    - Provides background to the framework structure and how its projects work.    
- For framework and project help screens use these commands.    

```
$ bash-x --HELP    
$ bash-x --PROJECT project-name --HELP
```      

***

<a name="PS"></a>    
[menu](#MENU)         
## Project setup.        

Project setup involves these json files.    

1. **inventory.json**.       
     - This file contains the ips of all the servers that are connected to.    
1. **help.json**.     
     - The values here determine the default settings for the project flags.    
     - You can see all the project flags in the screenshot in the below [--HELP section](#PH).    
     - Select the **authapproach** and define the **ssh** flags.     
     - Alternatively pass these parameters as runtime flags.             
1. **project_file1.json**.    
     - This project file is used for..   

***    

<a name="PJ"></a>
[menu](#MENU)          
## Project json.  

- All bash-x framework projects require four json files.    
- These are found in the subfolder **projects/project_name/json/project/**    
- Only the **help.json** should be modified by a user of the project in order to set defaults for project flags.    
- The other three json files are specified by the project developer and should not be changed.    

1. **project.json**          
    - The definition of the project stages.    
1. **arrays.json**          
    - The declaration of all arrays used in the project.    
1. **errors.json**          
    - The declaration of all error codes used in each stage of the project.    
1. **help.json**            
    - The file used to generate the help screen for the project and where the flag defaults are set.     

***

<a name="CICD"></a>        
[menu](#MENU)         
## CI/CD pipelines.       

This project can be run locally or from a CI/CD pipeline (e.g. Jenkins, Gitlab etc).

- The project includes Jenkins files for running in Prod, Stag and Ref environments.    
- When run the pipeline pulls a container and also the **bash-x** repository.       
- The pipeline UI allows runtime selections to be made.         
- After the pipeline is run, it takes a couple of minutes for the results to appear in prometheus / Grafana.       

***

<a name="TJ"></a>    
[menu](#MENU)         
## Heading two.  

### Sub heading three.

- etc    
- etc     
      
### Definition of a test.

- etc   
- etc    

***
<a name="PH"></a>     
[menu](#MENU)         
## Project --HELP screen.    

![bash-x](README_IMAGES/readme_image1.png){height=1836 width=1398}
EOF
};
function f_skeleton_stage_alterations(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/functions/fp_project_custom_runorder
function fp_project_custom_runorder(){

# About:
# - Perform logic before running a stage.
# - Enables flags or conditions to alter program flow.
# - Here the array 'A_json_stages' can be altered  to reassign the functions that are called.
# - e.g. A_json_stages["vj_stages_s1_t1_f1"]="fp_S1_function_to_run";
# - To ignore a function already defined in project.json 
#   - assign it to nothing.
#   - or perhaps reassign it to a screen msg display function.

# Usage:
# fp_project_custom_runorder;
# - no passed params.

# ---------------------------------------------------------------
# [1] Handle case statement based on the current stage number.

# Case statement to handle any passed flags or conditions that change program flow.
case "\${vp_stage_number}" in

    # ---------------------------------------------------------------
    # If not making any stage alterations then uncomment the asterix option.
    # - then for all stages no changes will be applied.
    # *)
        # :
        # ;;
    # ---------------------------------------------------------------
    "HELP")
        printf "%b\n" "\${yl}--> Info - \${rs}This project's stages can be skipped using the framework's '--SKIPSTAGES' flag. See example above.";
        printf "%b\n" "\${yl}--> Info - \${rs}Note all stages are dependent on stage 1.";
        \${spacer};;

    # ---------------------------------------------------------------
    "2")
        # If showstats flag is false, dont display tests stats and tests table.
        skip="false";
        if [[ "\${vf_framework_flags_behaviour_skipstages}" == "true" ]];then
            for k in \${a_skipstages[@]}
            do
                if [[ "\${k}" == "2" ]];then
                    skip="true";
                fi;
            done;
        fi;
        if [[ "\${skip}" == "true" ]] || [[ "\${vp_help_flags_showstats}" == "false" ]];then 
            # Append to the skipstages array.
            a_skipstages+=( '2' );
        fi;;

    # ---------------------------------------------------------------
    "5_remote1")
        
        skip="false";
        if [[ "\${vf_framework_flags_behaviour_skipstages}" == "true" ]];then
            for k in \${a_skipstages[@]}
            do
                if [[ "${k}" == "5_remote1" ]];then
                    skip="true";
                fi;
            done;
        fi;
        if [[ "\${skip}" == "true" ]];then 
            # Append to the skipstages array.
            a_skipstages+=( '5_remote1' );
        fi;;

    esac;
};
EOF

};
function f_skeleton_start(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/fp_project_start
function fp_project_start(){ 

# About:
# - This function is the starting point for the project. 
# - It is still part of stage 0 (framework and project initiation).
# - It runs checks, assisgns variables and finally calls the stages with their tasks and functions that make up the project.
# - Any changes to the runtime ordering / execution of stage functions is handled in the file functions/fp_project_custom_runorder 

# ---------------------------------------------------------------
# [1] For any project paths defined in help.json or passed as flags.
# - remove occurences of double forward slashes.
# - ensure folder paths end with a forward slash.

f_arrays_paths_clean_project;

# ---------------------------------------------------------------
# [2] Check local commands are available.

f_check_project_dependencies "check_cmd_available";   

# ---------------------------------------------------------------
# [3] Declare all project variables that can be set this early.

fp_S0_set_vars;

# ---------------------------------------------------------------
# [4] Create and clear local logs.

# Create timestamped log folders if they do not already exist.
fp_S0_logs_create;

# Remove local log folders based on the framework flag --LOGLIFEMINS.
f_utils_logs_rotate "folder_writetime" "\${vp_project_rootpath}input_output/" "\${vp_help_flags_loglifemins}";

# From this point forwards write all screen output to the local file 'console.log'.
# Any subprocesses run locally will write to a separate log.
exec > >(tee -a "\${vp_path_folder_timestamp_tests_logs}console.log");

# Display to screen the project banner.
fp_S0_ui_banner;

# ---------------------------------------------------------------
# [5] Call the loop to run each stage defined in 'project.json'. 

f_stages_loop;

# ---------------------------------------------------------------
# [6] Call the final stage to display a summary and exit.

f_stages_functions_final;
};
EOF
};
function f_skeleton_start_remote(){

cat << EOF > ${vf_path_framework_home}projects/${project_name}/lib/fp_project_start_remote
function fp_project_start_remote(){ 

# About:
# - The starting point for the project when run remotely.
# - This function is called from the function fp_project_start.

# ---------------------------------------------------------------
# [1] For any project paths defined in help.json or passed as flags.
# - remove occurences of double forward slashes.
# - ensure folder paths end with a forward slash.

f_arrays_paths_clean_project;

# ---------------------------------------------------------------
# [2] Check remote commands are available.

# f_check_project_dependencies_remote "check_cmd_available";   

# ---------------------------------------------------------------
# [3] Declare all remote project variables that can be set this early.

# fp_S0_set_vars_remote;

# ---------------------------------------------------------------
# [4] Create log folders/files and start logging.

# Remote logs are structured differently to local logs. 
# - They are retrieved and brought back to the local server.
# - The folders are timestamped on the local server but not the remote server.
# - As with the local logs, the screen output on the remote server is written to the console.log file.
# - The hostname of the remote server is added to the name of the console.log file to distinguish it.
# - This project does not use subprocesses on remote machines and hence no log setup for this. 

fp_S5_remote_create_logs;

# From now on all screen output is logged to the console log file.
exec > >(tee -a "\${vp_project_rootpath}input_output/logs/console_\${vf_local_hostname_short}.log");

# ---------------------------------------------------------------
# [5] Display the banner - this will be shown in the log file.

fp_S0_ui_banner;

# ---------------------------------------------------------------
# [6] Call the remote stage(s). 

f_stages_loop_remote;

# ---------------------------------------------------------------
# [7] Return the exitcode to the awaiting local 'f_multipids_wait' function.

# - Exit codes can pass back only a numeric between 0-255 - e.g. exit 5
# - The awaiting 'f_multipids_wait' will capture this on the local server.
# - In the event of a failure, the combination of stage number (added by the awaiting function) and the exit code will resolve to the value in the project's 'error.json'. 

exit "\${vf_status_exitcode}";
};
EOF
};
declare -A A_framework_vars; declare -A A_project_vars; declare -A A_framework_json; declare -A A_project_json; declare -A A_json_stages; declare -A A_json_arrays; declare -A A_json_help; declare -A A_json_errors; declare -A A_variables_all; declare -A A_variables_all_empty; declare -a a_variables_all_ordered; declare -A A_framework_stage_errcodes; declare -A A_framework_stage_errcodes_optional; declare -A A_dependency_checked; declare -A A_dependency_installed; declare -A A_dependency_checked_project; declare -A A_dependency_installed_project; declare -A A_dependency_checked_project_execute; declare -A A_dependency_checked_project_make; declare -A A_dependency_installed_project_execute; declare -A A_dependency_installed_project_make; declare -A A_metadata; declare -a a_metadata_ordered; declare -a a_multipds_runorder; declare -A A_json_project_template; declare -A A_stage_pid_details; declare -A A_stage_pid_fails; declare -a a_stage_pid_success; declare -A A_source_servers; declare -A A_project_stage_errors; declare a_limit; declare a_skipstages; declare -a A_correction_titles; declare -a A_correction_values; vf_path_before="${PATH}"; vf_script_name=$(basename "$0"); vf_script_path="$(readlink -f "${BASH_SOURCE[0]}" 2>/dev/null || greadlink -f "${BASH_SOURCE[0]}")"; vf_path_framework_home="$(dirname "${vf_script_path}")"; vf_path_framework_home="${vf_path_framework_home}/"; vf_path_framework_parent=$(dirname "${vf_path_framework_home}"); vf_path_framework_gparent=$(dirname "${vf_path_framework_parent}"); if [[ "${vf_path_framework_home}" == *"/bash-x-dev/lib/"* ]];then   vf_path_framework_home="${vf_path_framework_parent}/"; vf_path_framework_parent="${vf_path_framework_gparent}/"; vf_framework_source_list="$(find ${vf_path_framework_home}lib/functions -name "*" ! -name ".DS_Store")"; for file in $(printf "%s\n" "${vf_framework_source_list}"); do [ -f $file ] && . $file; done; else   vf_bashx_minified="true"; fi; raw_bash_version=$(bash --version); regex="v?([0-9]+(\.[0-9]+)+)"; [[ ${raw_bash_version} =~ ${regex} ]]; version_number="${BASH_REMATCH[0]}"; vf_bash_version=$(echo "${version_number}" | sed 's/[^0-9.]//g'); if [[ ${vf_bash_version:0:1} < 4 ]]; then   if [[ $BASH_UPGRADE_ATTEMPTED != 1 ]]; then     export BASH_UPGRADE_ATTEMPTED=1; export PATH=/usr/local/bin:"$PATH":/bin; exec "$(which bash)" --noprofile "$0" """$@"""; else     export OLD_BASH=1; fi; fi; if [[ ${vf_bash_version:0:1} -lt 4 ]]; then   f_arrays_set_var "vf_dynamic_error_msg" "Bash version less than 4. On Mac use --SETUP flag to resolve issue with Homebrew."; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "bashx"; fi; vf_os_identify=$(f_utils_os); if [[ "${1}" == "-S" ]] || [[ "${1}" == "--SETUP" ]]; then     f_display_colors "true"; f_display_banner; f_setup; exit 0; fi; if [[ "${vf_os_identify}" == "Mac" ]]; then     command=$(/usr/local/bin/jq --version 2>/dev/null); if [[ $? == 0 ]];then       export PATH=/usr/local/bin:$PATH; jq="/usr/local/bin/jq"; else       command=$(/opt/homebrew/bin/jq --version 2>/dev/null); if [[ $? == 0 ]];then         export PATH=/opt/homebrew/bin:$PATH; jq="/opt/homebrew/bin/jq"; else           f_arrays_set_var "vf_dynamic_error_msg" "Install Homebrew package manager with --SETUP flag"; f_errors_exitmessages_framework "${FUNCNAME[0]}: $((LINENO))" "bashx"; fi; fi; vf_cmd_sed=$(which gsed) >/dev/null 2>&1 || vf_cmd_sed="gsed"; vf_cmd_date=$(which gdate) >/dev/null 2>&1 || vf_cmd_date="gdate"; vf_cmd_awk=$(which gawk) >/dev/null 2>&1 || vf_cmd_awk="gawk"; vf_cmd_grep=$(which ggrep) >/dev/null 2>&1 || vf_cmd_grep="ggrep"; vf_cmd_iproute=$(which ip) >/dev/null 2>&1 || vf_cmd_iproute="ip"; vf_cmd_docker=$(which docker) >/dev/null 2>&1 || vf_cmd_docker="docker"; vf_local_ip="$(ifconfig | grep "inet " | grep -Fv 127.0.0.1 | awk '{print $2}')"; else     installed=$(which jq); if [[ $? == 0 ]];then       export JQ_HOME=$(f_utils_strings_bpe "keep_fromleft_upto_excluding" ${installed} "/"); jq="${installed}"; else       vf_architecture=$(uname -m); if [[ "$vf_architecture" == *"x86_64"* ]];then         export JQ_HOME="${vf_path_framework_home}jq/x86_64"; elif [[ "$vf_architecture" == *"x86_32"* ]];then         export JQ_HOME="${vf_path_framework_home}jq/x86_32"; elif [[ "$vf_architecture" == *"aarch64"* ]] || [[ "$vf_architecture" == *"arm64"* ]];then         export JQ_HOME="${vf_path_framework_home}jq/arm64"; else         export JQ_HOME="${vf_path_framework_home}jq/arm32"; fi; export PATH=$JQ_HOME:$PATH; jq="${JQ_HOME}/jq"; fi; vf_cmd_sed="$(which sed)"     >/dev/null 2>&1 || vf_cmd_sed="sed"; vf_cmd_date="$(which date)"   >/dev/null 2>&1 || vf_cmd_date="date"; vf_cmd_awk="$(which awk)"     >/dev/null 2>&1 || vf_cmd_awk="awk"; vf_cmd_grep="$(which grep)"   >/dev/null 2>&1 || vf_cmd_grep="grep"; vf_cmd_docker=$(which docker) >/dev/null 2>&1 || vf_cmd_docker="docker"; vf_cmd_iproute=$(which ip) >/dev/null 2>&1 ||     if [[ "${vf_os_identify}" == "Centos" ]] || [[ "${vf_os_identify}" == "Redhat" ]]; then        vf_cmd_iproute="/usr/sbin/ip"; else       vf_cmd_iproute="/sbin/ip"; fi; vf_local_ip="$(/bin/hostname -I | awk '{print $1}')"; fi; f_json_recurse "$(cat ${vf_path_framework_home}json/framework.json)" "vj"; f_arrays_set_var "vf_path_before"           "${vf_path_before}"; f_arrays_set_var "vf_script_name"           "${vf_script_name}"; f_arrays_set_var "vf_script_path"           "${vf_script_path}"; f_arrays_set_var "vf_path_framework_home"   "${vf_path_framework_home}"; f_arrays_set_var "vf_path_framework_parent" "${vf_path_framework_parent}"; f_arrays_set_var "vf_bashx_minified"        "${vf_bashx_minified}"; f_arrays_set_var "vf_framework_source_list" "${vf_framework_source_list}"; f_arrays_set_var "vf_bash_version"          "${vf_bash_version}"; f_arrays_set_var "vf_os_identify"           "${vf_os_identify}"; f_arrays_set_var "jq"                       "${jq}"; f_arrays_set_var "vf_cmd_sed"               "${vf_cmd_sed}"; f_arrays_set_var "vf_cmd_date"              "${vf_cmd_date}"; f_arrays_set_var "vf_cmd_awk"               "${vf_cmd_awk}"; f_arrays_set_var "vf_cmd_grep"              "${vf_cmd_grep}"; f_arrays_set_var "vf_cmd_iproute"           "${vf_cmd_iproute}"; f_arrays_set_var "vf_cmd_docker"            "${vf_cmd_docker}"; f_arrays_set_var "vf_local_ip"              "${vf_local_ip}"; f_arrays_set_var "vp_stage_number"          "0"; f_arrays_set_var "vf_local_hostname"        "$(hostname -f)"; f_arrays_set_var "vf_local_hostname_short"  "$(hostname)"; f_arrays_set_var "vf_starttime"             "$(date +%s)"; f_arrays_set_var "vf_timestamp"             "$(echo $(date +%F_%T))"; vf_args_passed="$@"; f_arrays_set_var "vf_status_exitcode"       "0"; f_arrays_set_var "vf_status_exitlocation"   ""; f_arrays_set_var "vf_status_exithint"       ""; f_arrays_set_var "vf_path_projects"         ""; f_arrays_set_var "vf_path_bashx"            ""; f_arrays_set_var "vf_dynamic_error_msg"     ""; f_arrays_set_var "vp_dynamic_error_msg"     ""; f_arrays_set_var "vf_flag_current"          ""; f_arrays_set_var "vf_flag_current_value"    ""; f_arrays_set_var "vf_git_branch" ""; if [[ "${vj_framework_flags_paths_projects}" == *"../bash-x-projects"* ]];then     f_arrays_set_var "vf_path_projects" "${vf_path_framework_parent}/bash-x-projects/"; else     f_arrays_set_var "vf_path_projects" "${vj_framework_flags_paths_projects}"; fi; if [[ "${vj_framework_flags_paths_bashx}" == *"../bash-x"* ]];then     f_arrays_set_var "vf_path_bashx" "${vf_path_framework_parent}/bash-x/"; else     f_arrays_set_var "vf_path_bashx" "${vj_framework_flags_paths_bashx}"; fi; git_branchname="$(git name-rev --name-only HEAD 2> /dev/null)"; if [[ "$?" != "0" ]];then      f_arrays_set_var "vf_git_branch" "git is not available"; else     f_arrays_set_var "vf_git_branch" "$(git rev-parse --abbrev-ref ${git_branchname})"; fi; f_errors_codes; f_framework ${vf_args_passed};
